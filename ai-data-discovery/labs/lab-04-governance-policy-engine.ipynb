{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Data Governance & Automated Policy Engine\n",
    "\n",
    "**Data Discovery: Harnessing AI, AGI & Vector Databases - Day 2**\n",
    "\n",
    "| Duration | Difficulty | Framework | Exercises |\n",
    "|---|---|---|---|\n",
    "| 90 min | Intermediate | pandas, numpy, matplotlib, networkx | 6 |\n",
    "\n",
    "In this lab, you'll practice:\n",
    "- Defining governance policies as executable rule functions\n",
    "- Scanning data assets against policies to detect violations\n",
    "- Modelling data lineage as a directed graph\n",
    "- Simulating role-based access control (RBAC)\n",
    "- Building a compliance dashboard\n",
    "- Generating automated compliance reports\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1w7u1s3oi9",
   "source": "## Student Notes & Background\n\n### Why Data Governance Matters\n\nAs organisations accumulate thousands of data assets across departments, the question shifts from *\"Can we find this data?\"* to *\"Should anyone be accessing this data, and is it compliant with our policies?\"* **Data governance** is the framework of policies, processes, and controls that ensures data is managed responsibly throughout its lifecycle.\n\nWithout automated governance, organisations face:\n- **Compliance violations** — PII stored without encryption, breaching GDPR, HIPAA, or CCPA\n- **Security risks** — unauthorised users accessing sensitive data\n- **Data decay** — stale, orphaned, or redundant data consuming resources\n- **Audit failures** — inability to demonstrate compliance to regulators\n\n### Key Concepts\n\n#### 1. Policy-as-Code\nTraditional governance relies on written policies that humans interpret and enforce manually. **Policy-as-code** encodes governance rules as executable functions that can be run automatically against every data asset in your catalogue. Each policy check takes an asset's metadata and returns a verdict: *compliant* or *violation* with a detail message.\n\nThe benefits are significant:\n- **Consistency** — every asset is evaluated by the same rules\n- **Speed** — hundreds of assets scanned in seconds rather than weeks of manual audit\n- **Auditability** — every check produces a traceable record\n- **Composability** — new policies can be added without modifying existing ones\n\n#### 2. Policy Severity Levels\nNot all violations are equal. A standard severity classification:\n\n| Severity | Description | Response Time |\n|---|---|---|\n| **Critical** | Immediate risk of data breach or regulatory penalty | Fix within 24 hours |\n| **High** | Significant compliance gap requiring prompt action | Fix within 1 week |\n| **Medium** | Best-practice deviation that should be addressed | Fix within 1 month |\n| **Low** | Minor improvement opportunity | Address in next review cycle |\n\n#### 3. Data Lineage\n**Data lineage** tracks how data flows through an organisation — from source systems (databases, APIs, files), through transformations (ETL jobs, ML pipelines, aggregations), to outputs (dashboards, reports, exports). Lineage is modelled as a **directed acyclic graph (DAG)** where:\n- **Nodes** represent data assets or processing steps\n- **Edges** represent data flow from upstream to downstream\n\nLineage analysis reveals:\n- **Bottleneck nodes** — transforms that many pipelines depend on (high failure impact)\n- **Long dependency chains** — complex pipelines that are harder to debug and audit\n- **Blast radius** — if a source system fails, which downstream outputs are affected?\n\n#### 4. Role-Based Access Control (RBAC)\n**RBAC** restricts data access based on a user's role rather than their individual identity. A typical enterprise model:\n\n| Role | Access Level | Typical Users |\n|---|---|---|\n| **Admin** | All sensitivity levels | Data platform team, CTO |\n| **Analyst** | Up to Confidential | Data analysts, business intelligence |\n| **Engineer** | Up to Internal | Software engineers, DevOps |\n| **Viewer** | Public only | General staff, external partners |\n\nA **violation** occurs when a user in a lower-privilege role accesses data above their clearance level. Monitoring access patterns helps detect both policy gaps and potential security incidents.\n\n#### 5. Compliance Dashboards\nA **compliance dashboard** provides at-a-glance visibility into your governance posture. Effective dashboards show:\n- Overall compliance score (percentage of clean assets)\n- Violations broken down by severity, category, and policy\n- Trends over time (is compliance improving or degrading?)\n- Sensitivity distribution of violating assets\n\n#### 6. Compliance Reports\nAutomated **compliance reports** translate raw violation data into actionable documents for different audiences:\n- **Executive summary** for leadership (score, headline numbers, rating)\n- **Critical findings** for the security team (specific assets and violations)\n- **Department breakdown** for data stewards (their team's compliance posture)\n- **Recommendations** for the governance committee (prioritised remediation actions)\n\n### What You'll Build\n\nIn this lab, you will:\n1. **Define** 6 governance policy check functions covering PII encryption, retention periods, stale data, owner assignment, access control, and backup compliance\n2. **Build** an automated scanner that runs all policies against 300 synthetic data assets and collects violations into a structured DataFrame\n3. **Model** data lineage as a NetworkX directed graph with source, transform, and output nodes, then analyse it for bottlenecks and long dependency chains\n4. **Simulate** 1,000 RBAC access requests across 4 roles and visualise violation rates as a heatmap\n5. **Create** a 6-panel governance dashboard with matplotlib showing severity breakdowns, compliance rates, and an overall score\n6. **Generate** a formatted compliance report with executive summary, critical findings, department breakdown, and actionable recommendations\n\n### Prerequisites\n- Familiarity with pandas DataFrames, numpy, and matplotlib\n- Understanding of set operations (for access control checks)\n- Concepts from Labs 1-2: data asset metadata, sensitivity levels, PII detection\n\n### Tips\n- Each policy function follows the same signature: `def check_policy(row) -> (bool, str)` — this makes them composable and testable\n- The synthetic data includes deliberate governance gaps (unencrypted PII, missing owners, stale assets) so you will find violations\n- For the lineage graph, `networkx` provides powerful analysis functions like `nx.dag_longest_path()`, `nx.descendants()`, and `nx.betweenness_centrality()`\n- When building the dashboard, use `plt.tight_layout()` to prevent label overlap in the 2×3 grid\n\n---",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Settings\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Generate Synthetic Data Assets\n",
    "\n",
    "We'll create ~300 data assets with governance-relevant metadata including PII flags, encryption status, retention periods, and access patterns."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "categories = ['HR', 'Finance', 'Marketing', 'Engineering', 'Legal']\n",
    "owners = ['alice', 'bob', 'carol', 'dave', 'eve', None]\n",
    "sensitivity_levels = ['Public', 'Internal', 'Confidential', 'Restricted']\n",
    "\n",
    "n_assets = 300\n",
    "assets = []\n",
    "\n",
    "all_users = ['alice', 'bob', 'carol', 'dave', 'eve', 'frank', 'grace', 'henry', 'iris', 'jack']\n",
    "\n",
    "for i in range(n_assets):\n",
    "    cat = np.random.choice(categories)\n",
    "    sens = np.random.choice(sensitivity_levels, p=[0.15, 0.30, 0.30, 0.25])\n",
    "    has_pii = cat in ['HR', 'Legal'] or (cat == 'Finance' and np.random.random() < 0.5)\n",
    "    has_encryption = (sens in ['Confidential', 'Restricted'] and np.random.random() < 0.7) or np.random.random() < 0.2\n",
    "    \n",
    "    # Determine approved users based on sensitivity\n",
    "    if sens == 'Restricted':\n",
    "        n_approved = np.random.randint(1, 4)\n",
    "    elif sens == 'Confidential':\n",
    "        n_approved = np.random.randint(2, 6)\n",
    "    else:\n",
    "        n_approved = np.random.randint(3, 10)\n",
    "    approved = list(np.random.choice(all_users, size=n_approved, replace=False))\n",
    "    \n",
    "    # Actual users (sometimes includes unauthorized)\n",
    "    n_actual = np.random.randint(1, min(n_approved + 3, len(all_users)))\n",
    "    actual = list(np.random.choice(all_users, size=n_actual, replace=False))\n",
    "    \n",
    "    assets.append({\n",
    "        'asset_id': f'ASSET-{i+1:04d}',\n",
    "        'name': f'{cat.lower()}_asset_{i+1:04d}',\n",
    "        'category': cat,\n",
    "        'owner': np.random.choice(owners, p=[0.2, 0.2, 0.2, 0.2, 0.15, 0.05]),\n",
    "        'sensitivity': sens,\n",
    "        'has_pii': has_pii,\n",
    "        'has_encryption': has_encryption,\n",
    "        'last_access_days_ago': np.random.randint(0, 400),\n",
    "        'retention_days': np.random.choice([90, 180, 365, 730, 1095]),\n",
    "        'days_since_creation': np.random.randint(30, 1200),\n",
    "        'access_count_30d': np.random.randint(0, 200),\n",
    "        'has_backup': np.random.random() < 0.6,\n",
    "        'approved_users': approved,\n",
    "        'actual_users': actual,\n",
    "    })\n",
    "\n",
    "assets_df = pd.DataFrame(assets)\n",
    "print(f\"Generated {len(assets_df)} data assets\")\n",
    "print(f\"\\nSensitivity distribution:\")\n",
    "print(assets_df['sensitivity'].value_counts())\n",
    "print(f\"\\nPII assets: {assets_df['has_pii'].sum()} ({assets_df['has_pii'].mean()*100:.1f}%)\")\n",
    "print(f\"Encrypted:  {assets_df['has_encryption'].sum()} ({assets_df['has_encryption'].mean()*100:.1f}%)\")\n",
    "assets_df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.1: Define Governance Policies\n",
    "\n",
    "Create executable policy rule functions that check data assets for compliance violations.\n",
    "\n",
    "**Your Task:** Implement 6 policy check functions. Each takes a row (asset dict) and returns `(bool, str)` — whether the asset violates the policy and a description of the violation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def check_pii_encryption(row):\n",
    "    \"\"\"CRITICAL: Assets containing PII must be encrypted.\n",
    "    Returns: (is_violation: bool, detail: str)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "def check_retention_compliance(row):\n",
    "    \"\"\"HIGH: Assets past their retention period must be flagged for review.\n",
    "    Violation if days_since_creation > retention_days.\n",
    "    Returns: (is_violation: bool, detail: str)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "def check_stale_data(row):\n",
    "    \"\"\"MEDIUM: Assets not accessed in 180+ days should be reviewed.\n",
    "    Returns: (is_violation: bool, detail: str)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "def check_owner_assigned(row):\n",
    "    \"\"\"HIGH: All data assets must have an assigned owner.\n",
    "    Returns: (is_violation: bool, detail: str)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "def check_access_control(row):\n",
    "    \"\"\"CRITICAL: No unauthorized users should be accessing assets.\n",
    "    Violation if any user in actual_users is not in approved_users.\n",
    "    Returns: (is_violation: bool, detail: str)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "def check_backup_compliance(row):\n",
    "    \"\"\"HIGH: Confidential and Restricted assets must have backups.\n",
    "    Returns: (is_violation: bool, detail: str)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "# Policy registry\n",
    "POLICIES = [\n",
    "    {'id': 'POL-001', 'name': 'PII Encryption Required', 'severity': 'Critical', 'check': check_pii_encryption},\n",
    "    {'id': 'POL-002', 'name': 'Retention Compliance', 'severity': 'High', 'check': check_retention_compliance},\n",
    "    {'id': 'POL-003', 'name': 'Stale Data Review', 'severity': 'Medium', 'check': check_stale_data},\n",
    "    {'id': 'POL-004', 'name': 'Owner Assignment', 'severity': 'High', 'check': check_owner_assigned},\n",
    "    {'id': 'POL-005', 'name': 'Access Control', 'severity': 'Critical', 'check': check_access_control},\n",
    "    {'id': 'POL-006', 'name': 'Backup Compliance', 'severity': 'High', 'check': check_backup_compliance},\n",
    "]\n",
    "\n",
    "print(f\"Defined {len(POLICIES)} governance policies\")\n",
    "for p in POLICIES:\n",
    "    print(f\"  [{p['severity']}] {p['id']}: {p['name']}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.2: Automated Policy Scanning\n",
    "\n",
    "Run all policies against all data assets to produce a violations report.\n",
    "\n",
    "**Your Task:** Scan every asset against every policy, collect all violations, and produce a summary."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def scan_all_assets(assets_df, policies):\n",
    "    \"\"\"Scan all assets against all policies.\n",
    "    \n",
    "    Steps:\n",
    "    1. For each asset, run each policy check function\n",
    "    2. Collect violations as dicts: {asset_id, policy_id, policy_name, severity, detail, category}\n",
    "    3. Return as a DataFrame\n",
    "    \n",
    "    Returns: violations DataFrame\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "violations_df = scan_all_assets(assets_df, POLICIES)\n",
    "\n",
    "if violations_df is not None and len(violations_df) > 0:\n",
    "    print(f\"Total violations found: {len(violations_df)}\")\n",
    "    print(f\"Assets with violations: {violations_df['asset_id'].nunique()} / {len(assets_df)}\")\n",
    "    print(f\"\\nViolations by severity:\")\n",
    "    print(violations_df['severity'].value_counts())\n",
    "    print(f\"\\nViolations by policy:\")\n",
    "    print(violations_df['policy_name'].value_counts())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.1: Data Lineage Tracking\n",
    "\n",
    "Build a directed graph representing data lineage — how data flows from source systems through transformations to outputs.\n",
    "\n",
    "**Your Task:** Generate synthetic lineage data, build a NetworkX directed graph, and visualize it."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def build_lineage_graph(n_pipelines=30):\n",
    "    \"\"\"Build a data lineage directed graph.\n",
    "    \n",
    "    Steps:\n",
    "    1. Create source nodes (databases, APIs, files)\n",
    "    2. Create transform nodes (ETL jobs, ML models, aggregations)\n",
    "    3. Create output nodes (reports, dashboards, exports)\n",
    "    4. Connect them in realistic pipeline patterns\n",
    "    5. Visualize with node coloring by type\n",
    "    \n",
    "    Node types: 'source' (green), 'transform' (orange), 'output' (blue)\n",
    "    \n",
    "    Returns: NetworkX DiGraph\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "G = build_lineage_graph()\n",
    "\n",
    "if G is not None:\n",
    "    print(f\"Lineage graph: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def analyze_lineage(G):\n",
    "    \"\"\"Analyze the lineage graph for governance insights.\n",
    "    \n",
    "    Find:\n",
    "    - Most connected nodes (highest degree) — potential bottlenecks\n",
    "    - Longest paths — most complex data pipelines\n",
    "    - Source nodes with most downstream dependents\n",
    "    \n",
    "    Print findings.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "if G is not None:\n",
    "    analyze_lineage(G)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.2: Access Control Simulation\n",
    "\n",
    "Model a role-based access control (RBAC) system and simulate access requests to detect violations.\n",
    "\n",
    "**Your Task:** Define roles with sensitivity permissions, simulate access requests, and analyze violations."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def simulate_rbac(assets_df, n_requests=1000):\n",
    "    \"\"\"Simulate RBAC access requests and detect violations.\n",
    "    \n",
    "    Roles and their maximum allowed sensitivity:\n",
    "    - admin: Restricted (can access everything)\n",
    "    - analyst: Confidential\n",
    "    - engineer: Internal\n",
    "    - viewer: Public\n",
    "    \n",
    "    Sensitivity ordering: Public < Internal < Confidential < Restricted\n",
    "    \n",
    "    Steps:\n",
    "    1. Define role -> max_sensitivity mapping\n",
    "    2. Generate random access requests (user, role, asset)\n",
    "    3. Check if the role is allowed to access that sensitivity level\n",
    "    4. Compute violation rates by role\n",
    "    5. Plot a heatmap of violations by role vs sensitivity level\n",
    "    \n",
    "    Returns: access_log DataFrame\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "access_log = simulate_rbac(assets_df)\n",
    "\n",
    "if access_log is not None:\n",
    "    print(f\"\\nTotal requests: {len(access_log)}\")\n",
    "    print(f\"Violations: {access_log['violation'].sum()} ({access_log['violation'].mean()*100:.1f}%)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.1: Governance Dashboard\n",
    "\n",
    "Build a comprehensive 2x3 compliance dashboard visualizing the governance state of your data catalogue.\n",
    "\n",
    "**Your Task:** Create a 6-panel matplotlib dashboard."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def build_governance_dashboard(assets_df, violations_df):\n",
    "    \"\"\"Build a 2x3 governance compliance dashboard.\n",
    "    \n",
    "    Panels:\n",
    "    1. Top-left: Violations by severity (bar chart)\n",
    "    2. Top-centre: Violations by category (grouped bar showing category vs severity)\n",
    "    3. Top-right: Asset compliance rate (pie chart: compliant vs non-compliant)\n",
    "    4. Bottom-left: Top violated policies (horizontal bar)\n",
    "    5. Bottom-centre: Sensitivity distribution of violating assets (bar)\n",
    "    6. Bottom-right: Overall compliance score (large text showing percentage)\n",
    "    \n",
    "    Use figsize=(18, 10) and tight_layout.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "if violations_df is not None and len(violations_df) > 0:\n",
    "    build_governance_dashboard(assets_df, violations_df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.2: Compliance Report Generator\n",
    "\n",
    "Generate a text-based compliance report with executive summary, critical findings, and per-department breakdown.\n",
    "\n",
    "**Your Task:** Implement a report generator that produces a formatted compliance report."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def generate_compliance_report(assets_df, violations_df):\n",
    "    \"\"\"Generate a formatted compliance report.\n",
    "    \n",
    "    Sections:\n",
    "    1. Executive Summary: overall compliance score, total assets, total violations\n",
    "    2. Critical Findings: list all Critical severity violations with asset details\n",
    "    3. Department Breakdown: for each category, show violation count, top issues\n",
    "    4. Recommendations: top 3 actionable recommendations based on findings\n",
    "    \n",
    "    Returns: formatted report string\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "if violations_df is not None and len(violations_df) > 0:\n",
    "    report = generate_compliance_report(assets_df, violations_df)\n",
    "    if report:\n",
    "        print(report)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, you learned how to:\n",
    "\n",
    "1. **Define** governance policies as executable rule functions\n",
    "2. **Scan** data assets against policies to detect compliance violations\n",
    "3. **Model** data lineage as a directed graph and identify bottlenecks\n",
    "4. **Simulate** role-based access control to detect unauthorized access\n",
    "5. **Build** a comprehensive governance compliance dashboard\n",
    "6. **Generate** automated compliance reports with findings and recommendations\n",
    "\n",
    "---\n",
    "\n",
    "*Data Discovery: Harnessing AI, AGI & Vector Databases | AI Elevate*"
   ]
  }
 ]
}