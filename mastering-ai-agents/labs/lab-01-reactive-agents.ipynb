{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Building Reactive Agents\n",
    "\n",
    "In this lab, you'll build reactive agents from scratch and understand the stimulus-response pattern.\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand reactive agent architecture\n",
    "- Implement rule-based decision making\n",
    "- Build multiple agent types (thermostat, trading bot, game AI)\n",
    "- Test agents in simulated environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Basic Reactive Agent\n",
    "\n",
    "A reactive agent maps percepts directly to actions using rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import Any, Dict\n",
    "\n",
    "class ReactiveAgent(ABC):\n",
    "    \"\"\"Base class for reactive agents\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "        self.action_history = []\n",
    "    \n",
    "    @abstractmethod\n",
    "    def perceive(self, environment: Dict) -> Dict:\n",
    "        \"\"\"Get percepts from environment\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def decide(self, percepts: Dict) -> str:\n",
    "        \"\"\"Choose action based on percepts\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def act(self, action: str):\n",
    "        \"\"\"Execute action and record it\"\"\"\n",
    "        self.action_history.append(action)\n",
    "        return action\n",
    "    \n",
    "    def run_cycle(self, environment: Dict) -> str:\n",
    "        \"\"\"One perception-action cycle\"\"\"\n",
    "        percepts = self.perceive(environment)\n",
    "        action = self.decide(percepts)\n",
    "        return self.act(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Thermostat Agent\n",
    "\n",
    "A simple agent that controls temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThermostatAgent(ReactiveAgent):\n",
    "    \"\"\"A reactive thermostat agent\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, target_temp: float = 21.0, tolerance: float = 1.0):\n",
    "        super().__init__(name)\n",
    "        self.target_temp = target_temp\n",
    "        self.tolerance = tolerance\n",
    "    \n",
    "    def perceive(self, environment: Dict) -> Dict:\n",
    "        return {\n",
    "            'current_temp': environment.get('temperature', 20),\n",
    "            'humidity': environment.get('humidity', 50)\n",
    "        }\n",
    "    \n",
    "    def decide(self, percepts: Dict) -> str:\n",
    "        temp = percepts['current_temp']\n",
    "        \n",
    "        if temp < self.target_temp - self.tolerance:\n",
    "            return 'HEAT_ON'\n",
    "        elif temp > self.target_temp + self.tolerance:\n",
    "            return 'COOL_ON'\n",
    "        else:\n",
    "            return 'MAINTAIN'\n",
    "\n",
    "# Test the thermostat\n",
    "thermostat = ThermostatAgent('Living Room', target_temp=21)\n",
    "\n",
    "test_environments = [\n",
    "    {'temperature': 18, 'humidity': 45},\n",
    "    {'temperature': 21, 'humidity': 50},\n",
    "    {'temperature': 25, 'humidity': 60},\n",
    "]\n",
    "\n",
    "for env in test_environments:\n",
    "    action = thermostat.run_cycle(env)\n",
    "    print(f\"Temp: {env['temperature']}°C → Action: {action}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Trading Bot Agent\n",
    "\n",
    "Implement a simple trading agent that:\n",
    "- Buys when price drops below a threshold\n",
    "- Sells when price rises above a threshold\n",
    "- Holds otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TradingAgent(ReactiveAgent):\n",
    "    \"\"\"A simple reactive trading agent\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, buy_threshold: float, sell_threshold: float):\n",
    "        super().__init__(name)\n",
    "        self.buy_threshold = buy_threshold\n",
    "        self.sell_threshold = sell_threshold\n",
    "        self.position = 0  # Number of shares held\n",
    "    \n",
    "    def perceive(self, environment: Dict) -> Dict:\n",
    "        # YOUR CODE HERE\n",
    "        # Return dict with 'price' and 'volume'\n",
    "        pass\n",
    "    \n",
    "    def decide(self, percepts: Dict) -> str:\n",
    "        # YOUR CODE HERE\n",
    "        # Return 'BUY', 'SELL', or 'HOLD'\n",
    "        pass\n",
    "\n",
    "# Test your trading agent\n",
    "trader = TradingAgent('SimpleTrder', buy_threshold=95, sell_threshold=105)\n",
    "\n",
    "market_data = [\n",
    "    {'price': 100, 'volume': 1000},\n",
    "    {'price': 90, 'volume': 1500},\n",
    "    {'price': 110, 'volume': 2000},\n",
    "    {'price': 98, 'volume': 800},\n",
    "]\n",
    "\n",
    "for data in market_data:\n",
    "    action = trader.run_cycle(data)\n",
    "    print(f\"Price: ${data['price']} → Action: {action}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Rule-Based System\n",
    "\n",
    "A more flexible approach using explicit rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Callable, List\n",
    "\n",
    "@dataclass\n",
    "class Rule:\n",
    "    \"\"\"A condition-action rule\"\"\"\n",
    "    name: str\n",
    "    condition: Callable[[Dict], bool]\n",
    "    action: str\n",
    "    priority: int = 0\n",
    "\n",
    "class RuleBasedAgent(ReactiveAgent):\n",
    "    \"\"\"Agent that uses explicit rules\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, rules: List[Rule]):\n",
    "        super().__init__(name)\n",
    "        # Sort rules by priority (highest first)\n",
    "        self.rules = sorted(rules, key=lambda r: r.priority, reverse=True)\n",
    "    \n",
    "    def perceive(self, environment: Dict) -> Dict:\n",
    "        return environment\n",
    "    \n",
    "    def decide(self, percepts: Dict) -> str:\n",
    "        for rule in self.rules:\n",
    "            if rule.condition(percepts):\n",
    "                print(f\"  Triggered rule: {rule.name}\")\n",
    "                return rule.action\n",
    "        return 'NO_ACTION'\n",
    "\n",
    "# Example: Home Security Agent\n",
    "security_rules = [\n",
    "    Rule('fire_alarm', lambda p: p.get('smoke', False), 'CALL_FIRE_DEPT', priority=100),\n",
    "    Rule('intrusion', lambda p: p.get('motion', False) and not p.get('owner_home', True), 'ALERT_OWNER', priority=50),\n",
    "    Rule('night_lights', lambda p: p.get('dark', False) and p.get('owner_home', False), 'LIGHTS_ON', priority=10),\n",
    "]\n",
    "\n",
    "security = RuleBasedAgent('HomeSecurity', security_rules)\n",
    "\n",
    "scenarios = [\n",
    "    {'smoke': True, 'motion': False, 'owner_home': True, 'dark': False},\n",
    "    {'smoke': False, 'motion': True, 'owner_home': False, 'dark': True},\n",
    "    {'smoke': False, 'motion': False, 'owner_home': False, 'dark': True},\n",
    "]\n",
    "\n",
    "for i, scenario in enumerate(scenarios):\n",
    "    print(f\"\\nScenario {i+1}: {scenario}\")\n",
    "    action = security.run_cycle(scenario)\n",
    "    print(f\"Action: {action}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Game AI Agent\n",
    "\n",
    "Create a reactive agent for a simple game where:\n",
    "- If enemy is close and health is low → FLEE\n",
    "- If enemy is close and health is high → ATTACK\n",
    "- If health is low and no enemy → HEAL\n",
    "- If treasure nearby → COLLECT\n",
    "- Otherwise → EXPLORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Create game_rules list with Rule objects\n",
    "# Create RuleBasedAgent with those rules\n",
    "# Test with various game states\n",
    "\n",
    "game_rules = [\n",
    "    # YOUR CODE HERE\n",
    "]\n",
    "\n",
    "game_ai = RuleBasedAgent('GameAI', game_rules)\n",
    "\n",
    "# Test scenarios\n",
    "game_states = [\n",
    "    {'enemy_distance': 5, 'health': 20, 'treasure_nearby': False},\n",
    "    {'enemy_distance': 5, 'health': 80, 'treasure_nearby': False},\n",
    "    {'enemy_distance': 100, 'health': 30, 'treasure_nearby': False},\n",
    "    {'enemy_distance': 100, 'health': 80, 'treasure_nearby': True},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Environment Simulation\n",
    "\n",
    "Let's create a simple environment that agents can interact with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class SimpleEnvironment:\n",
    "    \"\"\"A simple simulated environment\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.temperature = 20.0\n",
    "        self.time_step = 0\n",
    "    \n",
    "    def get_state(self) -> Dict:\n",
    "        return {\n",
    "            'temperature': self.temperature,\n",
    "            'time': self.time_step\n",
    "        }\n",
    "    \n",
    "    def apply_action(self, action: str):\n",
    "        if action == 'HEAT_ON':\n",
    "            self.temperature += 0.5\n",
    "        elif action == 'COOL_ON':\n",
    "            self.temperature -= 0.5\n",
    "        \n",
    "        # Natural drift\n",
    "        self.temperature += random.uniform(-0.2, 0.2)\n",
    "        self.time_step += 1\n",
    "    \n",
    "    def run_simulation(self, agent: ReactiveAgent, steps: int = 20):\n",
    "        history = []\n",
    "        \n",
    "        for _ in range(steps):\n",
    "            state = self.get_state()\n",
    "            action = agent.run_cycle(state)\n",
    "            self.apply_action(action)\n",
    "            history.append({\n",
    "                'time': self.time_step,\n",
    "                'temp': state['temperature'],\n",
    "                'action': action\n",
    "            })\n",
    "        \n",
    "        return history\n",
    "\n",
    "# Run simulation\n",
    "env = SimpleEnvironment()\n",
    "env.temperature = 15.0  # Start cold\n",
    "\n",
    "thermostat = ThermostatAgent('SmartThermo', target_temp=21)\n",
    "history = env.run_simulation(thermostat, steps=30)\n",
    "\n",
    "# Visualize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "times = [h['time'] for h in history]\n",
    "temps = [h['temp'] for h in history]\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(times, temps, 'b-', label='Temperature')\n",
    "plt.axhline(y=21, color='r', linestyle='--', label='Target')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Temperature (°C)')\n",
    "plt.title('Thermostat Agent Simulation')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Exercise\n",
    "\n",
    "Create a multi-agent simulation with:\n",
    "1. Multiple thermostat agents in different rooms\n",
    "2. Heat transfer between rooms\n",
    "3. External temperature influence\n",
    "\n",
    "Visualize how the agents coordinate (or don't) to maintain comfort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE - Challenge Exercise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
