{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Lab 1: Python for Data Science - SOLUTIONS\n\n**Duration:** 60-90 minutes | **Difficulty:** Beginner\n\n**This notebook contains all solutions. Use for reference after attempting the exercises.**\n\n---\n\n## Overview\n\nThis lab introduces the essential Python libraries for data science: NumPy, Pandas, and Matplotlib. You'll learn to manipulate data arrays, work with tabular data, create visualizations, and preprocess data for machine learning applications.\n\n### Lab Structure\n\n| Part | Topic | Key Concepts |\n|------|-------|--------------|\n| **Part 1** | NumPy Arrays | Creating arrays, statistics (mean/max/min/sum), reshaping, slicing |\n| **Part 2** | Pandas DataFrames | Creating DataFrames, exploring data, filtering, grouping & aggregation |\n| **Part 3** | Data Visualization | Histograms, scatter plots, bar charts with Matplotlib |\n| **Part 4** | Data Preprocessing | Normalization, standardization, one-hot encoding |\n\n### Libraries Used\n\n- **NumPy** - Numerical computing and array operations\n- **Pandas** - Data manipulation and analysis\n- **Matplotlib** - Data visualization\n\n### Dataset\n\nThis lab uses a synthetic **Customer dataset** (100 rows) with columns:\n`customer_id`, `age`, `income`, `years_customer`, `region`, `purchased`\n\n---\n\n## Learning Objectives\n\nBy the end of this lab, you will be able to:\n1. Create and manipulate NumPy arrays\n2. Use Pandas DataFrames to filter and aggregate data\n3. Create visualizations with Matplotlib\n4. Preprocess data for machine learning\n\n## Instructions\n\n- This is the **SOLUTIONS** notebook - use for reference after attempting exercises\n- All exercise cells contain the correct answers\n- Run cells with `Shift+Enter`"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Run the cell below to import the required libraries. You must run this cell first before any other code will work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Setup complete! NumPy:\", np.__version__, \"| Pandas:\", pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: NumPy Arrays\n",
    "\n",
    "NumPy is the foundation of data science in Python. It provides fast array operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Creating Arrays - Demonstration\n",
    "\n",
    "Run the cell below to see different ways to create NumPy arrays:\n",
    "- `np.array([list])` - Create from a Python list\n",
    "- `np.zeros((rows, cols))` - Create array filled with zeros\n",
    "- `np.ones((rows, cols))` - Create array filled with ones\n",
    "- `np.arange(n)` - Create array with values 0 to n-1\n",
    "- `np.eye(n)` - Create n×n identity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From a list\n",
    "arr1 = np.array([1, 2, 3, 4, 5])\n",
    "print(\"From list:\", arr1)\n",
    "\n",
    "# Zeros (2 rows, 3 columns)\n",
    "arr2 = np.zeros((2, 3))\n",
    "print(\"\\nZeros (2x3):\")\n",
    "print(arr2)\n",
    "\n",
    "# Range 0 to 9\n",
    "arr3 = np.arange(10)\n",
    "print(\"\\nRange 0-9:\", arr3)\n",
    "\n",
    "# Identity matrix\n",
    "arr4 = np.eye(3)\n",
    "print(\"\\n3x3 Identity:\")\n",
    "print(arr4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.1: Create Arrays - SOLUTION\n",
    "\n",
    "In the cell below, replace each `None` with the correct code:\n",
    "\n",
    "| Variable | What to create | Code to write |\n",
    "|----------|----------------|---------------|\n",
    "| `arr_a` | Array containing [10, 20, 30, 40, 50] | `np.array([10, 20, 30, 40, 50])` |\n",
    "| `arr_b` | 4×4 array filled with zeros | `np.zeros((4, 4))` |\n",
    "| `arr_c` | Array with values 0 to 19 | `np.arange(20)` |\n",
    "| `arr_d` | 5×5 identity matrix | `np.eye(5)` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "\"\"\"\nExercise 1.1 Solution: Creating NumPy Arrays\n\nThis solution demonstrates four different ways to create NumPy arrays:\n- From a Python list\n- Filled with zeros\n- Using a range of values\n- As an identity matrix\n\"\"\"\n\n# Create array [10, 20, 30, 40, 50] from a Python list\narr_a = np.array([10, 20, 30, 40, 50])\n\n# Create 4x4 array filled with zeros - useful for initializing matrices\narr_b = np.zeros((4, 4))\n\n# Create array with values 0 to 19 using arange\narr_c = np.arange(20)\n\n# Create 5x5 identity matrix - diagonal of 1s, rest 0s\narr_d = np.eye(5)\n\n# Print results to verify\nprint(\"arr_a:\", arr_a)\nprint(\"arr_b shape:\", arr_b.shape)\nprint(\"arr_c:\", arr_c)\nprint(\"arr_d shape:\", arr_d.shape)"
  },
  {
   "cell_type": "markdown",
   "source": "### Code Explanation: Exercise 1.1\n\n| Line | Code | Explanation |\n|------|------|-------------|\n| 1 | `arr_a = np.array([10, 20, 30, 40, 50])` | **Creates an array from a Python list.** The `np.array()` function converts a regular Python list into a NumPy array, enabling fast mathematical operations. |\n| 2 | `arr_b = np.zeros((4, 4))` | **Creates a 4×4 matrix of zeros.** The tuple `(4, 4)` specifies the shape. Zeros arrays are commonly used to initialize matrices before filling them with computed values. |\n| 3 | `arr_c = np.arange(20)` | **Creates an array with values 0 to 19.** `arange(n)` generates integers from 0 to n-1, similar to Python's `range()` but returns an array instead of an iterator. |\n| 4 | `arr_d = np.eye(5)` | **Creates a 5×5 identity matrix.** An identity matrix has 1s on the diagonal and 0s elsewhere. It's essential in linear algebra (multiplying by identity returns the original matrix). |\n| 5 | `print(..., arr_b.shape)` | **The `.shape` attribute** returns a tuple with the dimensions of the array. For `arr_b`, this is `(4, 4)` meaning 4 rows and 4 columns. |\n\n**Why these functions matter:**\n- `np.array()` is the foundation - it converts Python data to NumPy's optimized format\n- `np.zeros()` and `np.ones()` are used to pre-allocate memory for efficiency\n- `np.arange()` is faster than converting `list(range())` to an array\n- `np.eye()` is essential for matrix operations like solving linear equations",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Array Statistics - Demonstration\n",
    "\n",
    "NumPy provides functions to calculate statistics:\n",
    "- `np.mean(arr)` - Average value\n",
    "- `np.max(arr)` - Maximum value\n",
    "- `np.min(arr)` - Minimum value\n",
    "- `np.sum(arr)` - Sum of all values\n",
    "- `np.argmax(arr)` - Index of maximum value\n",
    "\n",
    "Run the cell below to see these in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.array([85, 92, 78, 90, 88, 76, 95, 89])\n",
    "print(\"Scores:\", scores)\n",
    "print(\"Mean:\", np.mean(scores))\n",
    "print(\"Max:\", np.max(scores))\n",
    "print(\"Min:\", np.min(scores))\n",
    "print(\"Sum:\", np.sum(scores))\n",
    "print(\"Index of max:\", np.argmax(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "\"\"\"\nExercise 1.2 Solution: Array Statistics\n\nThis solution demonstrates NumPy's statistical functions for analyzing data.\nThese functions operate on entire arrays and return single values.\n\"\"\"\n\ntemperatures = np.array([72, 75, 68, 80, 85, 70, 60])\nprint(\"Temperatures:\", temperatures)\n\n# Calculate the arithmetic mean (sum of values / count)\navg_temp = np.mean(temperatures)\n\n# Find the maximum value in the array\nmax_temp = np.max(temperatures)\n\n# Find the minimum value in the array\nmin_temp = np.min(temperatures)\n\n# Find the INDEX (position) of the maximum value, not the value itself\nhottest_day = np.argmax(temperatures)\n\n# Calculate range: difference between highest and lowest values\ntemp_range = max_temp - min_temp\n\nprint(\"\\nAverage:\", avg_temp)\nprint(\"Max:\", max_temp)\nprint(\"Min:\", min_temp)\nprint(\"Hottest day index:\", hottest_day)\nprint(\"Range:\", temp_range)"
  },
  {
   "cell_type": "markdown",
   "source": "### Code Explanation: Exercise 1.2\n\n| Line | Code | Explanation |\n|------|------|-------------|\n| 1 | `avg_temp = np.mean(temperatures)` | **Calculates the arithmetic mean.** Adds all values and divides by the count. Result: (72+75+68+80+85+70+60)/7 = 72.86. This is the central tendency of the data. |\n| 2 | `max_temp = np.max(temperatures)` | **Finds the maximum value.** Scans the entire array and returns the largest element (85). Useful for finding peaks or upper bounds. |\n| 3 | `min_temp = np.min(temperatures)` | **Finds the minimum value.** Returns the smallest element (60). Together with max, defines the range of data. |\n| 4 | `hottest_day = np.argmax(temperatures)` | **Returns the INDEX of the maximum, not the value.** Returns 4 because `temperatures[4]` is 85. The \"arg\" prefix means \"argument\" or position. |\n| 5 | `temp_range = max_temp - min_temp` | **Calculates the range.** The difference between max and min (85-60=25) shows the spread of the data. |\n\n**Key distinction: `max()` vs `argmax()`**\n- `np.max([10, 50, 30])` returns `50` (the value)\n- `np.argmax([10, 50, 30])` returns `1` (the index where 50 is located)\n\n**Why these functions matter:**\n- `mean()` summarizes data with a single representative value\n- `max()`/`min()` identify extremes and outliers\n- `argmax()` finds WHERE the maximum occurs (e.g., which day was hottest)\n- These are vectorized operations - much faster than Python loops",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures = np.array([72, 75, 68, 80, 85, 70, 60])\n",
    "print(\"Temperatures:\", temperatures)\n",
    "\n",
    "avg_temp = np.mean(temperatures)  # SOLUTION\n",
    "max_temp = np.max(temperatures)  # SOLUTION\n",
    "min_temp = np.min(temperatures)  # SOLUTION\n",
    "hottest_day = np.argmax(temperatures)  # SOLUTION\n",
    "temp_range = max_temp - min_temp  # SOLUTION\n",
    "\n",
    "print(\"\\nAverage:\", avg_temp)\n",
    "print(\"Max:\", max_temp)\n",
    "print(\"Min:\", min_temp)\n",
    "print(\"Hottest day index:\", hottest_day)\n",
    "print(\"Range:\", temp_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Reshaping Arrays - Demonstration\n",
    "\n",
    "You can change the shape of an array with `.reshape(rows, cols)`.\n",
    "\n",
    "**Important:** The total number of elements must stay the same (e.g., 12 elements can be 3×4, 4×3, 2×6, etc.)\n",
    "\n",
    "Run the cell below to see reshaping in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(12)  # [0, 1, 2, ..., 11]\n",
    "print(\"Original:\", arr)\n",
    "print(\"Shape:\", arr.shape)\n",
    "\n",
    "# Reshape to 3 rows x 4 columns\n",
    "arr_3x4 = arr.reshape(3, 4)\n",
    "print(\"\\nReshaped to 3x4:\")\n",
    "print(arr_3x4)\n",
    "\n",
    "# Reshape to 4 rows x 3 columns\n",
    "arr_4x3 = arr.reshape(4, 3)\n",
    "print(\"\\nReshaped to 4x3:\")\n",
    "print(arr_4x3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Array Slicing - Demonstration\n",
    "\n",
    "Select parts of arrays using slicing syntax `[row, column]`:\n",
    "- `arr[0, :]` - First row (all columns)\n",
    "- `arr[:, 0]` - First column (all rows)\n",
    "- `arr[:, -1]` - Last column\n",
    "- `arr[1:4, 1:4]` - Rows 1-3, columns 1-3\n",
    "\n",
    "Run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "\"\"\"\nExercise 1.3 Solution: Reshaping and Slicing Arrays\n\nThis solution demonstrates how to change array dimensions with reshape()\nand extract portions of arrays using slicing notation.\n\"\"\"\n\narr = np.arange(20)\nmatrix = np.arange(25).reshape(5, 5)\n\nprint(\"arr:\", arr)\nprint(\"\\nmatrix:\")\nprint(matrix)\n\n# Reshape 1D array (20 elements) into 2D array (4 rows × 5 columns)\n# Total elements must match: 4 × 5 = 20\narr_4x5 = arr.reshape(4, 5)\n\n# Slice first row: [0, :] means row 0, all columns\n# The colon (:) is a wildcard meaning \"all\"\nfirst_row = matrix[0, :]\n\n# Slice last column: [:, -1] means all rows, last column\n# Negative indices count from the end (-1 = last)\nlast_col = matrix[:, -1]\n\n# Slice center 3×3: [1:4, 1:4] means rows 1,2,3 and columns 1,2,3\n# Note: end index is exclusive, so 1:4 gives indices 1, 2, 3\ncenter = matrix[1:4, 1:4]\n\nprint(\"\\narr_4x5:\")\nprint(arr_4x5)\nprint(\"\\nfirst_row:\", first_row)\nprint(\"last_col:\", last_col)\nprint(\"center:\")\nprint(center)"
  },
  {
   "cell_type": "markdown",
   "source": "### Code Explanation: Exercise 1.3\n\n| Line | Code | Explanation |\n|------|------|-------------|\n| 1 | `arr_4x5 = arr.reshape(4, 5)` | **Reshapes a 1D array into 2D.** The 20-element array becomes 4 rows × 5 columns. Elements fill row-by-row (row-major order). Total elements must match: 4×5=20. |\n| 2 | `first_row = matrix[0, :]` | **Extracts row 0 (first row).** The syntax `[row, col]` selects elements. `:` means \"all columns\". Result: `[0, 1, 2, 3, 4]`. |\n| 3 | `last_col = matrix[:, -1]` | **Extracts the last column.** `:` means \"all rows\", `-1` is the last column index. Negative indexing counts from the end. |\n| 4 | `center = matrix[1:4, 1:4]` | **Extracts a 3×3 subarray.** `1:4` means indices 1, 2, 3 (end is exclusive). This gets the center portion, excluding edges. |\n\n**Slicing Syntax Breakdown:**\n```\nmatrix[start_row:end_row, start_col:end_col]\n```\n- Omitting start defaults to 0: `[:3]` = `[0:3]`\n- Omitting end defaults to length: `[2:]` = from index 2 to end\n- `:` alone means \"everything\"\n\n**Visual Example of `matrix[1:4, 1:4]`:**\n```\nOriginal 5×5:           Slice [1:4, 1:4]:\n[[ 0  1  2  3  4]       \n [ 5 [6  7  8] 9]       [[ 6  7  8]\n [10 [11 12 13] 14]  →   [11 12 13]\n [15 [16 17 18] 19]      [16 17 18]]\n [20 21 22 23 24]]\n```\n\n**Why reshaping and slicing matter:**\n- Reshaping prepares data for algorithms that expect specific dimensions\n- Slicing extracts features, windows, or batches from datasets\n- Both are zero-copy operations when possible (very efficient)",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.3: Reshape and Slice - SOLUTION\n",
    "\n",
    "Complete the following tasks by replacing `None` with the correct code:\n",
    "\n",
    "| Variable | What to do | Code to write |\n",
    "|----------|------------|---------------|\n",
    "| `arr_4x5` | Reshape `arr` to 4 rows × 5 columns | `arr.reshape(4, 5)` |\n",
    "| `first_row` | Get the first row of `matrix` | `matrix[0, :]` |\n",
    "| `last_col` | Get the last column of `matrix` | `matrix[:, -1]` |\n",
    "| `center` | Get the center 3×3 subarray | `matrix[1:4, 1:4]` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(20)\n",
    "matrix = np.arange(25).reshape(5, 5)\n",
    "\n",
    "print(\"arr:\", arr)\n",
    "print(\"\\nmatrix:\")\n",
    "print(matrix)\n",
    "\n",
    "# Reshape arr to 4x5\n",
    "arr_4x5 = arr.reshape(4, 5)  # SOLUTION\n",
    "\n",
    "# Get first row of matrix\n",
    "first_row = matrix[0, :]  # SOLUTION\n",
    "\n",
    "# Get last column of matrix\n",
    "last_col = matrix[:, -1]  # SOLUTION\n",
    "\n",
    "# Get center 3x3\n",
    "center = matrix[1:4, 1:4]  # SOLUTION\n",
    "\n",
    "print(\"\\narr_4x5:\")\n",
    "print(arr_4x5)\n",
    "print(\"\\nfirst_row:\", first_row)\n",
    "print(\"last_col:\", last_col)\n",
    "print(\"center:\")\n",
    "print(center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: Pandas DataFrames\n",
    "\n",
    "Pandas provides the DataFrame - like an Excel spreadsheet in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Creating DataFrames - Demonstration\n",
    "\n",
    "Create a DataFrame from a dictionary where:\n",
    "- Keys become column names\n",
    "- Values (lists) become the data\n",
    "\n",
    "Run the cell below to see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'Diana'],\n",
    "    'age': [25, 30, 35, 28],\n",
    "    'city': ['NYC', 'LA', 'NYC', 'LA'],\n",
    "    'salary': [70000, 80000, 90000, 75000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "print(\"\\nShape:\", df.shape)\n",
    "print(\"Columns:\", list(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Exploring DataFrames - Demonstration\n",
    "\n",
    "Useful methods for exploring data:\n",
    "- `df.head()` - First 5 rows\n",
    "- `df.describe()` - Summary statistics\n",
    "- `df['column']` - Select a single column\n",
    "- `df['column'].mean()` - Mean of a column\n",
    "\n",
    "Run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First 2 rows:\")\n",
    "print(df.head(2))\n",
    "\n",
    "print(\"\\nSummary statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\nAverage salary:\", df['salary'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "\"\"\"\nExercise 2.1 Solution: Exploring DataFrame Statistics\n\nThis solution demonstrates how to access DataFrame columns and\ncalculate summary statistics using Pandas methods.\n\"\"\"\n\n# Access 'age' column and calculate mean\n# The bracket notation df['column'] returns a Series\navg_age = customers['age'].mean()\n\n# Access 'income' column and find maximum value\nmax_income = customers['income'].max()\n\n# Sum the 'purchased' column (0s and 1s)\n# Since purchased is binary, sum gives count of 1s (purchases)\ntotal_purchased = customers['purchased'].sum()\n\nprint(\"Average age:\", avg_age)\nprint(\"Max income:\", max_income)\nprint(\"Total purchased:\", total_purchased)"
  },
  {
   "cell_type": "markdown",
   "source": "### Code Explanation: Exercise 2.1\n\n| Line | Code | Explanation |\n|------|------|-------------|\n| 1 | `avg_age = customers['age'].mean()` | **Accesses the 'age' column and calculates mean.** `customers['age']` returns a Pandas Series (single column). `.mean()` calculates the average of all values in that column. |\n| 2 | `max_income = customers['income'].max()` | **Finds the maximum income.** The `.max()` method returns the largest value in the column. Useful for identifying the highest earner. |\n| 3 | `total_purchased = customers['purchased'].sum()` | **Sums the purchase column.** Since 'purchased' contains 0s and 1s, summing counts how many 1s exist (i.e., how many customers made a purchase). |\n\n**Understanding DataFrame Column Access:**\n```python\ncustomers['age']      # Returns a Series (single column)\ncustomers[['age', 'income']]  # Returns a DataFrame (multiple columns)\ncustomers.age         # Dot notation (works but less flexible)\n```\n\n**Common Statistical Methods:**\n| Method | Returns |\n|--------|---------|\n| `.mean()` | Average value |\n| `.median()` | Middle value when sorted |\n| `.std()` | Standard deviation |\n| `.sum()` | Sum of all values |\n| `.count()` | Number of non-null values |\n| `.min()` / `.max()` | Minimum / Maximum |\n\n**Why this matters:**\n- Understanding data distributions is the first step in any analysis\n- These summary statistics help identify outliers and data quality issues\n- Binary columns (0/1) can be summed to count occurrences",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "n = 100\n",
    "\n",
    "customers = pd.DataFrame({\n",
    "    'customer_id': range(1, n+1),\n",
    "    'age': np.random.randint(18, 65, n),\n",
    "    'income': np.random.normal(50000, 15000, n).astype(int),\n",
    "    'years_customer': np.random.randint(1, 15, n),\n",
    "    'region': np.random.choice(['North', 'South', 'East', 'West'], n),\n",
    "    'purchased': np.random.choice([0, 1], n, p=[0.6, 0.4])\n",
    "})\n",
    "\n",
    "print(\"Customer dataset created!\")\n",
    "print(f\"Shape: {customers.shape[0]} rows, {customers.shape[1]} columns\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(customers.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.1: Explore the Customer Data - SOLUTION\n",
    "\n",
    "Calculate statistics about the customer dataset by replacing `None` with the correct code:\n",
    "\n",
    "| Variable | What to calculate | Code to write |\n",
    "|----------|-------------------|---------------|\n",
    "| `avg_age` | Average customer age | `customers['age'].mean()` |\n",
    "| `max_income` | Maximum income | `customers['income'].max()` |\n",
    "| `total_purchased` | Total customers who purchased (sum of 1s) | `customers['purchased'].sum()` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "\"\"\"\nExercise 2.2 Solution: Filtering DataFrames\n\nThis solution demonstrates boolean indexing to filter rows based on conditions.\nPandas uses bracket notation with boolean expressions inside.\n\"\"\"\n\n# Filter rows where income is greater than 70000\n# customers['income'] > 70000 creates a boolean Series (True/False for each row)\n# Passing this to customers[...] returns only rows where True\nhigh_income = customers[customers['income'] > 70000]\n\n# Filter rows where region equals 'East'\n# Use == for equality comparison (single = is assignment)\neast_region = customers[customers['region'] == 'East']\n\n# Multiple conditions: age < 30 AND purchased == 1\n# Each condition must be in parentheses\n# Use & for AND, | for OR (not 'and'/'or' keywords)\nyoung_buyers = customers[(customers['age'] < 30) & (customers['purchased'] == 1)]\n\nprint(\"High income count:\", len(high_income))\nprint(\"East region count:\", len(east_region))\nprint(\"Young buyers count:\", len(young_buyers))"
  },
  {
   "cell_type": "markdown",
   "source": "### Code Explanation: Exercise 2.2\n\n| Line | Code | Explanation |\n|------|------|-------------|\n| 1 | `high_income = customers[customers['income'] > 70000]` | **Filters rows where income exceeds 70000.** The inner expression creates a boolean mask (True/False for each row), and the outer brackets select only True rows. |\n| 2 | `east_region = customers[customers['region'] == 'East']` | **Filters rows where region is 'East'.** Uses `==` for equality. Strings must be quoted and match exactly (case-sensitive). |\n| 3 | `young_buyers = customers[(customers['age'] < 30) & (customers['purchased'] == 1)]` | **Combines two conditions with AND.** Each condition is wrapped in parentheses. The `&` operator requires both conditions to be True. |\n\n**How Boolean Indexing Works:**\n```python\n# Step 1: Create boolean mask\nmask = customers['income'] > 70000\n# mask is: [False, True, False, True, ...]\n\n# Step 2: Use mask to filter\nresult = customers[mask]\n# Returns only rows where mask is True\n```\n\n**Logical Operators in Pandas:**\n| Operator | Meaning | Example |\n|----------|---------|---------|\n| `&` | AND | `(cond1) & (cond2)` |\n| `\\|` | OR | `(cond1) \\| (cond2)` |\n| `~` | NOT | `~(condition)` |\n\n**Common Pitfall:**\n```python\n# WRONG - Python keywords don't work\ndf[(df['a'] > 5) and (df['b'] < 10)]  # Error!\n\n# CORRECT - Use & with parentheses\ndf[(df['a'] > 5) & (df['b'] < 10)]\n```\n\n**Why filtering matters:**\n- Segment data for targeted analysis\n- Remove outliers or invalid records\n- Create subsets for training/testing in ML",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Filtering Data - Demonstration\n",
    "\n",
    "Filter rows using boolean conditions:\n",
    "- `df[df['column'] > value]` - Rows where column > value\n",
    "- `df[df['column'] == 'text']` - Rows where column equals text\n",
    "- `df[(cond1) & (cond2)]` - Multiple conditions with AND\n",
    "\n",
    "Run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter: age > 50\n",
    "older = customers[customers['age'] > 50]\n",
    "print(f\"Customers over 50: {len(older)}\")\n",
    "\n",
    "# Filter: region is 'West'\n",
    "west = customers[customers['region'] == 'West']\n",
    "print(f\"Customers in West: {len(west)}\")\n",
    "\n",
    "# Multiple conditions: age > 40 AND purchased\n",
    "older_buyers = customers[(customers['age'] > 40) & (customers['purchased'] == 1)]\n",
    "print(f\"Older buyers: {len(older_buyers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "\"\"\"\nExercise 2.3 Solution: Grouping and Aggregation\n\nThis solution demonstrates the split-apply-combine pattern:\n1. Split data into groups by a column\n2. Apply an aggregation function to each group\n3. Combine results into a new Series\n\"\"\"\n\n# Group by 'region', then calculate mean of 'income' column\n# Result is a Series with region as index and average income as values\navg_income_by_region = customers.groupby('region')['income'].mean()\n\n# Group by 'region', count customer_ids in each group\n# This gives the number of customers per region\ncount_by_region = customers.groupby('region')['customer_id'].count()\n\n# Group by 'region', calculate mean of 'purchased' (0 or 1)\n# Mean of binary values gives the proportion/rate\npurchase_rate = customers.groupby('region')['purchased'].mean()\n\nprint(\"Average income by region:\")\nprint(avg_income_by_region)\nprint(\"\\nCount by region:\")\nprint(count_by_region)\nprint(\"\\nPurchase rate by region:\")\nprint(purchase_rate)"
  },
  {
   "cell_type": "markdown",
   "source": "### Code Explanation: Exercise 2.3\n\n| Line | Code | Explanation |\n|------|------|-------------|\n| 1 | `avg_income_by_region = customers.groupby('region')['income'].mean()` | **Groups rows by region, then calculates mean income for each group.** This is the split-apply-combine pattern: split by region → apply mean → combine into Series. |\n| 2 | `count_by_region = customers.groupby('region')['customer_id'].count()` | **Counts customers in each region.** `.count()` returns the number of non-null values in each group. |\n| 3 | `purchase_rate = customers.groupby('region')['purchased'].mean()` | **Calculates purchase rate per region.** Since 'purchased' is 0 or 1, the mean gives the proportion who purchased (e.g., 0.4 = 40%). |\n\n**Understanding `groupby()` Step by Step:**\n```python\n# Step 1: Group the data\ngrouped = customers.groupby('region')\n# Creates GroupBy object (no computation yet)\n\n# Step 2: Select column to aggregate\ncolumn = grouped['income']\n# Specifies which column to calculate on\n\n# Step 3: Apply aggregation\nresult = column.mean()\n# Computes mean for each group\n```\n\n**Common Aggregation Functions:**\n| Function | Purpose |\n|----------|---------|\n| `.mean()` | Average value |\n| `.sum()` | Total |\n| `.count()` | Number of rows |\n| `.min()` / `.max()` | Extremes |\n| `.std()` | Standard deviation |\n| `.agg(['mean', 'sum'])` | Multiple aggregations |\n\n**Why the mean of binary data gives a rate:**\n```\npurchased = [1, 0, 1, 1, 0]\nmean = (1+0+1+1+0) / 5 = 3/5 = 0.6 = 60% purchase rate\n```\n\n**Why grouping matters:**\n- Compares metrics across segments (regions, demographics)\n- Essential for creating pivot tables and reports\n- Foundation for feature engineering in ML",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Income > 70000\n",
    "high_income = customers[customers['income'] > 70000]  # SOLUTION\n",
    "\n",
    "# Region is East\n",
    "east_region = customers[customers['region'] == 'East']  # SOLUTION\n",
    "\n",
    "# Young buyers (age < 30 and purchased)\n",
    "young_buyers = customers[(customers['age'] < 30) & (customers['purchased'] == 1)]  # SOLUTION\n",
    "\n",
    "print(\"High income count:\", len(high_income) if high_income is not None else None)\n",
    "print(\"East region count:\", len(east_region) if east_region is not None else None)\n",
    "print(\"Young buyers count:\", len(young_buyers) if young_buyers is not None else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Grouping Data - Demonstration\n",
    "\n",
    "Group data and calculate aggregates:\n",
    "- `df.groupby('column')['other'].mean()` - Average by group\n",
    "- `df.groupby('column')['other'].count()` - Count by group\n",
    "\n",
    "Run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average income by region\n",
    "print(\"Average income by region:\")\n",
    "print(customers.groupby('region')['income'].mean())\n",
    "\n",
    "# Count by region\n",
    "print(\"\\nCustomers per region:\")\n",
    "print(customers.groupby('region')['customer_id'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "\"\"\"\nExercise 3.1 Solution: Creating a Histogram\n\nThis solution creates a histogram to visualize the distribution\nof customer income values using Matplotlib.\n\"\"\"\n\n# Create a new figure with specified size (width=10, height=5 inches)\nplt.figure(figsize=(10, 5))\n\n# Create histogram of income data\n# bins=20: divide data range into 20 equal intervals\n# edgecolor='black': add black border around each bar\n# alpha=0.7: make bars 70% opaque (slight transparency)\nplt.hist(customers['income'], bins=20, edgecolor='black', alpha=0.7)\n\n# Add labels and title for clarity\nplt.xlabel('Income ($)')      # X-axis label\nplt.ylabel('Frequency')       # Y-axis label\nplt.title('Distribution of Customer Income')  # Chart title\n\n# Display the plot\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "source": "### Code Explanation: Exercise 3.1\n\n| Line | Code | Explanation |\n|------|------|-------------|\n| 1 | `plt.figure(figsize=(10, 5))` | **Creates a new figure canvas.** The tuple (10, 5) sets width and height in inches. Larger figures show more detail. |\n| 2 | `plt.hist(customers['income'], bins=20, ...)` | **Creates the histogram.** Divides income range into 20 bins and counts how many values fall in each bin. |\n| 3 | `edgecolor='black'` | **Adds black borders around bars.** Makes individual bars more visible, especially when colors are similar. |\n| 4 | `alpha=0.7` | **Sets transparency to 70%.** Values range 0 (invisible) to 1 (solid). Transparency helps when overlapping plots. |\n| 5 | `plt.xlabel('Income ($)')` | **Labels the X-axis.** Always include units (like $) for clarity. |\n| 6 | `plt.ylabel('Frequency')` | **Labels the Y-axis.** Frequency means \"count of occurrences\" in each bin. |\n| 7 | `plt.title(...)` | **Adds a title above the plot.** Describes what the visualization shows. |\n| 8 | `plt.show()` | **Renders and displays the plot.** Required in scripts; optional in Jupyter notebooks. |\n\n**Understanding Histogram Bins:**\n```\nIncome range: $20,000 - $80,000\nWith bins=20: each bin covers ($80,000 - $20,000) / 20 = $3,000\n\nBin 1: $20,000-$23,000 → count how many customers\nBin 2: $23,000-$26,000 → count how many customers\n... and so on\n```\n\n**Why histograms matter:**\n- Reveal the shape of data distribution (normal, skewed, bimodal)\n- Show where most values concentrate\n- Help identify outliers\n- Essential first step in exploratory data analysis (EDA)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average income by region\n",
    "avg_income_by_region = customers.groupby('region')['income'].mean()  # SOLUTION\n",
    "\n",
    "# Count by region\n",
    "count_by_region = customers.groupby('region')['customer_id'].count()  # SOLUTION\n",
    "\n",
    "# Purchase rate by region\n",
    "purchase_rate = customers.groupby('region')['purchased'].mean()  # SOLUTION\n",
    "\n",
    "print(\"Average income by region:\")\n",
    "print(avg_income_by_region)\n",
    "print(\"\\nCount by region:\")\n",
    "print(count_by_region)\n",
    "print(\"\\nPurchase rate by region:\")\n",
    "print(purchase_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 3: Data Visualization\n",
    "\n",
    "Matplotlib is the standard plotting library for Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "\"\"\"\nExercise 3.2 Solution: Creating a Scatter Plot\n\nThis solution creates a scatter plot to explore the relationship\nbetween customer tenure (years) and income.\n\"\"\"\n\n# Create figure with specified dimensions\nplt.figure(figsize=(10, 6))\n\n# Create scatter plot: each point represents one customer\n# x-axis: years as customer\n# y-axis: income\n# alpha=0.5: semi-transparent points reveal overlapping data\nplt.scatter(customers['years_customer'], customers['income'], alpha=0.5)\n\n# Add descriptive labels\nplt.xlabel('Years as Customer')\nplt.ylabel('Income ($)')\nplt.title('Customer Tenure vs Income')\n\n# Display the plot\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "source": "### Code Explanation: Exercise 3.2\n\n| Line | Code | Explanation |\n|------|------|-------------|\n| 1 | `plt.figure(figsize=(10, 6))` | **Creates a 10×6 inch figure.** Wider aspect ratio works well for scatter plots. |\n| 2 | `plt.scatter(x, y, alpha=0.5)` | **Plots each data point as a dot.** First argument is X values, second is Y values. Each customer becomes one point. |\n| 3 | `alpha=0.5` | **50% transparency.** When points overlap, darker areas show higher density. Essential for seeing patterns in crowded plots. |\n| 4 | `plt.xlabel(...)` / `plt.ylabel(...)` | **Label the axes.** Readers need to know what each axis represents. |\n\n**Interpreting Scatter Plots:**\n- **Positive correlation:** Points trend upward left-to-right\n- **Negative correlation:** Points trend downward left-to-right\n- **No correlation:** Points scattered randomly (like this example)\n- **Clusters:** Groups of points may indicate segments\n\n**Why scatter plots matter:**\n- Reveal relationships between two variables\n- Essential for detecting correlations before modeling\n- Help identify outliers (points far from the cluster)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(customers['age'], bins=15, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Customer Ages')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.1: Create a Histogram - SOLUTION\n",
    "\n",
    "Create a histogram of customer income. Add the following lines to the code cell below:\n",
    "\n",
    "```python\n",
    "plt.hist(customers['income'], bins=20, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Income ($)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Customer Income')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "\"\"\"\nExercise 3.3 Solution: Creating a Bar Chart\n\nThis solution creates a bar chart comparing purchase rates across regions.\nBar charts are ideal for comparing values across categories.\n\"\"\"\n\n# Create figure\nplt.figure(figsize=(8, 5))\n\n# First, calculate the purchase rate per region using groupby\n# Mean of binary 0/1 column gives the proportion (rate)\npurchase_rate = customers.groupby('region')['purchased'].mean()\n\n# Create bar chart from the Series\n# kind='bar': vertical bars (use 'barh' for horizontal)\n# color: fill color of bars\n# edgecolor: border color of bars\npurchase_rate.plot(kind='bar', color='green', edgecolor='black')\n\n# Add labels and title\nplt.xlabel('Region')\nplt.ylabel('Purchase Rate')\nplt.title('Purchase Rate by Region')\n\n# Rotate x-axis labels for readability (0 = horizontal)\nplt.xticks(rotation=0)\n\n# Display the plot\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "source": "### Code Explanation: Exercise 3.3\n\n| Line | Code | Explanation |\n|------|------|-------------|\n| 1 | `purchase_rate = customers.groupby('region')['purchased'].mean()` | **Calculates purchase rate per region.** Groups by region, then computes mean of the binary column. Result is a Series with regions as index. |\n| 2 | `purchase_rate.plot(kind='bar', ...)` | **Creates bar chart from Series.** Pandas Series have a built-in `.plot()` method. Index becomes x-axis labels, values become bar heights. |\n| 3 | `color='green'` | **Sets bar fill color.** Can use color names ('red', 'blue') or hex codes ('#FF5733'). |\n| 4 | `edgecolor='black'` | **Sets bar border color.** Adds definition to each bar. |\n| 5 | `plt.xticks(rotation=0)` | **Controls label rotation.** 0 = horizontal, 45 = diagonal, 90 = vertical. Adjust based on label length. |\n\n**Bar Chart vs Histogram:**\n| Bar Chart | Histogram |\n|-----------|-----------|\n| Categorical data | Continuous data |\n| Bars have gaps | Bars touch |\n| Compares groups | Shows distribution |\n| Example: Sales by region | Example: Age distribution |\n\n**Why bar charts matter:**\n- Best for comparing values across discrete categories\n- Height makes differences immediately visible\n- Commonly used in business reports and dashboards",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Scatter Plots - Demonstration\n",
    "\n",
    "Scatter plots show the relationship between two variables.\n",
    "\n",
    "Run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(customers['age'], customers['income'], alpha=0.5)\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Income ($)')\n",
    "plt.title('Age vs Income')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.2: Create a Scatter Plot - SOLUTION\n",
    "\n",
    "Create a scatter plot of `years_customer` vs `income`. Add the following lines:\n",
    "\n",
    "```python\n",
    "plt.scatter(customers['years_customer'], customers['income'], alpha=0.5)\n",
    "plt.xlabel('Years as Customer')\n",
    "plt.ylabel('Income ($)')\n",
    "plt.title('Customer Tenure vs Income')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "\"\"\"\nExercise 4.1 Solution: Normalization Function\n\nThis function scales array values to the range [0, 1] using min-max normalization.\nEssential for algorithms sensitive to feature scales (e.g., neural networks, KNN).\n\"\"\"\n\ndef normalize(arr):\n    \"\"\"\n    Normalize array values to range [0, 1].\n    \n    Formula: normalized = (x - min) / (max - min)\n    \n    Parameters:\n        arr: NumPy array of numeric values\n        \n    Returns:\n        NumPy array with values scaled to [0, 1]\n    \"\"\"\n    # Subtract minimum to shift range to start at 0\n    # Divide by (max - min) to scale range to [0, 1]\n    return (arr - arr.min()) / (arr.max() - arr.min())\n\n# Test the function\ntest_data = np.array([10, 20, 30, 40, 50])\nresult = normalize(test_data)\nprint(\"Input:\", test_data)\nprint(\"Output:\", result)\nprint(\"Expected: [0.   0.25 0.5  0.75 1.  ]\")"
  },
  {
   "cell_type": "markdown",
   "source": "### Code Explanation: Exercise 4.1\n\n| Line | Code | Explanation |\n|------|------|-------------|\n| 1 | `def normalize(arr):` | **Defines a reusable function.** Takes any NumPy array as input. |\n| 2 | `arr - arr.min()` | **Shifts values so minimum becomes 0.** If data is [10, 20, 30], after this: [0, 10, 20]. |\n| 3 | `arr.max() - arr.min()` | **Calculates the range.** This is the denominator that scales values to [0, 1]. |\n| 4 | `(arr - min) / (max - min)` | **Complete formula.** Numerator shifts to 0, denominator scales to 1. |\n\n**Step-by-Step Example:**\n```\nOriginal:    [10, 20, 30, 40, 50]\nmin = 10, max = 50, range = 40\n\nStep 1 (shift): [10-10, 20-10, 30-10, 40-10, 50-10] = [0, 10, 20, 30, 40]\nStep 2 (scale): [0/40, 10/40, 20/40, 30/40, 40/40] = [0, 0.25, 0.5, 0.75, 1.0]\n```\n\n**Properties of Normalized Data:**\n- Minimum value becomes exactly 0\n- Maximum value becomes exactly 1\n- All other values fall between 0 and 1\n- Preserves the relative distances between values\n\n**Why normalization matters:**\n- Many ML algorithms (neural networks, SVM, KNN) perform better when features are on similar scales\n- Prevents features with large values from dominating the model\n- Required for gradient-based optimization to converge properly",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Bar Charts - Demonstration\n",
    "\n",
    "Bar charts compare values across categories. Use `.plot(kind='bar')` on a Pandas Series.\n",
    "\n",
    "Run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_income = customers.groupby('region')['income'].mean()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "avg_income.plot(kind='bar', color='steelblue', edgecolor='black')\n",
    "plt.xlabel('Region')\n",
    "plt.ylabel('Average Income ($)')\n",
    "plt.title('Average Income by Region')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "\"\"\"\nExercise 4.2 Solution: Standardization Function\n\nThis function transforms data to have mean=0 and standard deviation=1 (z-score normalization).\nPreferred when data should follow a standard normal distribution.\n\"\"\"\n\ndef standardize(arr):\n    \"\"\"\n    Standardize array to mean=0, std=1.\n    \n    Formula: z = (x - mean) / std\n    \n    Parameters:\n        arr: NumPy array of numeric values\n        \n    Returns:\n        NumPy array with mean=0 and std=1\n    \"\"\"\n    # Subtract mean to center data around 0\n    # Divide by std to scale spread to 1\n    return (arr - arr.mean()) / arr.std()\n\n# Test the function\ntest_data = np.array([10, 20, 30, 40, 50])\nresult = standardize(test_data)\nprint(\"Input:\", test_data)\nprint(\"Output:\", result)\nif result is not None:\n    print(f\"Mean: {result.mean():.4f} (should be ~0)\")\n    print(f\"Std: {result.std():.4f} (should be ~1)\")"
  },
  {
   "cell_type": "markdown",
   "source": "### Code Explanation: Exercise 4.2\n\n| Line | Code | Explanation |\n|------|------|-------------|\n| 1 | `def standardize(arr):` | **Defines a function for z-score transformation.** |\n| 2 | `arr - arr.mean()` | **Centers data around 0.** After this, the mean of the result is 0. |\n| 3 | `arr.std()` | **Calculates standard deviation.** Measures the spread of data. |\n| 4 | `(arr - mean) / std` | **Complete z-score formula.** Each value becomes \"how many standard deviations from the mean.\" |\n\n**Step-by-Step Example:**\n```\nOriginal:    [10, 20, 30, 40, 50]\nmean = 30, std = 14.14\n\nStep 1 (center): [10-30, 20-30, 30-30, 40-30, 50-30] = [-20, -10, 0, 10, 20]\nStep 2 (scale):  [-20/14.14, -10/14.14, 0/14.14, 10/14.14, 20/14.14]\n                = [-1.41, -0.71, 0, 0.71, 1.41]\n```\n\n**Interpreting Z-Scores:**\n- z = 0: Value equals the mean\n- z = 1: Value is 1 standard deviation above mean\n- z = -2: Value is 2 standard deviations below mean\n- |z| > 3: Often considered an outlier\n\n**Standardization vs Normalization:**\n| Standardization | Normalization |\n|-----------------|---------------|\n| Mean=0, Std=1 | Range [0, 1] |\n| No fixed range | Fixed range |\n| Good for Gaussian data | Good for bounded data |\n| Used in linear models | Used in neural networks |\n\n**Why standardization matters:**\n- Required for algorithms that assume normally distributed features\n- Makes different features comparable (e.g., age in years vs income in dollars)\n- Helps with numerical stability in optimization",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# SOLUTION:\n",
    "purchase_rate = customers.groupby('region')['purchased'].mean()\n",
    "purchase_rate.plot(kind='bar', color='green', edgecolor='black')\n",
    "plt.xlabel('Region')\n",
    "plt.ylabel('Purchase Rate')\n",
    "plt.title('Purchase Rate by Region')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 4: Data Preprocessing\n",
    "\n",
    "Before using data in machine learning, we often need to preprocess it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "\"\"\"\nExercise 4.3 Solution: One-Hot Encoding\n\nThis solution converts categorical 'region' column into binary indicator columns.\nRequired for ML algorithms that cannot handle text categories directly.\n\"\"\"\n\nprint(\"Original columns:\", list(customers.columns))\n\n# pd.get_dummies() converts categorical columns to binary columns\n# columns=['region'] specifies which column(s) to encode\n# Original 'region' column is removed and replaced with:\n# region_East, region_North, region_South, region_West\ncustomers_encoded = pd.get_dummies(customers, columns=['region'])\n\nif customers_encoded is not None:\n    print(\"\\nNew columns:\", list(customers_encoded.columns))\n    print(\"\\nFirst 3 rows:\")\n    print(customers_encoded.head(3))"
  },
  {
   "cell_type": "markdown",
   "source": "### Code Explanation: Exercise 4.3\n\n| Line | Code | Explanation |\n|------|------|-------------|\n| 1 | `pd.get_dummies(customers, columns=['region'])` | **Converts 'region' to binary columns.** Each unique value becomes a new column with 0/1 values. |\n\n**Before and After One-Hot Encoding:**\n```\nBEFORE (categorical):\n| region  |\n|---------|\n| North   |\n| East    |\n| South   |\n\nAFTER (one-hot encoded):\n| region_East | region_North | region_South | region_West |\n|-------------|--------------|--------------|-------------|\n| 0           | 1            | 0            | 0           |\n| 1           | 0            | 0            | 0           |\n| 0           | 0            | 1            | 0           |\n```\n\n**Key Features of get_dummies():**\n- Original column is removed automatically\n- New columns named `originalname_value`\n- Exactly one column is 1 per row (mutually exclusive)\n- Creates k columns for k categories\n\n**The \"Dummy Variable Trap\":**\nWhen using one-hot encoding in regression:\n- k categories create k columns\n- Only k-1 are needed (the last is implied)\n- Use `drop_first=True` to avoid multicollinearity:\n  ```python\n  pd.get_dummies(df, columns=['region'], drop_first=True)\n  ```\n\n**Why one-hot encoding matters:**\n- Most ML algorithms require numeric input\n- Text categories have no mathematical meaning (North < South makes no sense)\n- Creates a representation where each category is equidistant\n- Essential preprocessing step for classification and regression",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([10, 20, 30, 40, 50])\n",
    "print(\"Original:\", data)\n",
    "\n",
    "normalized = (data - data.min()) / (data.max() - data.min())\n",
    "print(\"Normalized:\", normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.1: Write a Normalize Function - SOLUTION\n",
    "\n",
    "Complete the `normalize` function below. Replace the `return None` line with:\n",
    "\n",
    "```python\n",
    "return (arr - arr.min()) / (arr.max() - arr.min())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(arr):\n",
    "    \"\"\"Normalize array to [0, 1] range\"\"\"\n",
    "    return (arr - arr.min()) / (arr.max() - arr.min())  # SOLUTION\n",
    "\n",
    "# Test\n",
    "test_data = np.array([10, 20, 30, 40, 50])\n",
    "result = normalize(test_data)\n",
    "print(\"Input:\", test_data)\n",
    "print(\"Output:\", result)\n",
    "print(\"Expected: [0.   0.25 0.5  0.75 1.  ]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Standardization - Demonstration\n",
    "\n",
    "Standardization centers data around 0 with standard deviation of 1:\n",
    "\n",
    "```\n",
    "standardized = (x - mean) / std\n",
    "```\n",
    "\n",
    "Run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([10, 20, 30, 40, 50])\n",
    "print(\"Original:\", data)\n",
    "print(\"Mean:\", data.mean(), \"Std:\", data.std())\n",
    "\n",
    "standardized = (data - data.mean()) / data.std()\n",
    "print(\"\\nStandardized:\", standardized)\n",
    "print(\"New mean:\", standardized.mean().round(10))\n",
    "print(\"New std:\", standardized.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.2: Write a Standardize Function - SOLUTION\n",
    "\n",
    "Complete the `standardize` function below. Replace the `return None` line with:\n",
    "\n",
    "```python\n",
    "return (arr - arr.mean()) / arr.std()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(arr):\n",
    "    \"\"\"Standardize array to mean=0, std=1\"\"\"\n",
    "    return (arr - arr.mean()) / arr.std()  # SOLUTION\n",
    "\n",
    "# Test\n",
    "test_data = np.array([10, 20, 30, 40, 50])\n",
    "result = standardize(test_data)\n",
    "print(\"Input:\", test_data)\n",
    "print(\"Output:\", result)\n",
    "if result is not None:\n",
    "    print(f\"Mean: {result.mean():.4f} (should be ~0)\")\n",
    "    print(f\"Std: {result.std():.4f} (should be ~1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 One-Hot Encoding - Demonstration\n",
    "\n",
    "One-hot encoding converts categorical variables to binary columns.\n",
    "\n",
    "Use `pd.get_dummies(df, columns=['column_name'])`\n",
    "\n",
    "Run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.DataFrame({\n",
    "    'name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'city': ['NYC', 'LA', 'NYC']\n",
    "})\n",
    "print(\"Before:\")\n",
    "print(sample)\n",
    "\n",
    "encoded = pd.get_dummies(sample, columns=['city'])\n",
    "print(\"\\nAfter one-hot encoding:\")\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.3: One-Hot Encode the Customer Data - SOLUTION\n",
    "\n",
    "One-hot encode the `region` column in the customers DataFrame. Replace `None` with:\n",
    "\n",
    "```python\n",
    "pd.get_dummies(customers, columns=['region'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original columns:\", list(customers.columns))\n",
    "\n",
    "# One-hot encode the region column\n",
    "customers_encoded = pd.get_dummies(customers, columns=['region'])  # SOLUTION\n",
    "\n",
    "if customers_encoded is not None:\n",
    "    print(\"\\nNew columns:\", list(customers_encoded.columns))\n",
    "    print(\"\\nFirst 3 rows:\")\n",
    "    print(customers_encoded.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Lab Complete!\n",
    "\n",
    "## Summary\n",
    "\n",
    "You learned:\n",
    "- **NumPy**: Create arrays, calculate statistics, reshape, slice\n",
    "- **Pandas**: Create DataFrames, filter, group, aggregate\n",
    "- **Matplotlib**: Histograms, scatter plots, bar charts\n",
    "- **Preprocessing**: Normalize, standardize, one-hot encode\n",
    "\n",
    "## Quick Reference\n",
    "\n",
    "```python\n",
    "# NumPy\n",
    "np.array([1,2,3])       # Create array\n",
    "np.zeros((3,4))         # 3x4 zeros\n",
    "np.mean(arr)            # Average\n",
    "arr.reshape(2,3)        # Reshape\n",
    "\n",
    "# Pandas\n",
    "df['col'].mean()        # Column average\n",
    "df[df['col'] > 5]       # Filter\n",
    "df.groupby('a')['b'].mean()  # Group\n",
    "\n",
    "# Matplotlib\n",
    "plt.hist(data)          # Histogram\n",
    "plt.scatter(x, y)       # Scatter\n",
    "series.plot(kind='bar') # Bar chart\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}