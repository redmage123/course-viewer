# Video Scripts and Storyboards

A collection of video scripts for key concepts in the Enterprise AI Adoption course. These scripts are designed for 3-5 minute explainer videos.

---

## Table of Contents

1. [Video 1: Automate vs. Redesign - The Mindset Shift](#video-1-automate-vs-redesign)
2. [Video 2: The Five AI Role Types](#video-2-five-ai-role-types)
3. [Video 3: Oversight Models Explained](#video-3-oversight-models)
4. [Video 4: The AI Readiness Canvas](#video-4-ai-readiness-canvas)
5. [Video 5: Building Your AI Governance Framework](#video-5-governance-framework)
6. [Video 6: Before and After - Workflow Mapping](#video-6-workflow-mapping)
7. [Video 7: The 30-60-90 Day Rollout](#video-7-rollout-plan)
8. [Video 8: When AI Goes Wrong - Learning from Failures](#video-8-learning-from-failures)

---

# Video 1: Automate vs. Redesign

## Metadata
- **Duration:** 4 minutes
- **Style:** Animated explainer with voiceover
- **Target Audience:** All course participants
- **Learning Objective:** Understand the difference between automation and AI-native redesign

## Script

### Opening (0:00-0:30)

**[VISUAL: Split screen - left shows robot arm doing repetitive task, right shows question mark]**

**NARRATOR:** When most people hear "AI," they immediately think about automation—taking what we do today and having machines do it instead. But that's only half the story, and honestly? It's the less interesting half.

**[VISUAL: Transform to single screen with title "Automate vs. Redesign"]**

**NARRATOR:** In this video, we'll explore the difference between simply automating existing work and completely reimagining how work should be done in an AI-powered world.

---

### Section 1: The Automation Trap (0:30-1:30)

**[VISUAL: Animated workflow diagram - paper documents flowing through conveyor belt]**

**NARRATOR:** Let's say your team processes expense reports. The current workflow looks like this: employees fill out forms, managers review and approve, finance team enters data into the system, and eventually, employees get reimbursed.

**[VISUAL: Robot overlaid on the diagram, scanning documents]**

**NARRATOR:** The automation mindset says: "Let's add AI to scan the receipts and auto-fill the forms!" And sure, that saves some time.

**[VISUAL: Workflow still has same number of steps, just faster]**

**NARRATOR:** But notice something? The workflow is exactly the same. Same steps, same handoffs, same waiting. We've just made each step a little faster.

**[VISUAL: Magnifying glass revealing "The Automation Trap" label]**

**NARRATOR:** This is what we call the automation trap—using new technology to optimize old processes.

---

### Section 2: The Redesign Opportunity (1:30-2:30)

**[VISUAL: Screen clears, fresh canvas appears]**

**NARRATOR:** Now let's try something different. Instead of asking "How do we automate this workflow?" let's ask a better question:

**[VISUAL: Text appears: "What outcome are we actually trying to achieve?"]**

**NARRATOR:** "What outcome are we actually trying to achieve?"

**[VISUAL: Simple answer appears: "Employees get reimbursed fairly and quickly"]**

**NARRATOR:** For expense reports, the outcome is simple: employees get reimbursed fairly and quickly for legitimate business expenses.

**[VISUAL: New streamlined workflow appears - employee takes photo, AI processes, money appears in account]**

**NARRATOR:** With that outcome in mind, what if we redesigned from scratch? Employee takes a photo of a receipt. AI reads it, categorizes it, checks it against policy, and—if everything looks right—initiates the reimbursement immediately. No forms. No waiting for approvals. No data entry.

**[VISUAL: Side-by-side comparison - old complex workflow vs. new simple workflow]**

**NARRATOR:** The manager? They now review a weekly summary of all expenses, flagging anything that needs attention. Same oversight, but batched and intelligent instead of one-by-one.

---

### Section 3: The Key Question (2:30-3:15)

**[VISUAL: Thought bubble with lightbulb]**

**NARRATOR:** Here's the key insight: Automation asks "How do we do this faster?" Redesign asks "Should we be doing this at all?"

**[VISUAL: Two doors labeled "Automate" and "Redesign"]**

**NARRATOR:** Every workflow you look at, you have a choice. Door one: automate the existing process. Door two: redesign around the outcome.

**[VISUAL: Door two opens to reveal transformed landscape]**

**NARRATOR:** Door two is harder. It requires challenging assumptions, questioning why things are done a certain way, and sometimes having uncomfortable conversations. But it's where the real value lives.

---

### Section 4: Your Challenge (3:15-3:45)

**[VISUAL: Notepad with pen]**

**NARRATOR:** Here's your challenge: Think of a workflow you deal with regularly. Write down the outcome it's supposed to achieve. Then ask yourself: If I were building this from scratch today, with AI as a tool, would it look anything like what we have now?

**[VISUAL: Text appears: "If the answer is 'no,' you've found a redesign opportunity."]**

**NARRATOR:** If the answer is "no," you've found a redesign opportunity.

---

### Closing (3:45-4:00)

**[VISUAL: Course logo and next video teaser]**

**NARRATOR:** In the next video, we'll explore the five different roles AI can play in your workflows—from analyzer to generator. See you there.

**[END CARD with course branding]**

---

# Video 2: Five AI Role Types

## Metadata
- **Duration:** 5 minutes
- **Style:** Animated icons with real-world examples
- **Target Audience:** All course participants
- **Learning Objective:** Identify and apply the five AI role types

## Script

### Opening (0:00-0:25)

**[VISUAL: Five mystery boxes on screen]**

**NARRATOR:** Not all AI does the same thing. In fact, when we look at how AI is actually used in business today, we can identify five distinct role types—five different jobs that AI can do alongside humans.

**[VISUAL: Boxes open to reveal icons for each role]**

**NARRATOR:** Understanding these roles will help you design better workflows and choose the right oversight model for each AI application.

---

### Role 1: The Analyzer (0:25-1:15)

**[VISUAL: Magnifying glass icon, transforms into data analysis scene]**

**NARRATOR:** First up: the Analyzer. This is AI that examines information to find patterns, anomalies, or insights that humans might miss.

**[VISUAL: Examples appearing as icons - fraud detection, medical imaging, sentiment analysis]**

**NARRATOR:** Think fraud detection scanning thousands of transactions per second. Or medical imaging AI that highlights areas of concern on an X-ray. Or sentiment analysis that tells you how customers feel about your latest product launch.

**[VISUAL: Human figure receiving insights from AI]**

**NARRATOR:** The Analyzer doesn't make decisions—it surfaces information so humans can make better decisions faster.

**[VISUAL: Key text: "Analyzer = Find patterns, surface insights"]**

---

### Role 2: The Generator (1:15-2:05)

**[VISUAL: Paintbrush/creation icon, transforms into content creation scene]**

**NARRATOR:** Role two: the Generator. This is AI that creates new content—text, images, code, designs, music, you name it.

**[VISUAL: Examples - draft email appearing, code being written, image being generated]**

**NARRATOR:** Need a first draft of that quarterly report? A Generator can create it. Want variations of your ad copy to test? A Generator produces ten options in seconds. Need boilerplate code for a common function? Generated.

**[VISUAL: Human figure editing AI output]**

**NARRATOR:** The key word here is "draft." Generators create starting points that humans refine, not finished products.

**[VISUAL: Key text: "Generator = Create drafts, starting points"]**

---

### Role 3: The Recommender (2:05-2:55)

**[VISUAL: Signpost icon with multiple directions, transforms into recommendation scene]**

**NARRATOR:** Role three: the Recommender. This AI analyzes a situation and suggests a course of action.

**[VISUAL: Examples - next best action in sales, treatment recommendations, product suggestions]**

**NARRATOR:** A Recommender might tell a sales rep which customer to call next. It might suggest a treatment plan based on patient symptoms. Or it might recommend which products to reorder before they run out.

**[VISUAL: Human figure considering AI suggestion, then choosing]**

**NARRATOR:** Unlike the Analyzer, which just presents information, the Recommender goes a step further and says "here's what I think you should do." But the human still decides.

**[VISUAL: Key text: "Recommender = Suggest actions, inform choices"]**

---

### Role 4: The Validator (2:55-3:45)

**[VISUAL: Checkmark/shield icon, transforms into verification scene]**

**NARRATOR:** Role four: the Validator. This is AI that checks work for accuracy, compliance, or quality.

**[VISUAL: Examples - code review, document compliance check, data quality validation]**

**NARRATOR:** A Validator might review code for security vulnerabilities. It might check contracts against company policies. Or it might validate data entry for errors before it hits your database.

**[VISUAL: Quality gate with AI as checkpoint]**

**NARRATOR:** Think of Validators as quality gates—they catch problems before they cause harm.

**[VISUAL: Key text: "Validator = Check, verify, catch errors"]**

---

### Role 5: The Router (3:45-4:25)

**[VISUAL: Traffic controller icon, transforms into triage scene]**

**NARRATOR:** Finally, role five: the Router. This is AI that triages, categorizes, and directs work to the right place.

**[VISUAL: Examples - support ticket routing, lead scoring, email sorting]**

**NARRATOR:** A Router might categorize support tickets and send them to the right specialist team. It might score incoming leads and prioritize them for sales. Or it might sort your inbox by importance.

**[VISUAL: Work items flowing through router to different destinations]**

**NARRATOR:** Routers don't do the work themselves—they make sure work gets to whoever or whatever can handle it best.

**[VISUAL: Key text: "Router = Triage, categorize, direct"]**

---

### Putting It Together (4:25-4:50)

**[VISUAL: All five icons arranged in workflow]**

**NARRATOR:** In practice, you'll often combine multiple AI roles in a single workflow. A customer inquiry comes in, gets Routed to the right team, Analyzed for sentiment, a response is Generated as a draft, the agent adds their personal touch, and a Validator checks it meets quality standards before sending.

**[VISUAL: Workflow animation showing all five roles in action]**

**NARRATOR:** Five roles, working together, each doing what it does best.

---

### Closing (4:50-5:00)

**[VISUAL: Reflection prompt]**

**NARRATOR:** Your turn: Which of these roles could help your workflows most? Think about it, and we'll explore oversight models in the next video.

**[END CARD]**

---

# Video 3: Oversight Models Explained

## Metadata
- **Duration:** 4:30 minutes
- **Style:** Animated diagrams with scenario examples
- **Target Audience:** All course participants
- **Learning Objective:** Understand HITL, HOTL, and HOOTL oversight models

## Script

### Opening (0:00-0:30)

**[VISUAL: Human and robot figures side by side]**

**NARRATOR:** One of the most important decisions you'll make when deploying AI is: How much human oversight does it need?

**[VISUAL: Spectrum appears - full control on left, full autonomy on right]**

**NARRATOR:** Get this wrong, and you either create bottlenecks that defeat the purpose of AI, or you take on risks that could blow up in your face. Let's explore three oversight models that help you find the right balance.

---

### Model 1: Human-in-the-Loop (0:30-1:30)

**[VISUAL: Loop diagram with human in the center, AI feeding info to human]**

**NARRATOR:** Model one: Human-in-the-Loop, or HITL. In this model, a human reviews and approves every AI decision before it takes effect.

**[VISUAL: Example - loan application flow with human approval checkpoint]**

**NARRATOR:** Example: An AI reviews loan applications and recommends approve or deny. But a loan officer must sign off on every single decision. The AI does the analysis, the human makes the call.

**[VISUAL: Pros and cons appearing]**

**NARRATOR:** HITL provides maximum safety. Every decision has human judgment applied. But it can be slow, and you're limited by human capacity.

**[VISUAL: "When to use" checklist]**

**NARRATOR:** Use HITL when the stakes are high, when you're just starting with a new AI system, or when regulations require human accountability for every decision.

---

### Model 2: Human-on-the-Loop (1:30-2:30)

**[VISUAL: Loop diagram with human monitoring from above, AI operating, alert lines connecting]**

**NARRATOR:** Model two: Human-on-the-Loop, or HOTL. Here, AI operates independently, but humans monitor the outputs and can intervene when needed.

**[VISUAL: Example - content moderation with human reviewing flagged items]**

**NARRATOR:** Example: An AI moderates social media comments, automatically removing obvious spam. Borderline cases get flagged for human review. Humans also sample random decisions to check accuracy.

**[VISUAL: Dashboard showing AI activity with human monitoring]**

**NARRATOR:** HOTL gives you speed—AI handles the volume—while humans focus on exceptions and quality control.

**[VISUAL: "When to use" checklist]**

**NARRATOR:** Use HOTL when you have high volume that can't be reviewed one-by-one, when mistakes are recoverable, and when you trust your AI's accuracy for routine cases.

---

### Model 3: Human-out-of-the-Loop (2:30-3:15)

**[VISUAL: AI operating autonomously, human figure distant but with "override" button]**

**NARRATOR:** Model three: Human-out-of-the-Loop, or HOOTL. AI operates fully autonomously within defined boundaries. Humans set the rules, but don't review individual decisions.

**[VISUAL: Example - automated trading within risk parameters]**

**NARRATOR:** Example: An algorithmic trading system executes trades within pre-set risk parameters. No human approves each trade—that would defeat the purpose. But if risk thresholds are breached, the system stops and alerts humans.

**[VISUAL: Fence/boundary visual with AI operating freely inside]**

**NARRATOR:** HOOTL only works when you can define clear boundaries, have extensive testing, and when the downside of any single error is contained.

**[VISUAL: Warning sign]**

**NARRATOR:** And a crucial point: even with HOOTL, humans must be able to intervene if something goes wrong. Autonomous doesn't mean unaccountable.

---

### Choosing the Right Model (3:15-4:00)

**[VISUAL: Decision matrix appearing]**

**NARRATOR:** So how do you choose? Consider three factors:

**[VISUAL: Factor 1 - Stakes icon]**

**NARRATOR:** First, what's the consequence of an error? The higher the stakes, the more oversight you need.

**[VISUAL: Factor 2 - Volume icon]**

**NARRATOR:** Second, what's the volume? Human-in-the-loop doesn't scale infinitely. If you're processing thousands of decisions per hour, you need to be selective about what gets human review.

**[VISUAL: Factor 3 - Maturity icon]**

**NARRATOR:** Third, how mature is the AI? New systems need more oversight. As you build confidence, you can relax controls.

**[VISUAL: Arrow showing progression over time from HITL to HOTL to HOOTL]**

**NARRATOR:** Many organizations start with HITL, move to HOTL as they build trust, and only reach HOOTL for very specific, well-understood applications.

---

### Closing (4:00-4:30)

**[VISUAL: Three models side by side for comparison]**

**NARRATOR:** Remember: these models aren't permanent choices. They're settings you can adjust. Start with more oversight than you think you need. It's much easier to loosen controls than to recover from a disaster.

**[VISUAL: Reflection prompt]**

**NARRATOR:** Think about a workflow you're considering for AI. Which oversight model fits? What would need to change to move to a less restrictive model over time?

**[END CARD]**

---

# Video 4: AI Readiness Canvas

## Metadata
- **Duration:** 4 minutes
- **Style:** Template walkthrough with assessment guidance
- **Target Audience:** All course participants
- **Learning Objective:** Use the AI Readiness Canvas to assess organizational readiness

## Script

### Opening (0:00-0:25)

**[VISUAL: AI Readiness Canvas template appearing]**

**NARRATOR:** Before you can successfully deploy AI, you need to understand where your organization stands today. That's where the AI Readiness Canvas comes in—a structured way to assess your starting point and identify what needs to improve.

---

### The Five Dimensions (0:25-3:00)

**[VISUAL: Canvas with five sections highlighted one by one]**

**NARRATOR:** The canvas evaluates readiness across five dimensions. Let's walk through each one.

**[VISUAL: Dimension 1 - Data Access highlighted]**

**NARRATOR:** First: Data Access. AI needs data to learn from and operate on. Ask yourself: Is your data digitized? Can systems access it through APIs? Is it accurate and complete? If your data is trapped in PDFs, spreadsheets, or people's heads, that's a barrier.

**[VISUAL: Rating scale 1-5]**

**NARRATOR:** Rate yourself 1 to 5. A "1" means data is mostly analog and inaccessible. A "5" means data is digital, connected, and high quality.

**[VISUAL: Dimension 2 - Decision Speed highlighted]**

**NARRATOR:** Dimension two: Decision Speed. How quickly can decisions be made? Are there layers of approval that slow everything down? AI can produce recommendations instantly, but if they sit in an approval queue for two weeks, you've lost the benefit.

**[VISUAL: Dimension 3 - Risk Tolerance highlighted]**

**NARRATOR:** Dimension three: Risk Tolerance. Is your organization willing to experiment? How does it treat failure—as learning or as blame? Organizations with zero tolerance for error will struggle with AI, because AI will make mistakes, especially early on.

**[VISUAL: Dimension 4 - Tech Integration highlighted]**

**NARRATOR:** Dimension four: Technical Integration. Can your existing systems connect with AI tools? Do you have the infrastructure—cloud, computing power, security—to support AI workloads? Or is your IT environment a patchwork that resists change?

**[VISUAL: Dimension 5 - Employee Readiness highlighted]**

**NARRATOR:** And dimension five: Employee Readiness. Do your people understand what AI can and can't do? Are they open to working alongside AI, or fearful of it? Do you have champions who can help drive adoption?

---

### Using Your Results (3:00-3:40)

**[VISUAL: Completed canvas with varying scores]**

**NARRATOR:** Once you've assessed all five dimensions, you'll see a profile. Maybe your data is great but your risk tolerance is low. Maybe your employees are ready but your technology isn't.

**[VISUAL: Radar chart showing readiness profile]**

**NARRATOR:** This tells you where to focus. Low scores aren't failures—they're priorities. If employee readiness is low, invest in training before you launch. If data access is poor, that's your first project.

**[VISUAL: Action planning]**

**NARRATOR:** The canvas also helps you set realistic expectations. An organization with lots of 2s and 3s shouldn't expect to deploy advanced AI next month. Start with the fundamentals.

---

### Closing (3:40-4:00)

**[VISUAL: Download prompt for canvas template]**

**NARRATOR:** Your assignment: Complete the AI Readiness Canvas for your team or department. Be honest—this isn't a test, it's a tool. Then identify one dimension to improve before your next AI initiative.

**[END CARD]**

---

# Video 5: Building Your AI Governance Framework

## Metadata
- **Duration:** 4:30 minutes
- **Style:** Animated framework building with examples
- **Target Audience:** All course participants
- **Learning Objective:** Design an AI governance framework using the Governance Canvas

## Script

### Opening (0:00-0:30)

**[VISUAL: News headlines about AI failures]**

**NARRATOR:** AI projects fail for many reasons, but one stands out: lack of governance. No clear accountability, no defined escalation paths, no one thinking about what could go wrong until it already has.

**[VISUAL: Governance Canvas template]**

**NARRATOR:** The Governance Canvas is your framework for thinking through these issues before you deploy, not after.

---

### Section 1: Risk Dimensions (0:30-1:30)

**[VISUAL: Five risk categories appearing]**

**NARRATOR:** The canvas starts with risk assessment across five dimensions.

**[VISUAL: Data Risk icon]**

**NARRATOR:** Data Risk: What if your data is wrong, biased, or breached?

**[VISUAL: Model Risk icon]**

**NARRATOR:** Model Risk: What if the AI makes incorrect predictions or behaves unexpectedly?

**[VISUAL: Operational Risk icon]**

**NARRATOR:** Operational Risk: What if the system goes down or can't handle the load?

**[VISUAL: Security Risk icon]**

**NARRATOR:** Security Risk: What if someone manipulates the AI or accesses data they shouldn't?

**[VISUAL: Reputational Risk icon]**

**NARRATOR:** And Reputational Risk: What if customers or the public react badly?

**[VISUAL: Rating matrix]**

**NARRATOR:** For each dimension, rate the likelihood and impact. High-risk areas need stronger controls.

---

### Section 2: Oversight and Escalation (1:30-2:30)

**[VISUAL: Oversight model selection]**

**NARRATOR:** Next, choose your oversight model based on your risk assessment. Higher risk? More oversight. But also consider volume and practicality.

**[VISUAL: Escalation path diagram]**

**NARRATOR:** Then define escalation triggers. What conditions cause AI to stop and ask for human help? Maybe it's low confidence, maybe it's unusual patterns, maybe it's specific types of requests.

**[VISUAL: Escalation examples]**

**NARRATOR:** Example triggers: Confidence score below 80%. Request involves an amount over $10,000. Customer expresses frustration. These are your safety valves.

**[VISUAL: Override authority chart]**

**NARRATOR:** Also document who has authority to override AI decisions, and what documentation they need to provide. Clear authority prevents paralysis when things go wrong.

---

### Section 3: Monitoring and Response (2:30-3:30)

**[VISUAL: Dashboard metrics]**

**NARRATOR:** Governance isn't just about the rules—it's about watching to ensure they're working.

**[VISUAL: Key metrics appearing]**

**NARRATOR:** Define what you'll monitor. Accuracy rates. Error rates. Override frequency. Fairness metrics across different groups. Response times. Usage patterns.

**[VISUAL: Alert thresholds]**

**NARRATOR:** Set thresholds that trigger alerts. If accuracy drops below 90%, you want to know immediately, not in next month's report.

**[VISUAL: Incident response flowchart]**

**NARRATOR:** Finally, plan your incident response. Who gets called when something goes wrong? What's the process for investigating and fixing issues? What do you tell affected customers?

**[VISUAL: Post-incident review]**

**NARRATOR:** And always: post-incident reviews. Every failure is data. Learn from it.

---

### Section 4: Documentation and Review (3:30-4:15)

**[VISUAL: Governance document]**

**NARRATOR:** Document everything. The Governance Canvas becomes a living document that evolves as you learn.

**[VISUAL: Review calendar]**

**NARRATOR:** Set a regular review cadence. Monthly check on metrics. Quarterly governance reviews. Annual full assessment. AI systems drift over time—your governance needs to keep up.

**[VISUAL: Approval signatures]**

**NARRATOR:** Get sign-off from all relevant stakeholders: business, technical, legal, compliance, security. If everyone's fingerprints are on the governance framework, everyone owns its success.

---

### Closing (4:15-4:30)

**[VISUAL: Canvas template and worksheet]**

**NARRATOR:** Good governance isn't bureaucracy—it's the foundation that lets you move faster with confidence. Complete the Governance Canvas for your AI initiative, and you'll sleep better at night.

**[END CARD]**

---

# Video 6: Before and After - Workflow Mapping

## Metadata
- **Duration:** 5 minutes
- **Style:** Step-by-step animated workflow transformation
- **Target Audience:** All course participants
- **Learning Objective:** Map current and future state workflows with AI integration

## Script

### Opening (0:00-0:30)

**[VISUAL: Messy workflow diagram]**

**NARRATOR:** Every successful AI implementation starts with understanding where you are and clearly envisioning where you want to be. That's what workflow mapping does—it takes the invisible work of your organization and makes it visible.

**[VISUAL: Before and After split screen]**

**NARRATOR:** Let's walk through the process together.

---

### Step 1: Current State Mapping (0:30-1:45)

**[VISUAL: Blank canvas, trigger event appearing]**

**NARRATOR:** Start with the trigger. What event kicks off this workflow? A customer email? A form submission? A clock hitting a deadline?

**[VISUAL: Steps appearing one by one, color-coded blue for human]**

**NARRATOR:** Then map each step. Be specific. Not just "review the request" but "team lead reviews request for completeness, checks against policy, and assigns to specialist."

**[VISUAL: Decision points appearing in yellow]**

**NARRATOR:** Mark decision points. Where does the workflow branch? What determines which path is taken?

**[VISUAL: Pain points appearing in red]**

**NARRATOR:** Now, and this is crucial, mark the pain points. Where do things get stuck? Where do errors happen? Where do people complain?

**[VISUAL: Completed current state map with time annotations]**

**NARRATOR:** Finally, add timing. How long does each step take? How long between steps? You might be surprised how much time is just... waiting.

---

### Step 2: Analysis (1:45-2:30)

**[VISUAL: Magnifying glass moving across workflow]**

**NARRATOR:** With your current state mapped, analyze it. For each step, ask: Why does this step exist? What would happen if we skipped it?

**[VISUAL: Opportunities highlighted]**

**NARRATOR:** Look for AI opportunities. Repetitive tasks? Prime for automation. Data extraction? AI can help. Decision points with clear criteria? AI can recommend or even decide.

**[VISUAL: Human judgment bubbles]**

**NARRATOR:** But also identify where human judgment is truly essential. Not where it's always been done by humans—where human judgment actually adds value that AI can't replicate.

---

### Step 3: Future State Design (2:30-3:45)

**[VISUAL: Clear canvas, outcome statement at top]**

**NARRATOR:** Now forget your current workflow. Seriously. Start with the outcome. Write it at the top: "Customer receives accurate answer within 24 hours." That's your north star.

**[VISUAL: New workflow building from scratch]**

**NARRATOR:** Design backward from the outcome. What's the shortest path to get there? If AI can do something reliably, let it. If humans add essential value, include them.

**[VISUAL: Green steps for AI, Blue for human, hybrid purple]**

**NARRATOR:** Color code: green for AI tasks, blue for human tasks. You should see a mix. Pure green means you've probably cut too many corners. Pure blue means you're not leveraging AI.

**[VISUAL: Oversight checkpoints added]**

**NARRATOR:** Add oversight checkpoints based on your risk assessment. High-risk workflow? More checkpoints. Well-understood, low-stakes workflow? Fewer.

---

### Step 4: Gap Analysis (3:45-4:30)

**[VISUAL: Side-by-side comparison of current and future]**

**NARRATOR:** Compare your maps. What has to change? What data does AI need that you don't currently have? What systems need to integrate? What training do people need?

**[VISUAL: Gap list appearing]**

**NARRATOR:** Build your gap list. This becomes your implementation roadmap. Some gaps are quick wins—just connect two systems. Others are bigger projects.

**[VISUAL: Priority matrix]**

**NARRATOR:** Prioritize based on impact and effort. Start with high-impact, low-effort changes. Build momentum before tackling the hard stuff.

---

### Closing (4:30-5:00)

**[VISUAL: Both workflows animated side-by-side]**

**NARRATOR:** A good before-and-after map does three things: It shows stakeholders exactly what you're proposing. It identifies implementation requirements. And it gives you a benchmark to measure improvement against.

**[VISUAL: Template download prompt]**

**NARRATOR:** Use the workflow mapping template in your course materials. Map one of your workflows before our next session.

**[END CARD]**

---

# Video 7: The 30-60-90 Day Rollout

## Metadata
- **Duration:** 4 minutes
- **Style:** Timeline animation with milestones
- **Target Audience:** All course participants
- **Learning Objective:** Plan a phased AI rollout with appropriate milestones

## Script

### Opening (0:00-0:25)

**[VISUAL: Calendar with 90 days marked]**

**NARRATOR:** You've designed your AI-enhanced workflow. You've built your governance framework. Now what? The 30-60-90 day rollout plan gives you a structure for going from approved plan to successful operation.

---

### Days 1-30: Foundation (0:25-1:30)

**[VISUAL: Building foundation animation]**

**NARRATOR:** The first 30 days are about building your foundation. No AI goes live yet—this is setup and preparation.

**[VISUAL: Checklist appearing]**

**NARRATOR:** Finalize governance and get all approvals. Set up your project team. Confirm your data is ready and accessible. Build or configure your technical environment.

**[VISUAL: Pilot user selection]**

**NARRATOR:** Critically: identify your pilot users. You want 3 to 5 champions who are enthusiastic, technically capable, and willing to give honest feedback. These are your early adopters, your test subjects, your reality check.

**[VISUAL: 30-day milestone marker]**

**NARRATOR:** At day 30, you hit a go/no-go decision. Are all prerequisites complete? Is the pilot team ready? If yes, proceed. If not, extend the foundation phase. Rushing this is how disasters start.

---

### Days 31-60: Pilot (1:30-2:30)

**[VISUAL: Small group working with AI system]**

**NARRATOR:** Days 31 through 60 are your pilot phase. AI goes live, but only for your pilot group.

**[VISUAL: Training session]**

**NARRATOR:** Train your pilot users thoroughly. Not just how to use the system, but what to watch for, how to report issues, and when to override.

**[VISUAL: HITL oversight animation]**

**NARRATOR:** Start with maximum oversight. If your target is Human-on-the-Loop, start with Human-in-the-Loop. Trust is earned, not assumed.

**[VISUAL: Daily check-ins and metrics dashboard]**

**NARRATOR:** Check in with pilot users daily in the first week. Track everything: accuracy, errors, overrides, user satisfaction. Adjust quickly based on what you learn.

**[VISUAL: 60-day milestone marker]**

**NARRATOR:** At day 60, another checkpoint. Do pilot metrics meet your targets? Is user feedback positive? If yes, expand. If not, iterate. Sometimes you need another pilot cycle.

---

### Days 61-90: Scale (2:30-3:30)

**[VISUAL: Expanding circles showing user growth]**

**NARRATOR:** Days 61 through 90, assuming pilot success, you scale. Onboard the next wave of users. Conduct broader training.

**[VISUAL: Oversight model adjustment]**

**NARRATOR:** This is when you might loosen oversight—moving from HITL to HOTL if the pilot proved the system reliable. But do this deliberately, with data backing the decision.

**[VISUAL: Operations handoff animation]**

**NARRATOR:** Start transitioning from project mode to operations mode. Who monitors the system long-term? Who handles support requests? Who's responsible for ongoing improvement?

**[VISUAL: Documentation being created]**

**NARRATOR:** Document everything you learned. Update your playbook with real-world insights. Create standard operating procedures.

**[VISUAL: 90-day milestone and celebration]**

**NARRATOR:** At day 90, you formally close the project. The AI is now part of how work gets done. But governance continues forever.

---

### Closing (3:30-4:00)

**[VISUAL: Timeline with key checkpoints highlighted]**

**NARRATOR:** The 30-60-90 structure gives you natural checkpoints to assess progress, correct course, or even stop if things aren't working. It's not a straitjacket—adjust timing to your context. But the phases matter: foundation, pilot, scale.

**[VISUAL: Template download prompt]**

**NARRATOR:** Use the 30-60-90 day plan template to build your rollout roadmap. Include specific tasks, owners, and success criteria.

**[END CARD]**

---

# Video 8: When AI Goes Wrong - Learning from Failures

## Metadata
- **Duration:** 5 minutes
- **Style:** Case study presentation with lessons learned
- **Target Audience:** All course participants
- **Learning Objective:** Recognize failure patterns and prevention strategies

## Script

### Opening (0:00-0:30)

**[VISUAL: Warning sign]**

**NARRATOR:** Let's talk about failure. Not because we want to scare you, but because understanding how AI projects fail is the best way to prevent yours from failing.

**[VISUAL: Collection of case study icons]**

**NARRATOR:** We'll look at three common failure patterns and what you can do to avoid them.

---

### Pattern 1: The Rush to Deploy (0:30-1:45)

**[VISUAL: Company rushing with "90-day AI transformation" banner]**

**NARRATOR:** Pattern one: The rush to deploy. A company sees competitors using AI. Leadership demands results in 90 days. Multiple AI systems launch simultaneously with minimal testing.

**[VISUAL: Cascading failures animation]**

**NARRATOR:** What went wrong? Everything at once. Inventory AI misread seasonal patterns. Customer chatbot frustrated more people than it helped. Pricing algorithm created inconsistencies across channels.

**[VISUAL: Root cause diagram]**

**NARRATOR:** The root cause wasn't that AI doesn't work—it's that they skipped the foundation. No pilots. No governance. No coordination between systems.

**[VISUAL: Prevention checklist]**

**NARRATOR:** Prevention: Start with one use case. Pilot before scaling. Build governance before you need it. Executive enthusiasm is great, but channel it into doing one thing well before doing many things badly.

---

### Pattern 2: The Bias Blind Spot (1:45-3:00)

**[VISUAL: Resume screening scenario]**

**NARRATOR:** Pattern two: The bias blind spot. A staffing company trained an AI on ten years of hiring data. The AI got very good at predicting who would be hired—by learning all the biases in that historical data.

**[VISUAL: Bias patterns emerging]**

**NARRATOR:** Female candidates were screened out at higher rates. Certain universities were overweighted. Names associated with particular ethnic backgrounds got lower scores.

**[VISUAL: Legal consequences]**

**NARRATOR:** The consequences: EEOC complaints, lost clients, a $2.4 million settlement, and a permanently discontinued tool.

**[VISUAL: Root cause diagram]**

**NARRATOR:** Root cause: They never asked "what biases might be in our training data?" They assumed that because the data was historical, it was neutral. Historical data is never neutral—it's a record of past decisions, biases included.

**[VISUAL: Prevention checklist]**

**NARRATOR:** Prevention: Audit for bias before deployment. Test AI decisions across demographic groups. Don't assume historical data is fair. Include diverse perspectives in system design. For high-stakes decisions, human oversight is essential.

---

### Pattern 3: The Security Shortcut (3:00-4:15)

**[VISUAL: Knowledge management AI scenario]**

**NARRATOR:** Pattern three: The security shortcut. A consulting firm built an AI to help consultants find relevant past project materials. Great idea—until the AI returned confidential information from one client to a consultant working for their competitor.

**[VISUAL: Data flowing wrong direction]**

**NARRATOR:** What happened? The AI had access to all company documents with no access controls. No logging of what was retrieved. Confidential client data was even embedded in the training data itself.

**[VISUAL: Consequences - lawsuit, lost clients, resignation]**

**NARRATOR:** Consequences: A $5 million lawsuit settlement, loss of major clients, mandatory security audits by everyone who remained, and the CISO's resignation.

**[VISUAL: Root cause diagram]**

**NARRATOR:** Root cause: They treated AI like any other search tool. But AI can make connections and surface information in ways that traditional search can't. Security thinking didn't evolve with the technology.

**[VISUAL: Prevention checklist]**

**NARRATOR:** Prevention: Apply the principle of least privilege. Integrate AI with existing access controls. Log everything. Never train on actual confidential data—use synthetic or anonymized data instead.

---

### Closing (4:15-5:00)

**[VISUAL: Three patterns summary]**

**NARRATOR:** Three patterns, one meta-lesson: AI failures aren't usually about the AI itself. They're about rushing, assuming, and taking shortcuts on governance.

**[VISUAL: Key takeaways]**

**NARRATOR:** Slow is smooth, smooth is fast. Start narrow, prove value, then expand. Question your data. Design for security from day one. And build governance that's proportional to your risk.

**[VISUAL: Course resources]**

**NARRATOR:** Use the case studies in your course materials to explore more failures—and more importantly, successes. Learn from others' mistakes so you don't have to make your own.

**[END CARD]**

---

## Production Notes

### General Style Guidelines
- Clean, modern animation style
- Consistent color palette aligned with course branding
- Clear visual hierarchy
- Smooth transitions between sections
- Accessible design (good contrast, readable fonts)

### Audio Guidelines
- Professional voiceover (warm but authoritative tone)
- Subtle background music (not distracting)
- Sound effects for key transitions (minimal)
- Ensure accessibility (captioning required)

### Recommended Software/Tools
- Animation: After Effects, Vyond, or Animaker
- Illustration: Illustrator or Figma
- Voiceover: Professional recording or quality AI voice
- Editing: Premiere Pro or DaVinci Resolve

### Distribution Formats
- Primary: MP4 (1080p)
- Secondary: WebM for web embedding
- Subtitles: SRT file for each video
- Transcripts: PDF document

---

*Scripts Version 1.0 | Enterprise AI Adoption Course*
