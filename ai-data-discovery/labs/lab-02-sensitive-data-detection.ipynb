{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Lab 2: Sensitive Data Detection & AI Cataloguing\n\n**Data Discovery: Harnessing AI, AGI & Vector Databases - Day 2**\n\n| Duration | Framework | Sections |\n|---|---|---|\n| 90 min | pandas, re, spacy, scikit-learn, chromadb, matplotlib | 5 |\n\nIn this lab, you'll explore:\n- Scanning text for PII using regex patterns\n- Using spaCy NER for entity extraction and hybrid detection\n- Computing automated risk scores for data assets\n- Building a compliance dashboard with matplotlib\n- Integrating risk metadata into a vector catalogue\n\n---"
  },
  {
   "cell_type": "markdown",
   "source": "## Student Notes & Background\n\n### Why Sensitive Data Detection Matters\n\nEvery organisation handles data that, if exposed, could harm individuals or violate regulations. **Personally Identifiable Information (PII)** — Social Security numbers, credit card numbers, email addresses, phone numbers, medical records — is scattered across documents, databases, and emails, often without anyone knowing exactly where it lives.\n\nSensitive data detection is the process of **automatically scanning** data assets to find PII and other regulated content. This is a critical building block for:\n- **GDPR compliance** — knowing where EU personal data resides\n- **HIPAA compliance** — protecting patient health information\n- **PCI-DSS compliance** — securing credit card data\n- **CCPA compliance** — enabling data subject access and deletion requests\n\nManual detection doesn't scale. An enterprise with thousands of documents needs automated scanning that combines **pattern matching** (regex) with **AI-based entity recognition** (NER) for comprehensive coverage.\n\n### Key Concepts\n\n#### 1. Regex-Based PII Scanning\n**Regular expressions** are the first line of defence for PII detection. Common patterns include:\n\n| PII Type | Pattern | Example |\n|---|---|---|\n| **SSN** | `\\d{3}-\\d{2}-\\d{4}` | 123-45-6789 |\n| **Credit Card** | `\\d{4}-\\d{4}-\\d{4}-\\d{4}` | 4532-1234-5678-9012 |\n| **Email** | `[\\w.+-]+@[\\w-]+\\.[\\w.]+` | john.smith@company.com |\n| **Phone** | `\\(?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d{4}` | (555) 123-4567 |\n\n**Strengths:** Fast, deterministic, high precision for well-formatted data.\n**Weaknesses:** Cannot detect names, organisations, or locations. Misses non-standard formats. Produces false positives on data that matches the pattern but isn't PII (e.g., a product ID that looks like an SSN).\n\n#### 2. Named Entity Recognition (NER) with spaCy\n**NER** uses a trained neural network to identify and classify entities in text. spaCy's `en_core_web_sm` model recognises:\n\n| Entity Type | Description | Examples |\n|---|---|---|\n| **PERSON** | Named individuals | \"John Smith\", \"Dr. Garcia\" |\n| **ORG** | Organisations | \"Acme Corp\", \"MedPlus Health\" |\n| **GPE** | Geopolitical entities (cities, countries) | \"New York\", \"Seattle\" |\n\nNER complements regex by detecting PII types that have no fixed format — you can't write a regex for every possible person's name. The combination of regex + NER is called **hybrid detection** and achieves much higher recall than either method alone.\n\n#### 3. Risk Scoring\nA **risk score** (0–100) quantifies how sensitive a document is based on the types and volume of PII found. Typical scoring weights reflect the severity of potential harm:\n\n| Factor | Points | Rationale |\n|---|---|---|\n| SSN found | +30 | Direct identity theft risk |\n| Credit card found | +25 | Financial fraud risk |\n| Email found | +10 | Phishing/spam risk |\n| Phone found | +10 | Social engineering risk |\n| PERSON entities | +5 each (max 15) | Identity linkage risk |\n| Medical document | +15 | HIPAA regulatory exposure |\n| Financial document | +10 | PCI-DSS/SOX exposure |\n\nScores are capped at 100 and mapped to **risk tiers**: Critical (76–100), High (51–75), Medium (26–50), Low (0–25). Risk tiers drive prioritisation — Critical assets get remediated first.\n\n#### 4. Compliance Dashboards\nA **compliance dashboard** visualises the PII landscape across your document corpus. Effective dashboards answer four questions at a glance:\n1. **What PII do we have?** — Distribution of PII types (SSN, credit card, email, etc.)\n2. **How risky is our data?** — Risk tier breakdown (Critical/High/Medium/Low)\n3. **Which departments are most exposed?** — Average risk by document type\n4. **Which regulations apply?** — Count of documents subject to GDPR, HIPAA, PCI-DSS, CCPA\n\n#### 5. Vector Catalogue with Risk Metadata\nBuilding on Lab 1's vector catalogue, this lab adds **risk metadata** to each document's embedding entry. This enables **filtered semantic search** — for example, \"find employee personal data\" filtered to only Critical-risk documents. ChromaDB supports `where` clauses that filter on metadata fields before computing similarity, making these queries efficient even on large catalogues.\n\n### What You'll Build\n\nIn this lab, you will:\n1. **Scan** 200 synthetic enterprise documents for PII using regex patterns for SSNs, credit cards, emails, and phone numbers\n2. **Extract** named entities (PERSON, ORG, GPE) using spaCy NER and combine with regex findings for hybrid detection\n3. **Compute** a 0–100 risk score for each document based on PII types, volume, and document category\n4. **Build** a 2×2 compliance dashboard showing PII distribution, risk tiers, department risk, and regulatory exposure\n5. **Create** a ChromaDB vector catalogue with risk metadata and perform filtered semantic queries\n\n### Prerequisites\n- Completion of Lab 1 (or familiarity with pandas, TF-IDF, and ChromaDB basics)\n- Understanding of regular expressions (basic pattern matching)\n- No prior NLP experience required — spaCy usage is introduced step by step\n\n### Tips\n- When writing regex patterns, use `\\b` word boundaries to avoid matching substrings (e.g., matching \"123-45-6789\" inside a longer number)\n- spaCy's small model (`en_core_web_sm`) is fast but less accurate than larger models — expect some missed entities\n- The risk scoring formula is deliberately simple; in production you'd weight factors based on your organisation's specific regulatory exposure\n- For the compliance dashboard, use `plt.suptitle()` for an overall title and `plt.tight_layout()` to prevent label overlap\n\n---",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# NLP\n",
    "import spacy\n",
    "\n",
    "# ML & Vector DB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "\n",
    "# Settings\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Generate Synthetic Documents\n",
    "\n",
    "We'll create ~200 synthetic text documents that simulate HR memos, financial reports, medical forms, and other enterprise content containing various types of PII."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "first_names = ['John', 'Jane', 'Robert', 'Maria', 'David', 'Sarah', 'Michael', 'Emily', 'James', 'Lisa']\n",
    "last_names = ['Smith', 'Johnson', 'Williams', 'Brown', 'Jones', 'Garcia', 'Miller', 'Davis', 'Rodriguez', 'Wilson']\n",
    "companies = ['Acme Corp', 'GlobalTech', 'MedPlus Health', 'FinanceFirst', 'DataDriven Inc']\n",
    "cities = ['New York', 'San Francisco', 'Chicago', 'Boston', 'Seattle', 'Austin', 'Denver', 'Atlanta']\n",
    "\n",
    "def random_ssn():\n",
    "    return f\"{np.random.randint(100,999)}-{np.random.randint(10,99)}-{np.random.randint(1000,9999)}\"\n",
    "\n",
    "def random_cc():\n",
    "    return f\"{np.random.randint(4000,4999)}-{np.random.randint(1000,9999)}-{np.random.randint(1000,9999)}-{np.random.randint(1000,9999)}\"\n",
    "\n",
    "def random_email(first, last):\n",
    "    domains = ['company.com', 'email.org', 'corp.net', 'enterprise.io']\n",
    "    return f\"{first.lower()}.{last.lower()}@{np.random.choice(domains)}\"\n",
    "\n",
    "def random_phone():\n",
    "    return f\"({np.random.randint(200,999)}) {np.random.randint(200,999)}-{np.random.randint(1000,9999)}\"\n",
    "\n",
    "templates = {\n",
    "    'hr_memo': [\n",
    "        \"Employee {name} (SSN: {ssn}) has been promoted to Senior Analyst effective March 2024. Contact: {email}, Phone: {phone}. Based in {city}.\",\n",
    "        \"Termination notice for {name}, SSN: {ssn}. Final paycheck to be sent to address on file. HR contact: {email}. Processed by {company}.\",\n",
    "        \"{name} from {company} submitted a leave request. Employee ID: EMP-{emp_id}. Emergency contact phone: {phone}. Location: {city}.\",\n",
    "        \"Salary adjustment memo: {name} (SSN: {ssn}) annual compensation increased to ${salary:,}. Effective date: January 2024. Department: {company}.\",\n",
    "    ],\n",
    "    'financial_report': [\n",
    "        \"Invoice #INV-{inv_id} for {company}: Payment of ${amount:,.2f} via credit card {cc}. Approved by {name}. Contact: {email}.\",\n",
    "        \"Expense report submitted by {name} ({email}) for ${amount:,.2f}. Corporate card ending {cc_last4}. Reimbursement approved by finance team at {company}.\",\n",
    "        \"Quarterly financial summary for {company}: Revenue ${amount:,.2f}. Prepared by {name}, CFO. Confidential. Phone: {phone}.\",\n",
    "        \"Wire transfer confirmation: ${amount:,.2f} sent to account ending {acct_last4} for {name} at {company}. Reference: TXN-{txn_id}.\",\n",
    "    ],\n",
    "    'medical_form': [\n",
    "        \"Patient: {name}, DOB: {dob}, SSN: {ssn}. Diagnosis: Type 2 Diabetes. Prescribed Metformin 500mg. Dr. {doctor} at {city} Medical Center.\",\n",
    "        \"Insurance claim for {name} (Member ID: MED-{med_id}). Procedure: Annual physical exam. Provider: {company} Health. Phone: {phone}.\",\n",
    "        \"Medical records request for {name}, DOB: {dob}. Records to be sent to {doctor} at {city} General Hospital. Patient email: {email}.\",\n",
    "    ],\n",
    "    'marketing_data': [\n",
    "        \"Campaign analytics report for {company}: {impressions:,} impressions, {clicks:,} clicks, {conversions} conversions. Manager: {name}, {email}.\",\n",
    "        \"Customer profile: {name}, {city}. Purchase history includes {purchases} orders. Email: {email}. Phone: {phone}. Loyalty tier: Gold.\",\n",
    "        \"Event registration: {name} from {company} registered for AI Summit 2024 in {city}. Contact: {email}. Dietary: vegetarian.\",\n",
    "    ],\n",
    "    'legal_document': [\n",
    "        \"Non-disclosure agreement between {name} and {company}. Effective date: January 2024. Jurisdiction: {city}. Contact: {email}.\",\n",
    "        \"Data processing agreement: {company} processes personal data of EU residents per GDPR Art. 28. DPO: {name}, {email}, {phone}.\",\n",
    "        \"Contract #CTR-{ctr_id} between {name} and {company}. Value: ${amount:,.2f}. Signed in {city}. Witness: {witness}.\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "documents = []\n",
    "for i in range(200):\n",
    "    doc_type = np.random.choice(list(templates.keys()))\n",
    "    template = np.random.choice(templates[doc_type])\n",
    "    first = np.random.choice(first_names)\n",
    "    last = np.random.choice(last_names)\n",
    "    name = f\"{first} {last}\"\n",
    "    \n",
    "    doc_text = template.format(\n",
    "        name=name,\n",
    "        ssn=random_ssn(),\n",
    "        cc=random_cc(),\n",
    "        cc_last4=f\"{np.random.randint(1000,9999)}\",\n",
    "        email=random_email(first, last),\n",
    "        phone=random_phone(),\n",
    "        city=np.random.choice(cities),\n",
    "        company=np.random.choice(companies),\n",
    "        salary=np.random.randint(50000, 200000),\n",
    "        amount=np.random.uniform(100, 500000),\n",
    "        emp_id=np.random.randint(10000, 99999),\n",
    "        inv_id=np.random.randint(10000, 99999),\n",
    "        txn_id=np.random.randint(100000, 999999),\n",
    "        acct_last4=f\"{np.random.randint(1000,9999)}\",\n",
    "        med_id=np.random.randint(100000, 999999),\n",
    "        dob=f\"{np.random.randint(1,12):02d}/{np.random.randint(1,28):02d}/{np.random.randint(1950,2000)}\",\n",
    "        doctor=f\"Dr. {np.random.choice(last_names)}\",\n",
    "        impressions=np.random.randint(10000, 1000000),\n",
    "        clicks=np.random.randint(100, 50000),\n",
    "        conversions=np.random.randint(10, 1000),\n",
    "        purchases=np.random.randint(1, 50),\n",
    "        ctr_id=np.random.randint(10000, 99999),\n",
    "        witness=f\"{np.random.choice(first_names)} {np.random.choice(last_names)}\",\n",
    "    )\n",
    "    \n",
    "    documents.append({\n",
    "        'doc_id': f'DOC-{i+1:04d}',\n",
    "        'doc_type': doc_type,\n",
    "        'text': doc_text,\n",
    "        'department': doc_type.replace('_', ' ').title().split()[0],\n",
    "    })\n",
    "\n",
    "docs_df = pd.DataFrame(documents)\n",
    "print(f\"Generated {len(docs_df)} documents\")\n",
    "print(f\"\\nDocument type distribution:\")\n",
    "print(docs_df['doc_type'].value_counts())\n",
    "print(f\"\\nSample document:\")\n",
    "print(docs_df.iloc[0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 1.1: Regex PII Scanning\n\nThe code below scans each document for PII using regex patterns that detect SSNs, credit card numbers, emails, and phone numbers. Regex is the first line of defence for PII detection — fast, deterministic, and high-precision for well-formatted data."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def scan_pii_regex(text):\n    \"\"\"Scan text for PII using regex patterns.\"\"\"\n    patterns = {\n        'ssn': re.compile(r'\\b\\d{3}-\\d{2}-\\d{4}\\b'),\n        'credit_card': re.compile(r'\\b\\d{4}-\\d{4}-\\d{4}-\\d{4}\\b'),\n        'email': re.compile(r'\\b[\\w.+-]+@[\\w-]+\\.[\\w.]+\\b'),\n        'phone': re.compile(r'\\(?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d{4}'),\n    }\n    findings = {}\n    for name, pat in patterns.items():\n        matches = pat.findall(text)\n        if matches:\n            findings[name] = matches\n    return findings\n\n# Apply to all documents\ndocs_df['pii_findings'] = docs_df['text'].apply(scan_pii_regex)\ndocs_df['ssn_count'] = docs_df['pii_findings'].apply(lambda x: len(x.get('ssn', [])))\ndocs_df['cc_count'] = docs_df['pii_findings'].apply(lambda x: len(x.get('credit_card', [])))\ndocs_df['email_count'] = docs_df['pii_findings'].apply(lambda x: len(x.get('email', [])))\ndocs_df['phone_count'] = docs_df['pii_findings'].apply(lambda x: len(x.get('phone', [])))\ndocs_df['total_pii'] = docs_df['ssn_count'] + docs_df['cc_count'] + docs_df['email_count'] + docs_df['phone_count']\n\nprint(\"PII Detection Summary:\")\nprint(f\"  Documents with SSN:         {(docs_df['ssn_count'] > 0).sum()}\")\nprint(f\"  Documents with Credit Card: {(docs_df['cc_count'] > 0).sum()}\")\nprint(f\"  Documents with Email:       {(docs_df['email_count'] > 0).sum()}\")\nprint(f\"  Documents with Phone:       {(docs_df['phone_count'] > 0).sum()}\")\nprint(f\"  Documents with any PII:     {(docs_df['total_pii'] > 0).sum()}\")"
  },
  {
   "cell_type": "markdown",
   "source": "### Analysis Questions\n\n1. Which PII type is found most frequently? Does this match the document type distribution?\n2. What types of PII could regex miss? Give an example of sensitive information that has no fixed format.\n3. Could any of the regex matches be false positives? What would cause that?",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 1.2: NER with spaCy\n\nThe code below uses spaCy's Named Entity Recognition to extract PERSON, ORG, and GPE entities from each document, then combines the findings with regex results for hybrid detection. NER catches PII types like names that have no fixed format."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def extract_ner_entities(text):\n    \"\"\"Extract named entities using spaCy.\"\"\"\n    doc = nlp(text)\n    entities = {'PERSON': [], 'ORG': [], 'GPE': []}\n    for ent in doc.ents:\n        if ent.label_ in entities:\n            entities[ent.label_].append(ent.text)\n    return entities\n\n# Apply to all documents\ndocs_df['ner_entities'] = docs_df['text'].apply(extract_ner_entities)\ndocs_df['person_count'] = docs_df['ner_entities'].apply(lambda x: len(x['PERSON']))\ndocs_df['org_count'] = docs_df['ner_entities'].apply(lambda x: len(x['ORG']))\ndocs_df['gpe_count'] = docs_df['ner_entities'].apply(lambda x: len(x['GPE']))\n\n# Combined PII types count\ndef count_pii_types(row):\n    types = 0\n    if row['ssn_count'] > 0: types += 1\n    if row['cc_count'] > 0: types += 1\n    if row['email_count'] > 0: types += 1\n    if row['phone_count'] > 0: types += 1\n    if row['person_count'] > 0: types += 1\n    if row['org_count'] > 0: types += 1\n    if row['gpe_count'] > 0: types += 1\n    return types\n\ndocs_df['total_pii_types'] = docs_df.apply(count_pii_types, axis=1)\n\nprint(\"NER Detection Summary:\")\nprint(f\"  Documents with PERSON:  {(docs_df['person_count'] > 0).sum()}\")\nprint(f\"  Documents with ORG:     {(docs_df['org_count'] > 0).sum()}\")\nprint(f\"  Documents with GPE:     {(docs_df['gpe_count'] > 0).sum()}\")\nprint(f\"\\nHybrid Detection (regex + NER):\")\nprint(f\"  Avg PII types per doc:  {docs_df['total_pii_types'].mean():.1f}\")\nprint(f\"  Max PII types in a doc: {docs_df['total_pii_types'].max()}\")"
  },
  {
   "cell_type": "markdown",
   "source": "### Analysis Questions\n\n1. How many PERSON entities did NER detect that regex could not? What does this tell you about hybrid detection?\n2. Look at the combined PII type counts — which document types have the most diverse PII footprint?\n3. What are the limitations of using a small NER model (en_core_web_sm)?",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 2.1: Risk Scoring\n\nThe code below computes a 0–100 risk score for each document based on the types and volume of PII found, plus bonuses for high-risk document categories (medical, financial). Scores are mapped to risk tiers that drive remediation priority."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def compute_risk_score(row):\n    \"\"\"Compute a 0-100 risk score for a document.\"\"\"\n    score = 0\n    \n    # PII type scores\n    if row['ssn_count'] > 0:\n        score += 30\n    if row['cc_count'] > 0:\n        score += 25\n    if row['email_count'] > 0:\n        score += 10\n    if row['phone_count'] > 0:\n        score += 10\n    \n    # NER entity scores\n    score += min(row['person_count'] * 5, 15)\n    \n    # Document type bonus\n    if row['doc_type'] == 'medical_form':\n        score += 15\n    elif row['doc_type'] == 'financial_report':\n        score += 10\n    \n    return min(score, 100)\n\n# Apply risk scoring\ndocs_df['risk_score'] = docs_df.apply(compute_risk_score, axis=1)\n\n# Assign risk tiers\ndef assign_tier(score):\n    if score >= 76:\n        return 'Critical'\n    elif score >= 51:\n        return 'High'\n    elif score >= 26:\n        return 'Medium'\n    else:\n        return 'Low'\n\ndocs_df['risk_tier'] = docs_df['risk_score'].apply(assign_tier)\n\nprint(\"Risk Tier Distribution:\")\nprint(docs_df['risk_tier'].value_counts())\nprint(f\"\\nAverage risk score: {docs_df['risk_score'].mean():.1f}\")\nprint(f\"Median risk score:  {docs_df['risk_score'].median():.1f}\")"
  },
  {
   "cell_type": "markdown",
   "source": "### Analysis Questions\n\n1. What percentage of documents fall into the Critical tier? Is this concerning?\n2. Which scoring factor contributes the most to high risk scores? (SSN at 30 pts, CC at 25 pts, etc.)\n3. If you were a compliance officer, would you adjust any of the scoring weights? Why?",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 2.2: Compliance Dashboard\n\nThe code below creates a 2×2 dashboard showing: PII type distribution, risk tier breakdown, average risk by document type, and regulatory exposure (GDPR, HIPAA, PCI-DSS, CCPA)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def build_compliance_dashboard(docs_df):\n    \"\"\"Build a 2x2 compliance dashboard.\"\"\"\n    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n\n    # 1. PII type distribution\n    pii_counts = {\n        'SSN': (docs_df['ssn_count'] > 0).sum(),\n        'Credit Card': (docs_df['cc_count'] > 0).sum(),\n        'Email': (docs_df['email_count'] > 0).sum(),\n        'Phone': (docs_df['phone_count'] > 0).sum(),\n        'Person (NER)': (docs_df['person_count'] > 0).sum(),\n        'Org (NER)': (docs_df['org_count'] > 0).sum(),\n        'Location (NER)': (docs_df['gpe_count'] > 0).sum(),\n    }\n    colors = ['#ef4444', '#f59e0b', '#3b82f6', '#10b981', '#8b5cf6', '#ec4899', '#06b6d4']\n    axes[0, 0].barh(list(pii_counts.keys()), list(pii_counts.values()), color=colors)\n    axes[0, 0].set_title('PII Type Distribution (docs containing each type)', fontsize=12)\n    axes[0, 0].set_xlabel('Number of Documents')\n\n    # 2. Risk tier distribution\n    tier_counts = docs_df['risk_tier'].value_counts()\n    tier_order = ['Critical', 'High', 'Medium', 'Low']\n    tier_colors = ['#ef4444', '#f59e0b', '#3b82f6', '#10b981']\n    tier_vals = [tier_counts.get(t, 0) for t in tier_order]\n    axes[0, 1].pie(tier_vals, labels=tier_order, colors=tier_colors,\n                   autopct='%1.1f%%', startangle=90)\n    axes[0, 1].set_title('Risk Tier Distribution', fontsize=12)\n\n    # 3. Average risk by doc type\n    avg_risk = docs_df.groupby('doc_type')['risk_score'].mean().sort_values()\n    avg_risk.plot(kind='barh', ax=axes[1, 0], color='#8b5cf6')\n    axes[1, 0].set_title('Average Risk Score by Document Type', fontsize=12)\n    axes[1, 0].set_xlabel('Average Risk Score')\n\n    # 4. Regulation applicability\n    regulations = {\n        'GDPR': (docs_df['person_count'] > 0).sum(),\n        'HIPAA': (docs_df['doc_type'] == 'medical_form').sum(),\n        'PCI-DSS': (docs_df['cc_count'] > 0).sum(),\n        'CCPA': ((docs_df['email_count'] > 0) & (docs_df['phone_count'] > 0)).sum(),\n    }\n    axes[1, 1].bar(regulations.keys(), regulations.values(),\n                   color=['#3b82f6', '#10b981', '#f59e0b', '#ef4444'])\n    axes[1, 1].set_title('Documents Subject to Regulation', fontsize=12)\n    axes[1, 1].set_ylabel('Number of Documents')\n\n    plt.suptitle('Compliance Dashboard', fontsize=16, fontweight='bold', y=1.02)\n    plt.tight_layout()\n    plt.show()\n\nbuild_compliance_dashboard(docs_df)"
  },
  {
   "cell_type": "markdown",
   "source": "### Analysis Questions\n\n1. Which regulation (GDPR, HIPAA, PCI-DSS, CCPA) applies to the most documents? Why?\n2. Which document type has the highest average risk score? What remediation would you prioritize?\n3. Are there any document types that appear low-risk but might be under-detected?",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 2.3: Catalogue Integration\n\nThe code below builds a ChromaDB vector catalogue that includes risk metadata (risk score and tier) for each document. This enables filtered semantic search — for example, finding \"employee personal data\" limited to only Critical-risk documents."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def build_risk_catalogue(docs_df):\n    \"\"\"Build a vector catalogue with risk metadata.\"\"\"\n    # Load model\n    model = SentenceTransformer('all-MiniLM-L6-v2')\n\n    # Encode texts\n    texts = docs_df['text'].tolist()\n    embeddings = model.encode(texts)\n\n    # Create ChromaDB collection\n    client = chromadb.Client()\n    collection = client.create_collection(\"risk_catalogue\")\n\n    # Add with metadata\n    collection.add(\n        embeddings=embeddings.tolist(),\n        documents=texts,\n        ids=docs_df['doc_id'].tolist(),\n        metadatas=[\n            {\n                'doc_type': row['doc_type'],\n                'risk_score': int(row['risk_score']),\n                'risk_tier': row['risk_tier'],\n            }\n            for _, row in docs_df.iterrows()\n        ]\n    )\n\n    print(f\"Risk catalogue built with {collection.count()} documents\")\n    return collection, model\n\ncollection, model = build_risk_catalogue(docs_df)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def filtered_risk_search(collection, query, risk_tier=None, n_results=5):\n    \"\"\"Search the risk catalogue with optional risk tier filter.\"\"\"\n    where_clause = None\n    if risk_tier:\n        where_clause = {'risk_tier': risk_tier}\n\n    results = collection.query(\n        query_texts=[query],\n        n_results=n_results,\n        where=where_clause\n    )\n\n    filter_str = f\" [filtered: {risk_tier}]\" if risk_tier else \"\"\n    print(f\"\\nQuery: '{query}'{filter_str}\")\n    print(\"-\" * 70)\n    for i, (doc, dist, meta) in enumerate(zip(\n        results['documents'][0],\n        results['distances'][0],\n        results['metadatas'][0]\n    )):\n        print(f\"  {i+1}. [{meta['risk_tier']:8} | {meta['doc_type']:18} | risk:{meta['risk_score']:3}]\")\n        print(f\"     {doc[:80]}...\")\n        print(f\"     (distance: {dist:.3f})\")\n\n# Test queries\nfiltered_risk_search(collection, \"employee personal data\", risk_tier=\"Critical\")\nfiltered_risk_search(collection, \"financial transactions and payments\")\nfiltered_risk_search(collection, \"medical patient records\", risk_tier=\"Critical\")"
  },
  {
   "cell_type": "markdown",
   "source": "### Analysis Questions\n\n1. When filtering by \"Critical\" risk tier, how do the search results change?\n2. Would you trust the risk scores enough to automate remediation actions, or would you require human review?",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, you learned how to:\n",
    "\n",
    "1. **Scan** documents for PII using regex patterns with precision/recall awareness\n",
    "2. **Extract** named entities with spaCy NER for hybrid PII detection\n",
    "3. **Score** data assets for compliance risk on a 0-100 scale\n",
    "4. **Visualise** compliance posture with a multi-chart dashboard\n",
    "5. **Integrate** risk metadata into a vector catalogue for filtered semantic search\n",
    "\n",
    "---\n",
    "\n",
    "*Data Discovery: Harnessing AI, AGI & Vector Databases | AI Elevate*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}