{
 "nbformat": 4,
 "nbformat_minor": 4,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Lab 1: Building Effective Prompts with the CRAFT Framework\n\nIn this lab, you'll learn to systematically construct high-quality prompts using the CRAFT framework. You'll measure prompt quality, build reusable templates, and visualize the difference between vague and well-structured prompts.\n\n## Learning Objectives\n- Apply the CRAFT framework systematically to any task\n- Diagnose and fix flawed CRAFT prompts\n- Critically evaluate prompt scoring heuristics\n- Build reusable prompt templates from scratch\n- Adapt prompts for different audiences and stakeholders\n\n**Duration:** 55-65 minutes | **Difficulty:** Beginner to Intermediate"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Understanding Prompt Components\n",
    "\n",
    "The CRAFT framework breaks every prompt into five essential components:\n",
    "\n",
    "- **C**ontext: Background information the AI needs to understand the situation\n",
    "- **R**ole: The expert persona the AI should adopt\n",
    "- **A**ction: The specific task you want performed\n",
    "- **F**ormat: How the output should be structured (bullets, table, essay, etc.)\n",
    "- **T**one: The voice and style of the response\n",
    "\n",
    "Let's build a Python toolkit to construct and evaluate CRAFT prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import re\n",
    "import textwrap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CRAFTPrompt:\n",
    "    \"\"\"A structured prompt built using the CRAFT framework.\"\"\"\n",
    "    context: str\n",
    "    role: str\n",
    "    action: str\n",
    "    format_spec: str\n",
    "    tone: str\n",
    "\n",
    "    def build(self) -> str:\n",
    "        \"\"\"Assemble components into a formatted prompt string.\"\"\"\n",
    "        sections = []\n",
    "        if self.context:\n",
    "            sections.append(f\"Context: {self.context}\")\n",
    "        if self.role:\n",
    "            sections.append(f\"Role: Act as {self.role}.\")\n",
    "        if self.action:\n",
    "            sections.append(f\"Task: {self.action}\")\n",
    "        if self.format_spec:\n",
    "            sections.append(f\"Format: {self.format_spec}\")\n",
    "        if self.tone:\n",
    "            sections.append(f\"Tone: {self.tone}\")\n",
    "        return \"\\n\\n\".join(sections)\n",
    "\n",
    "    def summary(self) -> str:\n",
    "        \"\"\"Return a one-line summary showing which fields are filled.\"\"\"\n",
    "        filled = []\n",
    "        for label, val in [(\"C\", self.context), (\"R\", self.role),\n",
    "                           (\"A\", self.action), (\"F\", self.format_spec),\n",
    "                           (\"T\", self.tone)]:\n",
    "            status = \"YES\" if val.strip() else \"---\"\n",
    "            filled.append(f\"{label}:{status}\")\n",
    "        return \"  |  \".join(filled)\n",
    "\n",
    "\n",
    "def score_prompt(prompt_text: str) -> Dict[str, int]:\n",
    "    \"\"\"Score a prompt from 1-5 on five quality dimensions.\n",
    "\n",
    "    Dimensions:\n",
    "        clarity       - Is the request unambiguous?\n",
    "        specificity   - Does it include concrete details?\n",
    "        context       - Does it provide background information?\n",
    "        format        - Does it specify desired output structure?\n",
    "        actionability - Is there a clear, measurable action?\n",
    "\n",
    "    Scoring uses keyword and pattern analysis as a lightweight heuristic.\n",
    "    \"\"\"\n",
    "    text = prompt_text.lower()\n",
    "    words = text.split()\n",
    "    word_count = len(words)\n",
    "\n",
    "    # --- Clarity ---\n",
    "    clarity = 1\n",
    "    if word_count >= 10:\n",
    "        clarity += 1\n",
    "    if any(w in text for w in [\"specifically\", \"exactly\", \"precisely\", \"must\", \"should\"]):\n",
    "        clarity += 1\n",
    "    if not any(w in text for w in [\"something\", \"stuff\", \"things\", \"whatever\", \"etc\"]):\n",
    "        clarity += 1\n",
    "    if word_count >= 25:\n",
    "        clarity += 1\n",
    "    clarity = min(clarity, 5)\n",
    "\n",
    "    # --- Specificity ---\n",
    "    specificity = 1\n",
    "    if re.search(r'\\d+', text):\n",
    "        specificity += 1\n",
    "    if any(w in text for w in [\"example\", \"such as\", \"including\", \"e.g.\", \"for instance\"]):\n",
    "        specificity += 1\n",
    "    specific_nouns = [\"industry\", \"sector\", \"company\", \"product\", \"metric\",\n",
    "                      \"audience\", \"stakeholder\", \"customer\", \"market\", \"region\"]\n",
    "    if sum(1 for w in specific_nouns if w in text) >= 2:\n",
    "        specificity += 1\n",
    "    if word_count >= 30:\n",
    "        specificity += 1\n",
    "    specificity = min(specificity, 5)\n",
    "\n",
    "    # --- Context ---\n",
    "    context_score = 1\n",
    "    context_signals = [\"background\", \"context\", \"situation\", \"scenario\",\n",
    "                       \"currently\", \"our company\", \"the team\", \"we are\",\n",
    "                       \"given that\", \"assuming\", \"based on\"]\n",
    "    matches = sum(1 for s in context_signals if s in text)\n",
    "    context_score += min(matches, 2)\n",
    "    if word_count >= 20:\n",
    "        context_score += 1\n",
    "    if re.search(r'(role|act as|you are|persona)', text):\n",
    "        context_score += 1\n",
    "    context_score = min(context_score, 5)\n",
    "\n",
    "    # --- Format ---\n",
    "    format_score = 1\n",
    "    format_signals = [\"bullet\", \"numbered\", \"table\", \"list\", \"heading\",\n",
    "                      \"paragraph\", \"json\", \"csv\", \"markdown\", \"format\",\n",
    "                      \"structure\", \"outline\", \"section\", \"step-by-step\"]\n",
    "    fmt_matches = sum(1 for s in format_signals if s in text)\n",
    "    format_score += min(fmt_matches, 2)\n",
    "    if re.search(r'\\d+\\s*(words|sentences|paragraphs|points|items|bullets)', text):\n",
    "        format_score += 1\n",
    "    if any(w in text for w in [\"include\", \"exclude\", \"begin with\", \"end with\"]):\n",
    "        format_score += 1\n",
    "    format_score = min(format_score, 5)\n",
    "\n",
    "    # --- Actionability ---\n",
    "    actionability = 1\n",
    "    action_verbs = [\"write\", \"create\", \"generate\", \"analyze\", \"compare\",\n",
    "                    \"summarize\", \"evaluate\", \"list\", \"design\", \"draft\",\n",
    "                    \"build\", \"develop\", \"produce\", \"identify\", \"recommend\"]\n",
    "    verb_hits = sum(1 for v in action_verbs if v in text)\n",
    "    actionability += min(verb_hits, 2)\n",
    "    if re.search(r'(for|targeting|aimed at)\\s+\\w+', text):\n",
    "        actionability += 1\n",
    "    if word_count >= 15:\n",
    "        actionability += 1\n",
    "    actionability = min(actionability, 5)\n",
    "\n",
    "    scores = {\n",
    "        \"clarity\": clarity,\n",
    "        \"specificity\": specificity,\n",
    "        \"context\": context_score,\n",
    "        \"format\": format_score,\n",
    "        \"actionability\": actionability,\n",
    "    }\n",
    "\n",
    "    total = sum(scores.values())\n",
    "    max_total = 25\n",
    "\n",
    "    print(f\"{'Dimension':<16} {'Score':>5}\")\n",
    "    print(\"-\" * 23)\n",
    "    for dim, val in scores.items():\n",
    "        bar = '#' * val + '.' * (5 - val)\n",
    "        print(f\"{dim:<16} [{bar}] {val}/5\")\n",
    "    print(\"-\" * 23)\n",
    "    print(f\"{'TOTAL':<16} {total}/{max_total}\")\n",
    "    print()\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "# Quick sanity check\n",
    "print(\"=== Scoring a vague prompt ===\")\n",
    "score_prompt(\"Write about AI\")\n",
    "\n",
    "print(\"=== Scoring a detailed CRAFT prompt ===\")\n",
    "score_prompt(\n",
    "    \"Context: Our healthcare startup is preparing a board presentation. \"\n",
    "    \"Role: Act as a healthcare strategy consultant with 15 years experience. \"\n",
    "    \"Task: Write a 500-word executive summary analyzing AI adoption trends \"\n",
    "    \"in the healthcare industry, including 3 specific examples of successful \"\n",
    "    \"implementations. Format: Use bullet points for key findings followed by \"\n",
    "    \"a numbered list of recommendations. Tone: Professional and data-driven.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Before & After Analysis\n",
    "\n",
    "The real power of CRAFT becomes clear when you compare a raw, off-the-cuff prompt with its structured counterpart. Below we take three common but vague prompts, rebuild each one with CRAFT, and measure the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Before / After pairs ----------\n",
    "\n",
    "before_after: List[Tuple[str, CRAFTPrompt]] = [\n",
    "    # Pair 1 -- \"Write about AI\"\n",
    "    (\n",
    "        \"Write about AI\",\n",
    "        CRAFTPrompt(\n",
    "            context=\"Our hospital network is evaluating AI tools to reduce \"\n",
    "                    \"diagnostic errors. The audience is the clinical leadership team.\",\n",
    "            role=\"a healthcare technology analyst with expertise in clinical AI\",\n",
    "            action=\"Write a 600-word briefing on how AI-assisted diagnostics are \"\n",
    "                   \"reducing misdiagnosis rates, including 3 specific case studies \"\n",
    "                   \"from peer-reviewed research.\",\n",
    "            format_spec=\"Start with a 2-sentence executive summary, then use \"\n",
    "                        \"bullet points for each case study, and end with a \"\n",
    "                        \"numbered list of 3 recommendations.\",\n",
    "            tone=\"Professional, evidence-based, and persuasive\"\n",
    "        )\n",
    "    ),\n",
    "    # Pair 2 -- \"Summarize this\"\n",
    "    (\n",
    "        \"Summarize this\",\n",
    "        CRAFTPrompt(\n",
    "            context=\"The attached 40-page quarterly earnings report covers \"\n",
    "                    \"revenue, operating costs, and forward guidance for Q3 2025.\",\n",
    "            role=\"a senior financial analyst preparing materials for the CFO\",\n",
    "            action=\"Summarize the report into an executive briefing that \"\n",
    "                   \"highlights the 5 most critical data points, identifies \"\n",
    "                   \"2 risks, and notes any upward or downward trends.\",\n",
    "            format_spec=\"Use a structured format: one heading per section, \"\n",
    "                        \"bullet points for data, and a comparison table for \"\n",
    "                        \"quarter-over-quarter metrics. Keep it under 300 words.\",\n",
    "            tone=\"Concise, analytical, and neutral\"\n",
    "        )\n",
    "    ),\n",
    "    # Pair 3 -- \"Help with email\"\n",
    "    (\n",
    "        \"Help with email\",\n",
    "        CRAFTPrompt(\n",
    "            context=\"We delivered a software demo to a prospective enterprise \"\n",
    "                    \"client last Tuesday. They asked about SSO integration \"\n",
    "                    \"and data residency in the EU. We need to follow up \"\n",
    "                    \"within 48 hours.\",\n",
    "            role=\"an enterprise account executive at a B2B SaaS company\",\n",
    "            action=\"Draft a follow-up email that thanks the client for their \"\n",
    "                   \"time, directly addresses their SSO and data-residency \"\n",
    "                   \"questions, and proposes a 30-minute technical deep-dive \"\n",
    "                   \"call next week.\",\n",
    "            format_spec=\"Subject line + body. Body should have a greeting, \"\n",
    "                        \"3 short paragraphs, and a clear call-to-action with \"\n",
    "                        \"2 proposed meeting times.\",\n",
    "            tone=\"Warm, confident, and professional\"\n",
    "        )\n",
    "    ),\n",
    "]\n",
    "\n",
    "# ---------- Score and display comparison ----------\n",
    "\n",
    "all_before_scores: List[Dict[str, int]] = []\n",
    "all_after_scores: List[Dict[str, int]] = []\n",
    "\n",
    "for idx, (before_text, after_craft) in enumerate(before_after, start=1):\n",
    "    after_text = after_craft.build()\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"  PAIR {idx}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    print(f\"\\n--- BEFORE ---\")\n",
    "    print(f'  \"{before_text}\"\\n')\n",
    "    b_scores = score_prompt(before_text)\n",
    "\n",
    "    print(f\"--- AFTER (CRAFT) ---\")\n",
    "    print(textwrap.indent(after_text, \"  \") + \"\\n\")\n",
    "    a_scores = score_prompt(after_text)\n",
    "\n",
    "    improvement = sum(a_scores.values()) - sum(b_scores.values())\n",
    "    print(f\"  >>> Improvement: +{improvement} points\\n\")\n",
    "\n",
    "    all_before_scores.append(b_scores)\n",
    "    all_after_scores.append(a_scores)\n",
    "\n",
    "# ---------- Summary table ----------\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"  SUMMARY TABLE\")\n",
    "print(\"=\" * 60)\n",
    "header = f\"{'Pair':<6} {'Before':>8} {'After':>8} {'Delta':>8}\"\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "for i in range(len(before_after)):\n",
    "    b_total = sum(all_before_scores[i].values())\n",
    "    a_total = sum(all_after_scores[i].values())\n",
    "    print(f\"{i+1:<6} {b_total:>7}/25 {a_total:>7}/25 {'+' + str(a_total - b_total):>7}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Exercise 1: Diagnose Broken Prompts (5 min)\n\nBelow are three `CRAFTPrompt` objects that **look** complete — every field is filled in — but each has a subtle flaw that would make the prompt ineffective in practice. Your job:\n\n1. **Run** the cell to see each prompt and its score.\n2. **Identify** the specific flaw in each prompt (write it in the comment).\n3. **Fix** the prompt by creating a corrected version and score it.\n\n| Prompt | Flaw Type | Hint |\n|--------|-----------|------|\n| Broken 1 | Context / Role mismatch | The role doesn't match what the context needs |\n| Broken 2 | Vague action | The action verb is too ambiguous to produce useful output |\n| Broken 3 | Wrong tone for audience | The tone will alienate the target reader |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Broken Prompt 1: Context / Role Mismatch ─────────────────────\n\nbroken_1 = CRAFTPrompt(\n    context=\"Our hospital is evaluating whether to adopt an AI-powered \"\n            \"radiology screening tool. The decision committee includes \"\n            \"the Chief Medical Officer and head of IT.\",\n    role=\"a social media influencer specializing in lifestyle content\",\n    action=\"Write a 400-word recommendation memo evaluating the clinical \"\n           \"accuracy, integration requirements, and ROI of the AI tool.\",\n    format_spec=\"Executive memo with sections: Summary, Clinical Evidence, \"\n                \"Technical Requirements, Cost-Benefit Analysis.\",\n    tone=\"Professional, evidence-based, and balanced\"\n)\n\nprint(\"=== BROKEN PROMPT 1 ===\")\nprint(broken_1.build())\nprint()\nscore_prompt(broken_1.build())\n\n# What's wrong?\nflaw_1 = (\"The role is a social media influencer, but the context requires \"\n          \"clinical/technical expertise for a hospital AI evaluation\")\n\n# Fixed version\nfixed_1 = CRAFTPrompt(\n    context=\"Our hospital is evaluating whether to adopt an AI-powered \"\n            \"radiology screening tool. The decision committee includes \"\n            \"the Chief Medical Officer and head of IT.\",\n    role=\"a healthcare technology consultant with expertise in clinical AI \"\n         \"systems and hospital IT integration\",\n    action=\"Write a 400-word recommendation memo evaluating the clinical \"\n           \"accuracy, integration requirements, and ROI of the AI tool.\",\n    format_spec=\"Executive memo with sections: Summary, Clinical Evidence, \"\n                \"Technical Requirements, Cost-Benefit Analysis.\",\n    tone=\"Professional, evidence-based, and balanced\"\n)\nprint(\"\\n=== FIXED PROMPT 1 ===\")\nprint(fixed_1.build())\nprint()\nscore_prompt(fixed_1.build())\n\n\n# ── Broken Prompt 2: Vague Action ────────────────────────────────\n\nbroken_2 = CRAFTPrompt(\n    context=\"Our e-commerce company had 15% cart abandonment increase \"\n            \"last quarter. The product team needs actionable insights \"\n            \"from user session data covering 50,000 transactions.\",\n    role=\"a senior UX researcher with expertise in e-commerce analytics\",\n    action=\"Look at the data and tell us what you think about it.\",\n    format_spec=\"Structured report with numbered findings, each including \"\n                \"the data pattern, its likely cause, and a specific fix.\",\n    tone=\"Analytical, direct, and data-driven\"\n)\n\nprint(\"\\n=== BROKEN PROMPT 2 ===\")\nprint(broken_2.build())\nprint()\nscore_prompt(broken_2.build())\n\n# What's wrong?\nflaw_2 = (\"The action 'Look at the data and tell us what you think about it' \"\n          \"is vague — no specific analysis tasks\")\n\n# Fixed version\nfixed_2 = CRAFTPrompt(\n    context=\"Our e-commerce company had 15% cart abandonment increase \"\n            \"last quarter. The product team needs actionable insights \"\n            \"from user session data covering 50,000 transactions.\",\n    role=\"a senior UX researcher with expertise in e-commerce analytics\",\n    action=\"Analyze the 50,000 transaction dataset to identify the top 5 \"\n           \"patterns contributing to the 15% cart abandonment increase, \"\n           \"including specific metrics for each pattern and actionable UX \"\n           \"recommendations to reduce abandonment by at least 8%\",\n    format_spec=\"Structured report with numbered findings, each including \"\n                \"the data pattern, its likely cause, and a specific fix.\",\n    tone=\"Analytical, direct, and data-driven\"\n)\nprint(\"\\n=== FIXED PROMPT 2 ===\")\nprint(fixed_2.build())\nprint()\nscore_prompt(fixed_2.build())\n\n\n# ── Broken Prompt 3: Wrong Tone for Audience ─────────────────────\n\nbroken_3 = CRAFTPrompt(\n    context=\"A Fortune 500 CEO is presenting to the board of directors \"\n            \"about the company's AI transformation roadmap for 2026. \"\n            \"Board members include institutional investors and industry veterans.\",\n    role=\"a management consultant at a top-tier strategy firm\",\n    action=\"Write the opening remarks for the board presentation, covering \"\n           \"strategic rationale, expected ROI, and competitive positioning.\",\n    format_spec=\"Speech script, 300 words, with clear transitions between \"\n                \"the three topics.\",\n    tone=\"Super casual, lots of slang, use emojis and exclamation marks!!!\"\n)\n\nprint(\"\\n=== BROKEN PROMPT 3 ===\")\nprint(broken_3.build())\nprint()\nscore_prompt(broken_3.build())\n\n# What's wrong?\nflaw_3 = (\"The tone (casual/slang/emojis) is completely wrong for a \"\n          \"Fortune 500 CEO presenting to a board of institutional investors\")\n\n# Fixed version\nfixed_3 = CRAFTPrompt(\n    context=\"A Fortune 500 CEO is presenting to the board of directors \"\n            \"about the company's AI transformation roadmap for 2026. \"\n            \"Board members include institutional investors and industry veterans.\",\n    role=\"a management consultant at a top-tier strategy firm\",\n    action=\"Write the opening remarks for the board presentation, covering \"\n           \"strategic rationale, expected ROI, and competitive positioning.\",\n    format_spec=\"Speech script, 300 words, with clear transitions between \"\n                \"the three topics.\",\n    tone=\"Authoritative, measured, and executive — conveying confidence \"\n         \"and strategic clarity appropriate for a board-level audience\"\n)\nprint(\"\\n=== FIXED PROMPT 3 ===\")\nprint(fixed_3.build())\nprint()\nscore_prompt(fixed_3.build())"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Prompt Templates\n",
    "\n",
    "Instead of crafting every prompt from scratch, experienced prompt engineers maintain a **template library** of reusable CRAFT prompts with placeholders. This section introduces a `PromptLibrary` class that lets you store, retrieve, list, and fill templates with specific values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "class PromptLibrary:\n",
    "    \"\"\"A reusable library of CRAFT prompt templates.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self._templates: OrderedDict[str, CRAFTPrompt] = OrderedDict()\n",
    "\n",
    "    def add_template(self, name: str, prompt: CRAFTPrompt) -> None:\n",
    "        \"\"\"Register a new template.\"\"\"\n",
    "        self._templates[name] = prompt\n",
    "        print(f\"  [+] Template '{name}' added.\")\n",
    "\n",
    "    def get_template(self, name: str) -> CRAFTPrompt:\n",
    "        \"\"\"Retrieve a template by name.\"\"\"\n",
    "        if name not in self._templates:\n",
    "            raise KeyError(f\"Template '{name}' not found. \"\n",
    "                           f\"Available: {list(self._templates.keys())}\")\n",
    "        return self._templates[name]\n",
    "\n",
    "    def list_templates(self) -> None:\n",
    "        \"\"\"Display all registered templates.\"\"\"\n",
    "        print(f\"{'#':<4} {'Template Name':<25} {'Placeholders'}\")\n",
    "        print(\"-\" * 65)\n",
    "        for i, (name, tmpl) in enumerate(self._templates.items(), 1):\n",
    "            combined = tmpl.build()\n",
    "            placeholders = sorted(set(re.findall(r'\\{(\\w+)\\}', combined)))\n",
    "            print(f\"{i:<4} {name:<25} {', '.join(placeholders) or '(none)'}\")\n",
    "\n",
    "    def fill_template(self, name: str, **kwargs: str) -> str:\n",
    "        \"\"\"Fill placeholders in a template and return the final prompt.\"\"\"\n",
    "        tmpl = self.get_template(name)\n",
    "        raw = tmpl.build()\n",
    "\n",
    "        # Find unfilled placeholders\n",
    "        expected = set(re.findall(r'\\{(\\w+)\\}', raw))\n",
    "        missing = expected - set(kwargs.keys())\n",
    "        if missing:\n",
    "            print(f\"  Warning: unfilled placeholders: {missing}\")\n",
    "\n",
    "        # Safe formatting that ignores unknown keys\n",
    "        for key, value in kwargs.items():\n",
    "            raw = raw.replace(\"{\" + key + \"}\", value)\n",
    "        return raw\n",
    "\n",
    "\n",
    "# ---------- Pre-populate the library ----------\n",
    "\n",
    "library = PromptLibrary()\n",
    "\n",
    "library.add_template(\"email_writer\", CRAFTPrompt(\n",
    "    context=\"We are a {company_type} company. The recipient is {recipient}.\",\n",
    "    role=\"a professional communications specialist\",\n",
    "    action=\"Draft a {email_type} email about {topic} that includes a clear \"\n",
    "           \"call-to-action.\",\n",
    "    format_spec=\"Subject line + 3 concise paragraphs. Keep under 200 words.\",\n",
    "    tone=\"{tone}\"\n",
    "))\n",
    "\n",
    "library.add_template(\"code_reviewer\", CRAFTPrompt(\n",
    "    context=\"The code is written in {language} for a {project_type} project. \"\n",
    "           \"The team follows {standard} coding standards.\",\n",
    "    role=\"a senior software engineer and code reviewer\",\n",
    "    action=\"Review the following code for bugs, performance issues, and \"\n",
    "           \"readability. Identify at least 3 specific improvements.\",\n",
    "    format_spec=\"Use a numbered list. For each issue: state the problem, \"\n",
    "                \"show the offending line, and suggest a fix with a code snippet.\",\n",
    "    tone=\"Constructive and educational\"\n",
    "))\n",
    "\n",
    "library.add_template(\"meeting_summarizer\", CRAFTPrompt(\n",
    "    context=\"The meeting was a {meeting_type} attended by {attendees}. \"\n",
    "           \"Duration: {duration}.\",\n",
    "    role=\"an executive assistant skilled at distilling meeting notes\",\n",
    "    action=\"Summarize the meeting into key decisions, action items with \"\n",
    "           \"owners, and open questions. Flag any items that are blocked.\",\n",
    "    format_spec=\"Use headings: Decisions, Action Items (table with Owner and \"\n",
    "                \"Due Date columns), Open Questions. Keep under 250 words.\",\n",
    "    tone=\"Neutral and precise\"\n",
    "))\n",
    "\n",
    "library.add_template(\"data_analyst\", CRAFTPrompt(\n",
    "    context=\"The dataset contains {dataset_description}. The stakeholder \"\n",
    "           \"is {audience}.\",\n",
    "    role=\"a senior data analyst at a {industry} company\",\n",
    "    action=\"Analyze the data to identify the top {num_insights} insights, \"\n",
    "           \"highlight any anomalies, and recommend next steps.\",\n",
    "    format_spec=\"Executive summary (3 sentences), then bullet points for each \"\n",
    "                \"insight, then a table of anomalies with severity ratings.\",\n",
    "    tone=\"Data-driven and actionable\"\n",
    "))\n",
    "\n",
    "# ---------- Show the library ----------\n",
    "print(\"\\n\")\n",
    "library.list_templates()\n",
    "\n",
    "# ---------- Demo: fill a template ----------\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"  DEMO: Filling the 'email_writer' template\")\n",
    "print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "filled = library.fill_template(\n",
    "    \"email_writer\",\n",
    "    company_type=\"B2B SaaS\",\n",
    "    recipient=\"the VP of Engineering at a Fortune 500 client\",\n",
    "    email_type=\"follow-up\",\n",
    "    topic=\"the security audit results from last week\",\n",
    "    tone=\"Confident, professional, and reassuring\"\n",
    ")\n",
    "print(filled)\n",
    "print(\"\\n--- Score ---\")\n",
    "score_prompt(filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Exercise 2: Game the System (10 min)\n\nThe `score_prompt()` function uses keyword heuristics — it isn't actually intelligent. This exercise exposes that.\n\n**Part A — High score, terrible prompt:** Write a prompt that scores **22 or higher** out of 25 but would produce **useless output** from an AI. Stuff it with scoring keywords while making the actual request incoherent or contradictory.\n\n**Part B — Low score, good prompt:** Write a prompt that scores **12 or lower** but would actually produce **excellent, useful output** from a real AI. Avoid the keywords the scorer looks for while keeping the request crystal clear.\n\n**Part C — Reflection:** In a comment, identify at least 2 specific blind spots in the scoring function that your examples exploit."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Part A: High-scoring TERRIBLE prompt (target: 22+ / 25)\n# The prompt should score well but be genuinely bad — contradictory,\n# incoherent, or so vague it would confuse any AI.\n\nterrible_high_scorer = (\n    \"Context: Given that our company in the healthcare industry is currently \"\n    \"evaluating the situation, we are specifically analyzing background context \"\n    \"for our product and customer stakeholder audience in the market sector \"\n    \"based on assumptions. Role: Act as a senior analyst. Task: Write and \"\n    \"create a comprehensive, precisely structured step-by-step bullet-point \"\n    \"numbered list in table format with heading sections, including 10 items \"\n    \"for each category, comparing and analyzing multiple metrics for the \"\n    \"audience. Format: Use bullet points, numbered list, table, headings, \"\n    \"paragraphs, and sections. Tone: Professional specifically actionable.\"\n)\n\nprint(\"=== Part A: High-scoring terrible prompt ===\")\nprint(f'\"{terrible_high_scorer}\"')\nprint()\na_scores = score_prompt(terrible_high_scorer)\na_total = sum(a_scores.values())\nprint(f\"Target: 22+  |  Your score: {a_total}\")\nassert a_total >= 22, f\"Score {a_total} is below 22. Add more scoring keywords.\"\nprint(\"PASS: Score is 22 or higher.\\n\")\n\n\n# Part B: Low-scoring GOOD prompt (target: 12 or lower)\n# The prompt should be genuinely clear and useful to a real AI,\n# but avoid the keywords that score_prompt() looks for.\n\ngood_low_scorer = (\n    \"What are three ways a bakery owner could use ChatGPT to save time each week?\"\n)\n\nprint(\"=== Part B: Low-scoring good prompt ===\")\nprint(f'\"{good_low_scorer}\"')\nprint()\nb_scores = score_prompt(good_low_scorer)\nb_total = sum(b_scores.values())\nprint(f\"Target: <=12  |  Your score: {b_total}\")\nassert b_total <= 12, f\"Score {b_total} is above 12. Remove scoring keywords.\"\nprint(\"PASS: Score is 12 or lower.\\n\")\n\n\n# Part C: Reflection — what are the blind spots?\nblind_spot_1 = (\"The scorer counts keywords like 'specifically', 'bullet', 'table' \"\n                \"regardless of whether the prompt makes logical sense — a contradictory \"\n                \"or incoherent prompt still scores high if it includes the right words\")\n\nblind_spot_2 = (\"The scorer penalizes short prompts even when brevity is appropriate — \"\n                \"a clear 15-word question can be more effective than a 50-word \"\n                \"keyword-stuffed mess\")\n\nprint(f\"Blind spot 1: {blind_spot_1}\")\nprint(f\"Blind spot 2: {blind_spot_2}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Visualization - Prompt Quality Comparison\n",
    "\n",
    "A radar chart (spider chart) makes it easy to see which quality dimensions are strong or weak across different prompt styles. Below we compare three prompts representing increasing levels of structure:\n",
    "\n",
    "1. **Vague** - A bare-minimum, one-line request\n",
    "2. **Partially Structured** - Some detail but missing key CRAFT components\n",
    "3. **Full CRAFT** - All five components filled in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Three comparison prompts ----------\n",
    "\n",
    "vague_prompt = \"Make a marketing plan\"\n",
    "\n",
    "partial_prompt = (\n",
    "    \"Write a marketing plan for our new mobile app targeting millennials. \"\n",
    "    \"Include social media strategy and budget estimates.\"\n",
    ")\n",
    "\n",
    "craft_prompt = CRAFTPrompt(\n",
    "    context=\"Our fintech startup is launching a budgeting app aimed at \"\n",
    "            \"millennials (ages 25-40) in the US market. We have a quarterly \"\n",
    "            \"marketing budget of $50,000 and currently 2,000 beta users.\",\n",
    "    role=\"a digital marketing strategist with 10 years of experience in \"\n",
    "         \"fintech product launches\",\n",
    "    action=\"Create a 90-day go-to-market plan that identifies the top 3 \"\n",
    "           \"customer acquisition channels, proposes a content calendar, and \"\n",
    "           \"estimates cost-per-acquisition for each channel.\",\n",
    "    format_spec=\"Use the following structure: Executive Summary (5 sentences), \"\n",
    "                \"Channel Strategy (table with columns: Channel, Audience Fit, \"\n",
    "                \"Monthly Budget, Est. CPA), Content Calendar (bullet points \"\n",
    "                \"by week), and KPIs (numbered list of 5 metrics to track).\",\n",
    "    tone=\"Strategic, data-informed, and action-oriented\"\n",
    ").build()\n",
    "\n",
    "# ---------- Score each ----------\n",
    "print(\"Scoring: Vague prompt\")\n",
    "s_vague = score_prompt(vague_prompt)\n",
    "print(\"Scoring: Partial prompt\")\n",
    "s_partial = score_prompt(partial_prompt)\n",
    "print(\"Scoring: Full CRAFT prompt\")\n",
    "s_craft = score_prompt(craft_prompt)\n",
    "\n",
    "# ---------- Radar chart ----------\n",
    "dimensions = list(s_vague.keys())\n",
    "n_dims = len(dimensions)\n",
    "\n",
    "angles = np.linspace(0, 2 * np.pi, n_dims, endpoint=False).tolist()\n",
    "angles += angles[:1]  # close the polygon\n",
    "\n",
    "def values_for(scores: Dict[str, int]) -> List[int]:\n",
    "    vals = [scores[d] for d in dimensions]\n",
    "    return vals + vals[:1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 7), subplot_kw=dict(polar=True))\n",
    "\n",
    "ax.plot(angles, values_for(s_vague), 'o-', linewidth=2,\n",
    "        label=f'Vague ({sum(s_vague.values())}/25)', color='#e74c3c')\n",
    "ax.fill(angles, values_for(s_vague), alpha=0.10, color='#e74c3c')\n",
    "\n",
    "ax.plot(angles, values_for(s_partial), 's-', linewidth=2,\n",
    "        label=f'Partial ({sum(s_partial.values())}/25)', color='#f39c12')\n",
    "ax.fill(angles, values_for(s_partial), alpha=0.10, color='#f39c12')\n",
    "\n",
    "ax.plot(angles, values_for(s_craft), 'D-', linewidth=2,\n",
    "        label=f'Full CRAFT ({sum(s_craft.values())}/25)', color='#27ae60')\n",
    "ax.fill(angles, values_for(s_craft), alpha=0.15, color='#27ae60')\n",
    "\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels([d.capitalize() for d in dimensions], fontsize=12)\n",
    "ax.set_yticks([1, 2, 3, 4, 5])\n",
    "ax.set_yticklabels(['1', '2', '3', '4', '5'], fontsize=9, color='grey')\n",
    "ax.set_ylim(0, 5)\n",
    "ax.set_title('Prompt Quality Comparison', fontsize=15, fontweight='bold', pad=20)\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Exercise 3: Build a Template from Scratch (15 min)\n\nDesign a **competitive analysis** prompt template entirely from scratch — no skeleton code is provided.\n\n**Requirements:**\n1. Create a `CRAFTPrompt` with **at least 4 placeholders** (e.g., `{company}`, `{competitor}`, `{industry}`, `{metric}`)\n2. Add it to the `library` under the name `\"competitive_analysis\"`\n3. Fill the template for **two different industries** (e.g., fintech vs. healthcare)\n4. Score both filled prompts — each must score **20 or higher** out of 25\n5. Print the library listing to confirm your template appears"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Step 1: Create the CRAFTPrompt with 4+ placeholders\ncomp_analysis_template = CRAFTPrompt(\n    context=\"Our {company_type} company is entering the {industry} market. \"\n            \"We need to understand how our product compares to {competitor} \"\n            \"and other players in the {region} region.\",\n    role=\"a senior competitive intelligence analyst specializing in {industry}\",\n    action=\"Create a competitive analysis comparing our product to {competitor}, \"\n           \"evaluating market share, pricing strategy, product features, and \"\n           \"customer satisfaction. Include at least 3 specific metrics and \"\n           \"identify 2 strategic opportunities for differentiation.\",\n    format_spec=\"Use a structured report with sections: Executive Summary, \"\n                \"Competitor Profile (table comparing 5 attributes), \"\n                \"Opportunity Analysis (numbered list), and Recommendations \"\n                \"(bullet points with priority ratings).\",\n    tone=\"Analytical, data-driven, and actionable\"\n)\n\n# Step 2: Add to the library as \"competitive_analysis\"\nlibrary.add_template(\"competitive_analysis\", comp_analysis_template)\n\n# Step 3: Fill for Industry 1 — Fintech / Digital Payments\nfilled_1 = library.fill_template(\"competitive_analysis\",\n    company_type=\"fintech startup\",\n    industry=\"digital payments\",\n    competitor=\"Stripe\",\n    region=\"North America\"\n)\nprint(\"=== Industry 1: Digital Payments ===\")\nprint(filled_1)\nprint()\nscores_1 = score_prompt(filled_1)\ntotal_1 = sum(scores_1.values())\nprint(f\"Score: {total_1}/25 (target: 20+)\")\nassert total_1 >= 20, f\"Score {total_1} is below 20.\"\n\n# Step 4: Fill for Industry 2 — Healthcare / Telemedicine\nfilled_2 = library.fill_template(\"competitive_analysis\",\n    company_type=\"healthcare SaaS\",\n    industry=\"telemedicine\",\n    competitor=\"Teladoc\",\n    region=\"European Union\"\n)\nprint(\"\\n=== Industry 2: Telemedicine ===\")\nprint(filled_2)\nprint()\nscores_2 = score_prompt(filled_2)\ntotal_2 = sum(scores_2.values())\nprint(f\"Score: {total_2}/25 (target: 20+)\")\nassert total_2 >= 20, f\"Score {total_2} is below 20.\"\n\n# Step 5: Show updated library\nprint(\"\\n=== Updated Library ===\")\nlibrary.list_templates()"
  },
  {
   "cell_type": "markdown",
   "source": "## Exercise 4: The Audience Pivot (15 min)\n\nThe same information needs radically different prompts depending on who will read the output. In this exercise, you'll write **three CRAFT prompts** that all request the same core information — a summary of your company's Q3 AI initiative results — but tailored for three very different audiences:\n\n| Audience | What they care about | Expected tone |\n|----------|---------------------|---------------|\n| **Engineering team** | Technical details, architecture, performance metrics | Technical, precise |\n| **VP of Product** | Roadmap impact, resource needs, timelines | Strategic, concise |\n| **CEO** | Business value, competitive advantage, ROI | Executive, high-level |\n\n**Requirements:**\n1. All 3 prompts must request the same underlying information (Q3 AI initiative results)\n2. Each prompt must score **18+ / 25**\n3. Create a **radar chart** comparing all 3 prompts (use the radar chart code from Part 4 as a reference)\n4. In a comment, explain which CRAFT component changes the most across audiences and why",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ── Prompt for Engineering Team ──────────────────────────────────\nprompt_engineering = CRAFTPrompt(\n    context=\"Our company completed the Q3 AI initiative, deploying a \"\n            \"recommendation engine and automated data pipeline. The engineering \"\n            \"team needs a technical retrospective.\",\n    role=\"a senior ML engineer summarizing for a technical audience\",\n    action=\"Write a technical summary of the Q3 AI initiative results, \"\n           \"including model architecture decisions, performance benchmarks \"\n           \"(latency, accuracy, throughput), infrastructure costs, and \"\n           \"technical debt identified during the project.\",\n    format_spec=\"Use sections: Architecture Overview, Performance Metrics \"\n                \"(table with before/after comparisons), Infrastructure \"\n                \"(bullet points), and Technical Debt (numbered list of 3 items).\",\n    tone=\"Technical, precise, and data-driven\"\n)\n\n# ── Prompt for VP of Product ─────────────────────────────────────\nprompt_vp = CRAFTPrompt(\n    context=\"Our company completed the Q3 AI initiative. The VP of Product \"\n            \"needs to understand roadmap impact and resource allocation \"\n            \"for Q4 planning.\",\n    role=\"a product strategy lead summarizing for senior product leadership\",\n    action=\"Summarize the Q3 AI initiative outcomes in terms of product \"\n           \"impact, including features shipped, user engagement metrics, \"\n           \"resource utilization vs. plan, and recommended Q4 priorities.\",\n    format_spec=\"Executive brief: 3-sentence summary, then bullet points \"\n                \"for key outcomes, a comparison table of planned vs. actual \"\n                \"milestones, and a numbered list of Q4 recommendations.\",\n    tone=\"Strategic, concise, and action-oriented\"\n)\n\n# ── Prompt for CEO ───────────────────────────────────────────────\nprompt_ceo = CRAFTPrompt(\n    context=\"Our company completed the Q3 AI initiative. The CEO is \"\n            \"presenting to the board and needs a high-level view of \"\n            \"business value delivered and competitive positioning.\",\n    role=\"a chief of staff preparing an executive briefing for the CEO\",\n    action=\"Create a business-value summary of the Q3 AI initiative, \"\n           \"including revenue impact, customer retention improvements, \"\n           \"competitive advantages gained, and 3 strategic recommendations \"\n           \"for scaling AI investment.\",\n    format_spec=\"One-page executive summary: 2-sentence headline, then \"\n                \"3 bullet points for key business outcomes, and a numbered \"\n                \"list of strategic recommendations.\",\n    tone=\"Executive, high-level, and business-focused\"\n)\n\n# Score all three\nprint(\"=== Engineering Team ===\")\ns_eng = score_prompt(prompt_engineering.build())\nt_eng = sum(s_eng.values())\n\nprint(\"=== VP of Product ===\")\ns_vp = score_prompt(prompt_vp.build())\nt_vp = sum(s_vp.values())\n\nprint(\"=== CEO ===\")\ns_ceo = score_prompt(prompt_ceo.build())\nt_ceo = sum(s_ceo.values())\n\nprint(f\"Engineering: {t_eng}/25 | VP: {t_vp}/25 | CEO: {t_ceo}/25\")\nprint(f\"All 18+? {all(t >= 18 for t in [t_eng, t_vp, t_ceo])}\")\n\n# ── Radar Chart: Compare all 3 audiences ────────────────────────\ndimensions = list(s_eng.keys())\nn_dims = len(dimensions)\nangles = np.linspace(0, 2 * np.pi, n_dims, endpoint=False).tolist()\nangles += angles[:1]\n\ndef values_for(scores):\n    vals = [scores[d] for d in dimensions]\n    return vals + vals[:1]\n\nfig, ax = plt.subplots(figsize=(7, 7), subplot_kw=dict(polar=True))\n\nax.plot(angles, values_for(s_eng), 'o-', linewidth=2,\n        label=f'Engineering ({t_eng}/25)', color='#3498db')\nax.fill(angles, values_for(s_eng), alpha=0.10, color='#3498db')\n\nax.plot(angles, values_for(s_vp), 's-', linewidth=2,\n        label=f'VP Product ({t_vp}/25)', color='#e74c3c')\nax.fill(angles, values_for(s_vp), alpha=0.10, color='#e74c3c')\n\nax.plot(angles, values_for(s_ceo), 'D-', linewidth=2,\n        label=f'CEO ({t_ceo}/25)', color='#27ae60')\nax.fill(angles, values_for(s_ceo), alpha=0.15, color='#27ae60')\n\nax.set_xticks(angles[:-1])\nax.set_xticklabels([d.capitalize() for d in dimensions], fontsize=12)\nax.set_yticks([1, 2, 3, 4, 5])\nax.set_yticklabels(['1', '2', '3', '4', '5'], fontsize=9, color='grey')\nax.set_ylim(0, 5)\nax.set_title('Audience Pivot: Prompt Quality Comparison', fontsize=15,\n             fontweight='bold', pad=20)\nax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=11)\nplt.tight_layout()\nplt.show()\n\n# Reflection\nmost_changed_component = \"Action and Format\"\nexplanation = (\"The Action changes the most because each audience needs different \"\n               \"information extracted from the same initiative — engineers want \"\n               \"benchmarks and architecture, VPs want roadmap and resources, \"\n               \"CEOs want revenue impact and competitive positioning. Format \"\n               \"also shifts significantly as technical audiences expect detailed \"\n               \"tables while executives prefer concise bullet points.\")\nprint(f\"\\nMost changed component: {most_changed_component}\")\nprint(f\"Explanation: {explanation}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Exercise 5: The Prompt Audit (Challenge) (10 min)\n\nBelow are three prompts that all score **21 or higher** on our scoring function. But high scores don't guarantee real-world effectiveness. Each prompt has a hidden practical problem that would hurt its output quality when used with a real AI.\n\n**Your task:**\n1. Run the cell to see each prompt and its score\n2. Identify the hidden real-world problem in each prompt (it won't show up in the score)\n3. Rank the three prompts from **most effective** to **least effective** in practice\n4. Write a 2-3 sentence justification for your ranking\n\n**Possible problem types:** conflicting instructions, impossible constraints, missing critical context, overspecification that restricts useful output, scope creep",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ── Audit Prompt A: Conflicting Instructions ─────────────────────\naudit_a = (\n    \"Context: Our company is launching a new product in the healthcare \"\n    \"industry targeting hospital administrators and clinical stakeholders. \"\n    \"Role: Act as a senior marketing strategist with 15 years experience. \"\n    \"Task: Write a 100-word executive summary that comprehensively covers \"\n    \"all 12 market segments, including 3 detailed case studies with full \"\n    \"financial breakdowns for each, a competitive landscape analysis of \"\n    \"the top 8 competitors, and a 5-year revenue projection model. \"\n    \"Format: Use bullet points, numbered lists, and a comparison table. \"\n    \"Tone: Concise and precisely data-driven.\"\n)\n\n# ── Audit Prompt B: Scope Creep ──────────────────────────────────\naudit_b = (\n    \"Context: We are a fintech company preparing for a board meeting. \"\n    \"The audience is our board of directors and key stakeholders. \"\n    \"Role: Act as a financial analyst and also a product designer and \"\n    \"also a legal compliance officer and also a marketing strategist. \"\n    \"Task: Write a board presentation that covers Q3 financial results, \"\n    \"redesign the customer onboarding flow, draft new compliance policies \"\n    \"for 5 regions, create a marketing campaign for the next product \"\n    \"launch, and build a competitive analysis of the market sector. \"\n    \"Format: Structured report with numbered sections, bullet points, \"\n    \"and a summary table. Include 10 items per section. \"\n    \"Tone: Professional, specifically precise, and must be actionable.\"\n)\n\n# ── Audit Prompt C: Missing Critical Context ─────────────────────\naudit_c = (\n    \"Context: Based on the data from last quarter, our company needs to \"\n    \"make a strategic decision. The team is evaluating multiple options \"\n    \"in our industry sector. \"\n    \"Role: Act as a management consultant at a top-tier strategy firm \"\n    \"specializing in our specific market and customer segment. \"\n    \"Task: Analyze the situation and recommend precisely which option \"\n    \"we should pursue, including a comparison table of 3 alternatives \"\n    \"with estimated ROI for each stakeholder group. \"\n    \"Format: Executive summary (5 sentences), then bullet points for each \"\n    \"option, then a numbered list of 3 recommendations. \"\n    \"Tone: Authoritative, data-driven, and specifically actionable.\"\n)\n\n# Score all three\nprint(\"=== AUDIT PROMPT A ===\")\nprint(audit_a)\nprint()\nsa = score_prompt(audit_a)\n\nprint(\"=== AUDIT PROMPT B ===\")\nprint(audit_b)\nprint()\nsb = score_prompt(audit_b)\n\nprint(\"=== AUDIT PROMPT C ===\")\nprint(audit_c)\nprint()\nsc = score_prompt(audit_c)\n\nprint(f\"Prompt A: {sum(sa.values())}/25 | \"\n      f\"Prompt B: {sum(sb.values())}/25 | \"\n      f\"Prompt C: {sum(sc.values())}/25\")\n\n\n# Identify the hidden problems\nproblem_a = (\"Conflicting constraints: asks for 100 words but demands comprehensive \"\n             \"coverage of 12 market segments, 3 detailed case studies with full \"\n             \"financial breakdowns, competitive analysis of 8 competitors, and a \"\n             \"5-year projection. This is physically impossible in 100 words.\")\n\nproblem_b = (\"Scope creep: assigns 4 different expert roles and 5 unrelated tasks. \"\n             \"No single response can be a board presentation AND a UX redesign AND \"\n             \"compliance policies AND a marketing campaign AND a competitive analysis. \"\n             \"The output will be shallow across all areas.\")\n\nproblem_c = (\"Missing critical context: uses vague references throughout — 'the data', \"\n             \"'our company', 'multiple options', 'our industry sector', 'our specific \"\n             \"market'. An AI has no way to know what any of these refer to, so the \"\n             \"output will be generic filler despite the authoritative tone.\")\n\n# Ranking\nranking = [\"A\", \"C\", \"B\"]\n\njustification = (\"Prompt A is most effective despite its impossible length constraint \"\n                 \"because the core request is coherent — a skilled user could simply \"\n                 \"remove the word limit. Prompt C is second because adding specific \"\n                 \"context would make it functional. Prompt B is least effective because \"\n                 \"the fundamental design is flawed — no amount of tweaking fixes the \"\n                 \"problem of asking one prompt to do 5 unrelated jobs requiring 4 \"\n                 \"different domains of expertise.\")\n\nprint(f\"\\nProblem A: {problem_a}\")\nprint(f\"\\nProblem B: {problem_b}\")\nprint(f\"\\nProblem C: {problem_c}\")\nprint(f\"\\nRanking (most to least effective): {ranking}\")\nprint(f\"\\nJustification: {justification}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}