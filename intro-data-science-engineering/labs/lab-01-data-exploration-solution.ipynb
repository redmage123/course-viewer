{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Data Exploration & Visualization - SOLUTIONS\n",
    "\n",
    "**Introduction to Data Science & Engineering - Day 1**\n",
    "\n",
    "| Duration | Difficulty | Framework | Exercises |\n",
    "|---|---|---|---|\n",
    "| 90 min | Beginner | pandas, matplotlib, seaborn | 5 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "n_samples = 2000\n",
    "\n",
    "# Generate dates over 2 years\n",
    "start_date = datetime(2023, 1, 1)\n",
    "dates = [start_date + timedelta(days=np.random.randint(0, 730)) for _ in range(n_samples)]\n",
    "\n",
    "# Customer segments\n",
    "segments = np.random.choice(['Premium', 'Standard', 'Basic', None], n_samples, p=[0.2, 0.4, 0.3, 0.1])\n",
    "\n",
    "# Product categories\n",
    "categories = np.random.choice(['Electronics', 'Clothing', 'Home & Garden', 'Books', 'Sports'], n_samples)\n",
    "\n",
    "data = {\n",
    "    'order_id': range(1, n_samples + 1),\n",
    "    'customer_id': np.random.randint(100, 600, n_samples),\n",
    "    'order_date': dates,\n",
    "    'product_category': categories,\n",
    "    'quantity': np.random.randint(1, 10, n_samples),\n",
    "    'unit_price': np.round(np.random.uniform(5, 500, n_samples), 2),\n",
    "    'customer_segment': segments,\n",
    "    'customer_age': np.random.randint(18, 75, n_samples).astype(float),\n",
    "    'satisfaction_score': np.random.choice([1, 2, 3, 4, 5, np.nan], n_samples, p=[0.05, 0.1, 0.2, 0.35, 0.2, 0.1]),\n",
    "    'region': np.random.choice(['North', 'South', 'East', 'West'], n_samples),\n",
    "    'is_returned': np.random.choice([0, 1], n_samples, p=[0.85, 0.15])\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Inject quality issues\n",
    "df.loc[np.random.choice(df.index, 80, replace=False), 'customer_age'] = np.nan\n",
    "df.loc[np.random.choice(df.index, 40, replace=False), 'unit_price'] = np.nan\n",
    "df.loc[np.random.choice(df.index, 10, replace=False), 'unit_price'] = np.random.uniform(2000, 5000, 10)\n",
    "df.loc[np.random.choice(df.index, 5, replace=False), 'quantity'] = np.random.randint(50, 100, 5)\n",
    "\n",
    "dup_indices = np.random.choice(df.index, 15, replace=False)\n",
    "duplicates = df.loc[dup_indices].copy()\n",
    "df = pd.concat([df, duplicates], ignore_index=True)\n",
    "df['total_amount'] = df['quantity'] * df['unit_price']\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.1: Basic Exploration - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types and shape\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "print(f\"\\nMemory Usage: {df.memory_usage(deep=True).sum() / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df) * 100).round(1)\n",
    "pd.DataFrame({'Missing': missing, 'Percent': missing_pct}).query('Missing > 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "print(f\"Duplicate rows: {df.duplicated().sum()}\")\n",
    "print(f\"Duplicate order_ids: {df['order_id'].duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.1: Handle Missing Values - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(df):\n",
    "    \"\"\"Handle missing values in the dataset.\"\"\"\n",
    "    df['customer_age'].fillna(df['customer_age'].median(), inplace=True)\n",
    "    df['unit_price'].fillna(df['unit_price'].median(), inplace=True)\n",
    "    df['satisfaction_score'].fillna(df['satisfaction_score'].median(), inplace=True)\n",
    "    df['customer_segment'].fillna('Unknown', inplace=True)\n",
    "    df['total_amount'] = df['quantity'] * df['unit_price']\n",
    "    return df\n",
    "\n",
    "df = handle_missing_values(df)\n",
    "print(\"Missing values after cleaning:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.2: Remove Duplicates - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(df):\n",
    "    \"\"\"Remove duplicate orders, keeping the first occurrence.\"\"\"\n",
    "    initial_len = len(df)\n",
    "    df = df.drop_duplicates(subset='order_id', keep='first')\n",
    "    removed = initial_len - len(df)\n",
    "    return df, removed\n",
    "\n",
    "df, removed = remove_duplicates(df)\n",
    "print(f\"Removed {removed} duplicate rows\")\n",
    "print(f\"Clean dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.3: Detect Outliers - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_iqr(series, factor=1.5):\n",
    "    \"\"\"Detect outliers using the IQR method.\"\"\"\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - factor * IQR\n",
    "    upper = Q3 + factor * IQR\n",
    "    outliers = series[(series < lower) | (series > upper)]\n",
    "    return outliers, lower, upper\n",
    "\n",
    "for col in ['unit_price', 'quantity', 'total_amount']:\n",
    "    outliers, lower, upper = detect_outliers_iqr(df[col])\n",
    "    print(f\"{col}: {len(outliers)} outliers (range: {lower:.2f} to {upper:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize outliers with box plots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "for ax, col in zip(axes, ['unit_price', 'quantity', 'total_amount']):\n",
    "    sns.boxplot(data=df, y=col, ax=ax, color='#3b82f6')\n",
    "    ax.set_title(f'{col} Distribution')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.1: Distribution Analysis - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distributions(df):\n",
    "    \"\"\"Plot distributions of key numeric features.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "    sns.histplot(df['unit_price'], bins=50, ax=axes[0,0], color='#3b82f6', kde=True)\n",
    "    axes[0,0].set_title('Unit Price Distribution')\n",
    "\n",
    "    sns.histplot(df['customer_age'], bins=30, ax=axes[0,1], color='#8b5cf6', kde=True)\n",
    "    axes[0,1].set_title('Customer Age Distribution')\n",
    "\n",
    "    sns.histplot(df['quantity'], bins=20, ax=axes[1,0], color='#10b981', kde=True)\n",
    "    axes[1,0].set_title('Quantity Distribution')\n",
    "\n",
    "    sns.histplot(df['satisfaction_score'].dropna(), bins=5, ax=axes[1,1], color='#f59e0b', kde=False)\n",
    "    axes[1,1].set_title('Satisfaction Score Distribution')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_distributions(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.2: Correlation Analysis - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation_matrix(df):\n",
    "    \"\"\"Compute and visualize the correlation matrix for numeric columns.\"\"\"\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    corr_matrix = df[numeric_cols].corr()\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f',\n",
    "                linewidths=0.5, square=True)\n",
    "    plt.title('Correlation Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_correlation_matrix(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.1: Category Analysis - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_categories(df):\n",
    "    \"\"\"Analyze sales by product category.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    category_revenue = df.groupby('product_category')['total_amount'].sum().sort_values(ascending=True)\n",
    "    category_revenue.plot(kind='barh', ax=axes[0], color='#3b82f6')\n",
    "    axes[0].set_title('Total Revenue by Category')\n",
    "    axes[0].set_xlabel('Revenue ($)')\n",
    "\n",
    "    category_counts = df['product_category'].value_counts()\n",
    "    axes[1].pie(category_counts, labels=category_counts.index, autopct='%1.1f%%',\n",
    "               colors=['#3b82f6', '#8b5cf6', '#10b981', '#f59e0b', '#ef4444'])\n",
    "    axes[1].set_title('Order Distribution by Category')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "analyze_categories(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.2: Customer Segmentation Analysis - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_segments(df):\n",
    "    \"\"\"Analyze customer segments.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    segment_stats = df.groupby('customer_segment')['total_amount'].agg(['mean', 'count'])\n",
    "    segment_stats['mean'].sort_values().plot(kind='barh', ax=axes[0], color='#8b5cf6')\n",
    "    axes[0].set_title('Average Order Value by Segment')\n",
    "    axes[0].set_xlabel('Average Amount ($)')\n",
    "\n",
    "    sns.boxplot(data=df, x='customer_segment', y='satisfaction_score', ax=axes[1],\n",
    "               order=['Basic', 'Standard', 'Premium', 'Unknown'], palette='viridis')\n",
    "    axes[1].set_title('Satisfaction Score by Segment')\n",
    "    axes[1].set_xlabel('Segment')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "analyze_segments(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.3: Time Series Analysis - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_time_series(df):\n",
    "    \"\"\"Analyze trends over time.\"\"\"\n",
    "    df['order_month'] = df['order_date'].dt.to_period('M')\n",
    "\n",
    "    monthly_stats = df.groupby('order_month').agg(\n",
    "        revenue=('total_amount', 'sum'),\n",
    "        orders=('order_id', 'count'),\n",
    "        avg_order=('total_amount', 'mean')\n",
    "    ).reset_index()\n",
    "    monthly_stats['order_month'] = monthly_stats['order_month'].astype(str)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "    axes[0].plot(monthly_stats['order_month'], monthly_stats['revenue'], \n",
    "                marker='o', color='#3b82f6', linewidth=2)\n",
    "    axes[0].set_title('Monthly Revenue Trend')\n",
    "    axes[0].set_ylabel('Revenue ($)')\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    axes[1].bar(monthly_stats['order_month'], monthly_stats['orders'], color='#8b5cf6', alpha=0.7)\n",
    "    axes[1].set_title('Monthly Order Count')\n",
    "    axes[1].set_ylabel('Number of Orders')\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "analyze_time_series(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.4: Regional Analysis - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_regions(df):\n",
    "    \"\"\"Analyze performance by region.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    region_revenue = df.groupby('region')['total_amount'].sum().sort_values(ascending=True)\n",
    "    region_revenue.plot(kind='barh', ax=axes[0], color=['#ef4444', '#f59e0b', '#10b981', '#3b82f6'])\n",
    "    axes[0].set_title('Revenue by Region')\n",
    "    axes[0].set_xlabel('Total Revenue ($)')\n",
    "\n",
    "    region_returns = df.groupby('region')['is_returned'].mean() * 100\n",
    "    region_returns.sort_values().plot(kind='barh', ax=axes[1], color=['#ef4444', '#f59e0b', '#10b981', '#3b82f6'])\n",
    "    axes[1].set_title('Return Rate by Region (%)')\n",
    "    axes[1].set_xlabel('Return Rate (%)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "analyze_regions(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5.1: Multi-dimensional Analysis - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_dimensional_analysis(df):\n",
    "    \"\"\"Create a comprehensive 2x2 multi-dimensional visualization.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "    # Scatter: Age vs Total Amount colored by segment\n",
    "    for segment in df['customer_segment'].unique():\n",
    "        mask = df['customer_segment'] == segment\n",
    "        axes[0,0].scatter(df.loc[mask, 'customer_age'], df.loc[mask, 'total_amount'],\n",
    "                          alpha=0.5, label=segment, s=20)\n",
    "    axes[0,0].set_title('Age vs Order Amount by Segment')\n",
    "    axes[0,0].set_xlabel('Customer Age')\n",
    "    axes[0,0].set_ylabel('Total Amount')\n",
    "    axes[0,0].legend()\n",
    "\n",
    "    # Heatmap: Category x Region\n",
    "    pivot = df.pivot_table(values='total_amount', index='product_category',\n",
    "                           columns='region', aggfunc='mean')\n",
    "    sns.heatmap(pivot, annot=True, fmt='.0f', cmap='YlOrRd', ax=axes[0,1])\n",
    "    axes[0,1].set_title('Avg Order Value: Category x Region')\n",
    "\n",
    "    # Return rate by category\n",
    "    return_by_cat = df.groupby('product_category')['is_returned'].mean() * 100\n",
    "    return_by_cat.sort_values().plot(kind='barh', ax=axes[1,0], color='#ef4444')\n",
    "    axes[1,0].set_title('Return Rate by Category (%)')\n",
    "\n",
    "    # Satisfaction distribution by return status\n",
    "    sns.violinplot(data=df, x='is_returned', y='satisfaction_score', ax=axes[1,1], palette='coolwarm')\n",
    "    axes[1,1].set_title('Satisfaction: Returned vs Not Returned')\n",
    "    axes[1,1].set_xticks([0, 1])\n",
    "    axes[1,1].set_xticklabels(['Kept', 'Returned'])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "multi_dimensional_analysis(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, you learned how to:\n",
    "\n",
    "1. **Generate and load** synthetic datasets with realistic quality issues\n",
    "2. **Assess data quality** -- missing values, duplicates, outliers\n",
    "3. **Clean data** using imputation, deduplication, and outlier detection\n",
    "4. **Compute statistics** and analyze distributions\n",
    "5. **Visualize data** with bar charts, histograms, scatter plots, heatmaps\n",
    "6. **Analyze trends** over time using time series grouping\n",
    "7. **Segment customers** and compare across dimensions\n",
    "\n",
    "---\n",
    "\n",
    "*Introduction to Data Science & Engineering | AI Elevate*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}