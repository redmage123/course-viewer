{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Lab 2: Machine Learning with PyTorch - SOLUTIONS\n\n## From Classical ML to Deep Learning Foundations\n\n**Duration:** 90-120 minutes | **Difficulty:** Intermediate | **Prerequisites:** Lab 1\n\n**This notebook contains all solutions. Use for reference after attempting the exercises.**\n\n---\n\n## Overview\n\nThis lab bridges classical machine learning and deep learning by teaching PyTorch fundamentals through hands-on implementation of ML algorithms. You'll learn to build, train, and evaluate models using the same patterns used in production deep learning systems.\n\n### Lab Structure\n\n| Part | Topic | Key Concepts |\n|------|-------|--------------|\n| **Part 1** | PyTorch Tensors | Creating tensors, tensor operations, automatic differentiation (autograd) |\n| **Part 2** | Linear Regression | Training loop from scratch, MSE loss, nn.Module, gradient descent |\n| **Part 3** | Logistic Regression | Sigmoid function, BCE loss, binary classification, decision boundaries |\n| **Part 4** | Support Vector Machines | Kernel trick (linear, RBF, polynomial), margins, support vectors |\n| **Part 5** | Model Evaluation | Confusion matrix, precision, recall, F1-score, classification report |\n\n### Key Pattern You'll Learn\n\nThe PyTorch training loop used in all deep learning:\n\n```python\nfor epoch in range(n_epochs):\n    y_pred = model(X)           # Forward pass\n    loss = criterion(y_pred, y) # Compute loss\n    optimizer.zero_grad()       # Clear gradients\n    loss.backward()             # Backward pass\n    optimizer.step()            # Update weights\n```\n\n---"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification, make_moons\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(\"Setup Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: PyTorch Tensors - Solutions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# EXERCISE 1.1 SOLUTION: Create Tensors\n",
    "# ============================================\n",
    "\n",
    "# a) Create a tensor containing [10, 20, 30, 40, 50]\n",
    "tensor_a = torch.tensor([10, 20, 30, 40, 50])\n",
    "\n",
    "# b) Create a 3x4 tensor filled with zeros\n",
    "tensor_b = torch.zeros(3, 4)\n",
    "\n",
    "# c) Create a 2x5 tensor with random values (uniform)\n",
    "tensor_c = torch.rand(2, 5)\n",
    "\n",
    "# ---- Test ----\n",
    "print(f\"a) {tensor_a}\")\n",
    "print(f\"b) Shape: {tensor_b.shape}\")\n",
    "print(f\"c) Random tensor with shape {tensor_c.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# EXERCISE 1.2 SOLUTION: Tensor Operations\n",
    "# ============================================\n",
    "\n",
    "x = torch.tensor([[1., 2., 3.], [4., 5., 6.]])\n",
    "y = torch.tensor([[7., 8., 9.], [10., 11., 12.]])\n",
    "\n",
    "print(\"x =\")\n",
    "print(x)\n",
    "print(\"\\ny =\")\n",
    "print(y)\n",
    "print()\n",
    "\n",
    "# a) Add x and y element-wise\n",
    "result_add = x + y\n",
    "\n",
    "# b) Calculate the mean of x\n",
    "result_mean = x.mean()\n",
    "\n",
    "# c) Calculate the sum of each row of x (dim=1)\n",
    "result_row_sum = x.sum(dim=1)\n",
    "\n",
    "# d) Reshape x to be 3 rows x 2 columns\n",
    "result_reshape = x.reshape(3, 2)\n",
    "\n",
    "# ---- Test ----\n",
    "print(f\"a) x + y =\\n{result_add}\")\n",
    "print(f\"\\nb) Mean of x = {result_mean}\")\n",
    "print(f\"\\nc) Sum of each row = {result_row_sum}\")\n",
    "print(f\"\\nd) x reshaped to 3x2:\\n{result_reshape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# EXERCISE 1.3 SOLUTION: Practice with Autograd\n",
    "# ============================================\n",
    "\n",
    "# Create x = 2.0 with gradient tracking\n",
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "\n",
    "# Compute y = 3x² - 4x + 5\n",
    "y = 3*x**2 - 4*x + 5\n",
    "\n",
    "# Compute the gradient\n",
    "y.backward()\n",
    "\n",
    "# ---- Test ----\n",
    "print(f\"y = 3x² - 4x + 5 at x=2: y = {y.item()}\")\n",
    "print(f\"dy/dx = 6x - 4 at x=2: dy/dx = {x.grad.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: Linear Regression - Solutions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Generate data\n",
    "np.random.seed(42)\n",
    "n_samples = 100\n",
    "X_np = np.random.rand(n_samples, 1) * 10\n",
    "y_np = 3 * X_np + 2 + np.random.randn(n_samples, 1) * 1.5\n",
    "X = torch.tensor(X_np, dtype=torch.float32)\n",
    "y = torch.tensor(y_np, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# EXERCISE 2.1 SOLUTION: Build Linear Regression\n",
    "# ============================================\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# Define the model\n",
    "class MyLinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # SOLUTION: Create a linear layer (1 input, 1 output)\n",
    "        self.linear = nn.Linear(1, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # SOLUTION: Return the output of the linear layer\n",
    "        return self.linear(x)\n",
    "\n",
    "# Create model, loss function, and optimizer\n",
    "my_model = MyLinearRegression()\n",
    "my_criterion = nn.MSELoss()  # SOLUTION\n",
    "my_optimizer = optim.SGD(my_model.parameters(), lr=0.01)  # SOLUTION\n",
    "\n",
    "# Training loop\n",
    "my_losses = []\n",
    "for epoch in range(100):\n",
    "    # SOLUTION: Complete the training loop\n",
    "    # 1. Forward pass\n",
    "    y_pred = my_model(X)\n",
    "    \n",
    "    # 2. Compute loss\n",
    "    loss = my_criterion(y_pred, y)\n",
    "    \n",
    "    # 3. Zero gradients\n",
    "    my_optimizer.zero_grad()\n",
    "    \n",
    "    # 4. Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # 5. Update weights\n",
    "    my_optimizer.step()\n",
    "    \n",
    "    my_losses.append(loss.item())\n",
    "    \n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        print(f'Epoch {epoch+1}/100 | Loss: {loss.item():.4f}')\n",
    "\n",
    "# Print results\n",
    "print(f\"\\nLearned: w = {my_model.linear.weight.item():.4f}, b = {my_model.linear.bias.item():.4f}\")\n",
    "print(f\"True:    w = 3.0000, b = 2.0000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 3: Logistic Regression - Solutions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Generate classification data\n",
    "X_class, y_class = make_classification(\n",
    "    n_samples=300, n_features=2, n_redundant=0, n_informative=2,\n",
    "    n_clusters_per_class=1, random_state=42\n",
    ")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_class, y_class, test_size=0.2, random_state=42\n",
    ")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train_t = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "X_test_t = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
    "y_test_t = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# EXERCISE 3.1 SOLUTION: Build a Classifier\n",
    "# ============================================\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "class MyClassifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        # SOLUTION: Create linear layer and sigmoid\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # SOLUTION: Apply linear then sigmoid\n",
    "        z = self.linear(x)\n",
    "        return self.sigmoid(z)\n",
    "\n",
    "# Create model, loss, and optimizer\n",
    "my_classifier = MyClassifier(input_dim=2)\n",
    "my_bce_loss = nn.BCELoss()  # SOLUTION\n",
    "my_opt = optim.Adam(my_classifier.parameters(), lr=0.1)  # SOLUTION\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    # SOLUTION: Complete the training loop\n",
    "    y_pred = my_classifier(X_train_t)\n",
    "    loss = my_bce_loss(y_pred, y_train_t)\n",
    "    \n",
    "    my_opt.zero_grad()\n",
    "    loss.backward()\n",
    "    my_opt.step()\n",
    "    \n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        acc = ((y_pred >= 0.5).float() == y_train_t).float().mean()\n",
    "        print(f'Epoch {epoch+1}/100 | Loss: {loss.item():.4f} | Acc: {acc.item():.4f}')\n",
    "\n",
    "# Test accuracy\n",
    "my_classifier.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = my_classifier(X_test_t)\n",
    "    y_class = (y_pred >= 0.5).float()\n",
    "    acc = (y_class == y_test_t).float().mean()\n",
    "print(f\"\\nTest Accuracy: {acc.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 4: Support Vector Machines - Solutions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Generate moons data\n",
    "X_moons, y_moons = make_moons(n_samples=300, noise=0.2, random_state=42)\n",
    "X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(\n",
    "    X_moons, y_moons, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# EXERCISE 4.1 SOLUTION: Train an SVM\n",
    "# ============================================\n",
    "\n",
    "# a) Create an RBF SVM with C=10\n",
    "my_svm = SVC(kernel='rbf', C=10)  # SOLUTION\n",
    "\n",
    "# b) Fit it on the training data\n",
    "my_svm.fit(X_train_m, y_train_m)  # SOLUTION\n",
    "\n",
    "# c) Calculate test accuracy\n",
    "accuracy = my_svm.score(X_test_m, y_test_m)\n",
    "n_support = len(my_svm.support_vectors_)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Number of Support Vectors: {n_support}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 5: Model Evaluation - Solutions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Train a logistic regression model for evaluation\n",
    "torch.manual_seed(42)\n",
    "\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.linear(x))\n",
    "\n",
    "log_model = LogisticRegressionModel(input_dim=2)\n",
    "criterion_bce = nn.BCELoss()\n",
    "optimizer_log = optim.Adam(log_model.parameters(), lr=0.1)\n",
    "\n",
    "for epoch in range(100):\n",
    "    y_pred_prob = log_model(X_train_t)\n",
    "    loss = criterion_bce(y_pred_prob, y_train_t)\n",
    "    optimizer_log.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer_log.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# EXERCISE 5.1 SOLUTION: Evaluate Your Model\n",
    "# ============================================\n",
    "\n",
    "# Get predictions from the logistic regression model\n",
    "log_model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_prob = log_model(X_test_t)\n",
    "    y_pred_log = (y_pred_prob >= 0.5).numpy().astype(int).flatten()\n",
    "\n",
    "# a) Create confusion matrix\n",
    "cm_log = confusion_matrix(y_test, y_pred_log)  # SOLUTION\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_log)\n",
    "print()\n",
    "\n",
    "# b) Print classification report\n",
    "print(\"Classification Report:\")  # SOLUTION\n",
    "print(classification_report(y_test, y_pred_log, target_names=['Class 0', 'Class 1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Solutions Summary\n",
    "\n",
    "## Exercise 1.1: Create Tensors\n",
    "```python\n",
    "tensor_a = torch.tensor([10, 20, 30, 40, 50])\n",
    "tensor_b = torch.zeros(3, 4)\n",
    "tensor_c = torch.rand(2, 5)\n",
    "```\n",
    "\n",
    "## Exercise 1.2: Tensor Operations\n",
    "```python\n",
    "result_add = x + y\n",
    "result_mean = x.mean()\n",
    "result_row_sum = x.sum(dim=1)\n",
    "result_reshape = x.reshape(3, 2)\n",
    "```\n",
    "\n",
    "## Exercise 1.3: Autograd\n",
    "```python\n",
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "y = 3*x**2 - 4*x + 5\n",
    "y.backward()\n",
    "```\n",
    "\n",
    "## Exercise 2.1: Linear Regression\n",
    "```python\n",
    "self.linear = nn.Linear(1, 1)\n",
    "return self.linear(x)\n",
    "my_criterion = nn.MSELoss()\n",
    "my_optimizer = optim.SGD(my_model.parameters(), lr=0.01)\n",
    "```\n",
    "\n",
    "## Exercise 3.1: Logistic Regression\n",
    "```python\n",
    "self.linear = nn.Linear(input_dim, 1)\n",
    "self.sigmoid = nn.Sigmoid()\n",
    "return self.sigmoid(self.linear(x))\n",
    "my_bce_loss = nn.BCELoss()\n",
    "my_opt = optim.Adam(my_classifier.parameters(), lr=0.1)\n",
    "```\n",
    "\n",
    "## Exercise 4.1: SVM\n",
    "```python\n",
    "my_svm = SVC(kernel='rbf', C=10)\n",
    "my_svm.fit(X_train_m, y_train_m)\n",
    "```\n",
    "\n",
    "## Exercise 5.1: Evaluation\n",
    "```python\n",
    "cm_log = confusion_matrix(y_test, y_pred_log)\n",
    "print(classification_report(y_test, y_pred_log))\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}