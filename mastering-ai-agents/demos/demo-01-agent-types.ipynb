{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: Reactive vs Deliberative Agents\n",
    "\n",
    "This demo compares reactive and deliberative agents navigating through different environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "from collections import deque\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorld:\n",
    "    \"\"\"A grid world with obstacles\"\"\"\n",
    "    \n",
    "    def __init__(self, width: int = 20, height: int = 20):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.grid = np.zeros((height, width))\n",
    "        self.start = (1, 1)\n",
    "        self.goal = (height - 2, width - 2)\n",
    "    \n",
    "    def add_obstacle(self, x: int, y: int):\n",
    "        self.grid[y, x] = 1\n",
    "    \n",
    "    def add_wall(self, x1: int, y1: int, x2: int, y2: int):\n",
    "        for x in range(min(x1, x2), max(x1, x2) + 1):\n",
    "            for y in range(min(y1, y2), max(y1, y2) + 1):\n",
    "                self.grid[y, x] = 1\n",
    "    \n",
    "    def is_valid(self, pos: tuple) -> bool:\n",
    "        x, y = pos\n",
    "        if 0 <= x < self.width and 0 <= y < self.height:\n",
    "            return self.grid[y, x] == 0\n",
    "        return False\n",
    "    \n",
    "    def get_neighbors(self, pos: tuple) -> list:\n",
    "        x, y = pos\n",
    "        neighbors = []\n",
    "        for dx, dy in [(0, 1), (1, 0), (0, -1), (-1, 0)]:\n",
    "            new_pos = (x + dx, y + dy)\n",
    "            if self.is_valid(new_pos):\n",
    "                neighbors.append(new_pos)\n",
    "        return neighbors\n",
    "\n",
    "class ReactiveNavigator:\n",
    "    \"\"\"Reactive agent: Always moves toward goal, avoids immediate obstacles\"\"\"\n",
    "    \n",
    "    def __init__(self, world: GridWorld):\n",
    "        self.world = world\n",
    "        self.position = world.start\n",
    "        self.path = [self.position]\n",
    "    \n",
    "    def move(self) -> bool:\n",
    "        if self.position == self.world.goal:\n",
    "            return True\n",
    "        \n",
    "        neighbors = self.world.get_neighbors(self.position)\n",
    "        if not neighbors:\n",
    "            return False\n",
    "        \n",
    "        # Greedy: move toward goal\n",
    "        goal = self.world.goal\n",
    "        best = min(neighbors, key=lambda p: abs(p[0] - goal[0]) + abs(p[1] - goal[1]))\n",
    "        \n",
    "        self.position = best\n",
    "        self.path.append(self.position)\n",
    "        return self.position == self.world.goal\n",
    "\n",
    "class DeliberativeNavigator:\n",
    "    \"\"\"Deliberative agent: Plans path using A*\"\"\"\n",
    "    \n",
    "    def __init__(self, world: GridWorld):\n",
    "        self.world = world\n",
    "        self.position = world.start\n",
    "        self.path = []\n",
    "        self.plan = self._astar()\n",
    "        self.step_idx = 0\n",
    "    \n",
    "    def _heuristic(self, a: tuple, b: tuple) -> float:\n",
    "        return abs(a[0] - b[0]) + abs(a[1] - b[1])\n",
    "    \n",
    "    def _astar(self) -> list:\n",
    "        start = self.world.start\n",
    "        goal = self.world.goal\n",
    "        \n",
    "        open_set = [(self._heuristic(start, goal), 0, start)]\n",
    "        came_from = {}\n",
    "        g_score = {start: 0}\n",
    "        \n",
    "        while open_set:\n",
    "            _, _, current = heapq.heappop(open_set)\n",
    "            \n",
    "            if current == goal:\n",
    "                path = []\n",
    "                while current in came_from:\n",
    "                    path.append(current)\n",
    "                    current = came_from[current]\n",
    "                path.append(start)\n",
    "                return path[::-1]\n",
    "            \n",
    "            for neighbor in self.world.get_neighbors(current):\n",
    "                tentative_g = g_score[current] + 1\n",
    "                \n",
    "                if neighbor not in g_score or tentative_g < g_score[neighbor]:\n",
    "                    came_from[neighbor] = current\n",
    "                    g_score[neighbor] = tentative_g\n",
    "                    f_score = tentative_g + self._heuristic(neighbor, goal)\n",
    "                    heapq.heappush(open_set, (f_score, tentative_g, neighbor))\n",
    "        \n",
    "        return []  # No path found\n",
    "    \n",
    "    def move(self) -> bool:\n",
    "        if self.step_idx < len(self.plan):\n",
    "            self.position = self.plan[self.step_idx]\n",
    "            self.path.append(self.position)\n",
    "            self.step_idx += 1\n",
    "            return self.position == self.world.goal\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create world with obstacles\n",
    "world = GridWorld(20, 20)\n",
    "\n",
    "# Add walls that create a maze-like environment\n",
    "world.add_wall(5, 0, 5, 12)\n",
    "world.add_wall(10, 7, 10, 19)\n",
    "world.add_wall(15, 0, 15, 10)\n",
    "\n",
    "# Create agents\n",
    "reactive = ReactiveNavigator(GridWorld(20, 20))\n",
    "reactive.world = world  # Share the world\n",
    "reactive.position = world.start\n",
    "reactive.path = [world.start]\n",
    "\n",
    "deliberative = DeliberativeNavigator(world)\n",
    "\n",
    "# Run simulation\n",
    "max_steps = 200\n",
    "for _ in range(max_steps):\n",
    "    reactive.move()\n",
    "    if reactive.position == world.goal:\n",
    "        break\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "for ax, agent, title in [(axes[0], reactive, 'Reactive Agent'),\n",
    "                          (axes[1], deliberative, 'Deliberative Agent (A*)')]:\n",
    "    ax.imshow(world.grid, cmap='binary', origin='lower')\n",
    "    \n",
    "    # Plot path\n",
    "    path = np.array(agent.path if agent.path else agent.plan)\n",
    "    if len(path) > 0:\n",
    "        ax.plot(path[:, 0], path[:, 1], 'b-', linewidth=2, alpha=0.7)\n",
    "    \n",
    "    # Start and goal\n",
    "    ax.scatter(*world.start, c='green', s=200, marker='o', label='Start', zorder=5)\n",
    "    ax.scatter(*world.goal, c='red', s=200, marker='*', label='Goal', zorder=5)\n",
    "    \n",
    "    ax.set_title(f\"{title}\\nSteps: {len(agent.path) if agent.path else len(agent.plan)}\")\n",
    "    ax.legend()\n",
    "    ax.set_xlim(-0.5, world.width - 0.5)\n",
    "    ax.set_ylim(-0.5, world.height - 0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Reactive agent steps: {len(reactive.path)}\")\n",
    "print(f\"Deliberative agent steps: {len(deliberative.plan)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Observations\n",
    "\n",
    "1. **Reactive Agent**: May get stuck or take suboptimal paths because it only considers immediate neighbors\n",
    "2. **Deliberative Agent**: Finds optimal path by planning ahead using A* algorithm\n",
    "3. **Trade-off**: Deliberative is better but requires more computation upfront"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
