{
 "nbformat": 4,
 "nbformat_minor": 4,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Building Effective Prompts with the CRAFT Framework\n",
    "\n",
    "In this lab, you'll learn to systematically construct high-quality prompts using the CRAFT framework. You'll measure prompt quality, build reusable templates, and visualize the difference between vague and well-structured prompts.\n",
    "\n",
    "## Learning Objectives\n",
    "- Apply the CRAFT framework systematically to any task\n",
    "- Compare prompt quality before and after applying CRAFT\n",
    "- Build reusable prompt templates for common tasks\n",
    "\n",
    "**Duration:** 45 minutes | **Difficulty:** Beginner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Understanding Prompt Components\n",
    "\n",
    "The CRAFT framework breaks every prompt into five essential components:\n",
    "\n",
    "- **C**ontext: Background information the AI needs to understand the situation\n",
    "- **R**ole: The expert persona the AI should adopt\n",
    "- **A**ction: The specific task you want performed\n",
    "- **F**ormat: How the output should be structured (bullets, table, essay, etc.)\n",
    "- **T**one: The voice and style of the response\n",
    "\n",
    "Let's build a Python toolkit to construct and evaluate CRAFT prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import re\n",
    "import textwrap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CRAFTPrompt:\n",
    "    \"\"\"A structured prompt built using the CRAFT framework.\"\"\"\n",
    "    context: str\n",
    "    role: str\n",
    "    action: str\n",
    "    format_spec: str\n",
    "    tone: str\n",
    "\n",
    "    def build(self) -> str:\n",
    "        \"\"\"Assemble components into a formatted prompt string.\"\"\"\n",
    "        sections = []\n",
    "        if self.context:\n",
    "            sections.append(f\"Context: {self.context}\")\n",
    "        if self.role:\n",
    "            sections.append(f\"Role: Act as {self.role}.\")\n",
    "        if self.action:\n",
    "            sections.append(f\"Task: {self.action}\")\n",
    "        if self.format_spec:\n",
    "            sections.append(f\"Format: {self.format_spec}\")\n",
    "        if self.tone:\n",
    "            sections.append(f\"Tone: {self.tone}\")\n",
    "        return \"\\n\\n\".join(sections)\n",
    "\n",
    "    def summary(self) -> str:\n",
    "        \"\"\"Return a one-line summary showing which fields are filled.\"\"\"\n",
    "        filled = []\n",
    "        for label, val in [(\"C\", self.context), (\"R\", self.role),\n",
    "                           (\"A\", self.action), (\"F\", self.format_spec),\n",
    "                           (\"T\", self.tone)]:\n",
    "            status = \"YES\" if val.strip() else \"---\"\n",
    "            filled.append(f\"{label}:{status}\")\n",
    "        return \"  |  \".join(filled)\n",
    "\n",
    "\n",
    "def score_prompt(prompt_text: str) -> Dict[str, int]:\n",
    "    \"\"\"Score a prompt from 1-5 on five quality dimensions.\n",
    "\n",
    "    Dimensions:\n",
    "        clarity       - Is the request unambiguous?\n",
    "        specificity   - Does it include concrete details?\n",
    "        context       - Does it provide background information?\n",
    "        format        - Does it specify desired output structure?\n",
    "        actionability - Is there a clear, measurable action?\n",
    "\n",
    "    Scoring uses keyword and pattern analysis as a lightweight heuristic.\n",
    "    \"\"\"\n",
    "    text = prompt_text.lower()\n",
    "    words = text.split()\n",
    "    word_count = len(words)\n",
    "\n",
    "    # --- Clarity ---\n",
    "    clarity = 1\n",
    "    if word_count >= 10:\n",
    "        clarity += 1\n",
    "    if any(w in text for w in [\"specifically\", \"exactly\", \"precisely\", \"must\", \"should\"]):\n",
    "        clarity += 1\n",
    "    if not any(w in text for w in [\"something\", \"stuff\", \"things\", \"whatever\", \"etc\"]):\n",
    "        clarity += 1\n",
    "    if word_count >= 25:\n",
    "        clarity += 1\n",
    "    clarity = min(clarity, 5)\n",
    "\n",
    "    # --- Specificity ---\n",
    "    specificity = 1\n",
    "    if re.search(r'\\d+', text):\n",
    "        specificity += 1\n",
    "    if any(w in text for w in [\"example\", \"such as\", \"including\", \"e.g.\", \"for instance\"]):\n",
    "        specificity += 1\n",
    "    specific_nouns = [\"industry\", \"sector\", \"company\", \"product\", \"metric\",\n",
    "                      \"audience\", \"stakeholder\", \"customer\", \"market\", \"region\"]\n",
    "    if sum(1 for w in specific_nouns if w in text) >= 2:\n",
    "        specificity += 1\n",
    "    if word_count >= 30:\n",
    "        specificity += 1\n",
    "    specificity = min(specificity, 5)\n",
    "\n",
    "    # --- Context ---\n",
    "    context_score = 1\n",
    "    context_signals = [\"background\", \"context\", \"situation\", \"scenario\",\n",
    "                       \"currently\", \"our company\", \"the team\", \"we are\",\n",
    "                       \"given that\", \"assuming\", \"based on\"]\n",
    "    matches = sum(1 for s in context_signals if s in text)\n",
    "    context_score += min(matches, 2)\n",
    "    if word_count >= 20:\n",
    "        context_score += 1\n",
    "    if re.search(r'(role|act as|you are|persona)', text):\n",
    "        context_score += 1\n",
    "    context_score = min(context_score, 5)\n",
    "\n",
    "    # --- Format ---\n",
    "    format_score = 1\n",
    "    format_signals = [\"bullet\", \"numbered\", \"table\", \"list\", \"heading\",\n",
    "                      \"paragraph\", \"json\", \"csv\", \"markdown\", \"format\",\n",
    "                      \"structure\", \"outline\", \"section\", \"step-by-step\"]\n",
    "    fmt_matches = sum(1 for s in format_signals if s in text)\n",
    "    format_score += min(fmt_matches, 2)\n",
    "    if re.search(r'\\d+\\s*(words|sentences|paragraphs|points|items|bullets)', text):\n",
    "        format_score += 1\n",
    "    if any(w in text for w in [\"include\", \"exclude\", \"begin with\", \"end with\"]):\n",
    "        format_score += 1\n",
    "    format_score = min(format_score, 5)\n",
    "\n",
    "    # --- Actionability ---\n",
    "    actionability = 1\n",
    "    action_verbs = [\"write\", \"create\", \"generate\", \"analyze\", \"compare\",\n",
    "                    \"summarize\", \"evaluate\", \"list\", \"design\", \"draft\",\n",
    "                    \"build\", \"develop\", \"produce\", \"identify\", \"recommend\"]\n",
    "    verb_hits = sum(1 for v in action_verbs if v in text)\n",
    "    actionability += min(verb_hits, 2)\n",
    "    if re.search(r'(for|targeting|aimed at)\\s+\\w+', text):\n",
    "        actionability += 1\n",
    "    if word_count >= 15:\n",
    "        actionability += 1\n",
    "    actionability = min(actionability, 5)\n",
    "\n",
    "    scores = {\n",
    "        \"clarity\": clarity,\n",
    "        \"specificity\": specificity,\n",
    "        \"context\": context_score,\n",
    "        \"format\": format_score,\n",
    "        \"actionability\": actionability,\n",
    "    }\n",
    "\n",
    "    total = sum(scores.values())\n",
    "    max_total = 25\n",
    "\n",
    "    print(f\"{'Dimension':<16} {'Score':>5}\")\n",
    "    print(\"-\" * 23)\n",
    "    for dim, val in scores.items():\n",
    "        bar = '#' * val + '.' * (5 - val)\n",
    "        print(f\"{dim:<16} [{bar}] {val}/5\")\n",
    "    print(\"-\" * 23)\n",
    "    print(f\"{'TOTAL':<16} {total}/{max_total}\")\n",
    "    print()\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "# Quick sanity check\n",
    "print(\"=== Scoring a vague prompt ===\")\n",
    "score_prompt(\"Write about AI\")\n",
    "\n",
    "print(\"=== Scoring a detailed CRAFT prompt ===\")\n",
    "score_prompt(\n",
    "    \"Context: Our healthcare startup is preparing a board presentation. \"\n",
    "    \"Role: Act as a healthcare strategy consultant with 15 years experience. \"\n",
    "    \"Task: Write a 500-word executive summary analyzing AI adoption trends \"\n",
    "    \"in the healthcare industry, including 3 specific examples of successful \"\n",
    "    \"implementations. Format: Use bullet points for key findings followed by \"\n",
    "    \"a numbered list of recommendations. Tone: Professional and data-driven.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Before & After Analysis\n",
    "\n",
    "The real power of CRAFT becomes clear when you compare a raw, off-the-cuff prompt with its structured counterpart. Below we take three common but vague prompts, rebuild each one with CRAFT, and measure the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Before / After pairs ----------\n",
    "\n",
    "before_after: List[Tuple[str, CRAFTPrompt]] = [\n",
    "    # Pair 1 -- \"Write about AI\"\n",
    "    (\n",
    "        \"Write about AI\",\n",
    "        CRAFTPrompt(\n",
    "            context=\"Our hospital network is evaluating AI tools to reduce \"\n",
    "                    \"diagnostic errors. The audience is the clinical leadership team.\",\n",
    "            role=\"a healthcare technology analyst with expertise in clinical AI\",\n",
    "            action=\"Write a 600-word briefing on how AI-assisted diagnostics are \"\n",
    "                   \"reducing misdiagnosis rates, including 3 specific case studies \"\n",
    "                   \"from peer-reviewed research.\",\n",
    "            format_spec=\"Start with a 2-sentence executive summary, then use \"\n",
    "                        \"bullet points for each case study, and end with a \"\n",
    "                        \"numbered list of 3 recommendations.\",\n",
    "            tone=\"Professional, evidence-based, and persuasive\"\n",
    "        )\n",
    "    ),\n",
    "    # Pair 2 -- \"Summarize this\"\n",
    "    (\n",
    "        \"Summarize this\",\n",
    "        CRAFTPrompt(\n",
    "            context=\"The attached 40-page quarterly earnings report covers \"\n",
    "                    \"revenue, operating costs, and forward guidance for Q3 2025.\",\n",
    "            role=\"a senior financial analyst preparing materials for the CFO\",\n",
    "            action=\"Summarize the report into an executive briefing that \"\n",
    "                   \"highlights the 5 most critical data points, identifies \"\n",
    "                   \"2 risks, and notes any upward or downward trends.\",\n",
    "            format_spec=\"Use a structured format: one heading per section, \"\n",
    "                        \"bullet points for data, and a comparison table for \"\n",
    "                        \"quarter-over-quarter metrics. Keep it under 300 words.\",\n",
    "            tone=\"Concise, analytical, and neutral\"\n",
    "        )\n",
    "    ),\n",
    "    # Pair 3 -- \"Help with email\"\n",
    "    (\n",
    "        \"Help with email\",\n",
    "        CRAFTPrompt(\n",
    "            context=\"We delivered a software demo to a prospective enterprise \"\n",
    "                    \"client last Tuesday. They asked about SSO integration \"\n",
    "                    \"and data residency in the EU. We need to follow up \"\n",
    "                    \"within 48 hours.\",\n",
    "            role=\"an enterprise account executive at a B2B SaaS company\",\n",
    "            action=\"Draft a follow-up email that thanks the client for their \"\n",
    "                   \"time, directly addresses their SSO and data-residency \"\n",
    "                   \"questions, and proposes a 30-minute technical deep-dive \"\n",
    "                   \"call next week.\",\n",
    "            format_spec=\"Subject line + body. Body should have a greeting, \"\n",
    "                        \"3 short paragraphs, and a clear call-to-action with \"\n",
    "                        \"2 proposed meeting times.\",\n",
    "            tone=\"Warm, confident, and professional\"\n",
    "        )\n",
    "    ),\n",
    "]\n",
    "\n",
    "# ---------- Score and display comparison ----------\n",
    "\n",
    "all_before_scores: List[Dict[str, int]] = []\n",
    "all_after_scores: List[Dict[str, int]] = []\n",
    "\n",
    "for idx, (before_text, after_craft) in enumerate(before_after, start=1):\n",
    "    after_text = after_craft.build()\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"  PAIR {idx}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    print(f\"\\n--- BEFORE ---\")\n",
    "    print(f'  \"{before_text}\"\\n')\n",
    "    b_scores = score_prompt(before_text)\n",
    "\n",
    "    print(f\"--- AFTER (CRAFT) ---\")\n",
    "    print(textwrap.indent(after_text, \"  \") + \"\\n\")\n",
    "    a_scores = score_prompt(after_text)\n",
    "\n",
    "    improvement = sum(a_scores.values()) - sum(b_scores.values())\n",
    "    print(f\"  >>> Improvement: +{improvement} points\\n\")\n",
    "\n",
    "    all_before_scores.append(b_scores)\n",
    "    all_after_scores.append(a_scores)\n",
    "\n",
    "# ---------- Summary table ----------\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"  SUMMARY TABLE\")\n",
    "print(\"=\" * 60)\n",
    "header = f\"{'Pair':<6} {'Before':>8} {'After':>8} {'Delta':>8}\"\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "for i in range(len(before_after)):\n",
    "    b_total = sum(all_before_scores[i].values())\n",
    "    a_total = sum(all_after_scores[i].values())\n",
    "    print(f\"{i+1:<6} {b_total:>7}/25 {a_total:>7}/25 {'+' + str(a_total - b_total):>7}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Score Your Own Prompts\n",
    "\n",
    "Think of a task you perform regularly at work (writing reports, drafting emails, analyzing data, creating presentations). Build a CRAFT prompt for it and score the result.\n",
    "\n",
    "**Goal:** Achieve a total score of at least 18/25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Create a CRAFTPrompt for a task relevant to your work\n",
    "# Then score it using score_prompt()\n",
    "\n",
    "my_prompt = CRAFTPrompt(\n",
    "    context=\"\",      # Fill in: What background does the AI need?\n",
    "    role=\"\",         # Fill in: What expert should the AI be?\n",
    "    action=\"\",       # Fill in: What specific task?\n",
    "    format_spec=\"\",  # Fill in: How should output be structured?\n",
    "    tone=\"\"          # Fill in: What voice/style?\n",
    ")\n",
    "\n",
    "print(\"CRAFT Component Check:\")\n",
    "print(my_prompt.summary())\n",
    "print()\n",
    "\n",
    "print(\"Your CRAFT Prompt:\")\n",
    "print(my_prompt.build())\n",
    "print()\n",
    "\n",
    "print(\"Score:\")\n",
    "score_prompt(my_prompt.build())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Prompt Templates\n",
    "\n",
    "Instead of crafting every prompt from scratch, experienced prompt engineers maintain a **template library** of reusable CRAFT prompts with placeholders. This section introduces a `PromptLibrary` class that lets you store, retrieve, list, and fill templates with specific values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "class PromptLibrary:\n",
    "    \"\"\"A reusable library of CRAFT prompt templates.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self._templates: OrderedDict[str, CRAFTPrompt] = OrderedDict()\n",
    "\n",
    "    def add_template(self, name: str, prompt: CRAFTPrompt) -> None:\n",
    "        \"\"\"Register a new template.\"\"\"\n",
    "        self._templates[name] = prompt\n",
    "        print(f\"  [+] Template '{name}' added.\")\n",
    "\n",
    "    def get_template(self, name: str) -> CRAFTPrompt:\n",
    "        \"\"\"Retrieve a template by name.\"\"\"\n",
    "        if name not in self._templates:\n",
    "            raise KeyError(f\"Template '{name}' not found. \"\n",
    "                           f\"Available: {list(self._templates.keys())}\")\n",
    "        return self._templates[name]\n",
    "\n",
    "    def list_templates(self) -> None:\n",
    "        \"\"\"Display all registered templates.\"\"\"\n",
    "        print(f\"{'#':<4} {'Template Name':<25} {'Placeholders'}\")\n",
    "        print(\"-\" * 65)\n",
    "        for i, (name, tmpl) in enumerate(self._templates.items(), 1):\n",
    "            combined = tmpl.build()\n",
    "            placeholders = sorted(set(re.findall(r'\\{(\\w+)\\}', combined)))\n",
    "            print(f\"{i:<4} {name:<25} {', '.join(placeholders) or '(none)'}\")\n",
    "\n",
    "    def fill_template(self, name: str, **kwargs: str) -> str:\n",
    "        \"\"\"Fill placeholders in a template and return the final prompt.\"\"\"\n",
    "        tmpl = self.get_template(name)\n",
    "        raw = tmpl.build()\n",
    "\n",
    "        # Find unfilled placeholders\n",
    "        expected = set(re.findall(r'\\{(\\w+)\\}', raw))\n",
    "        missing = expected - set(kwargs.keys())\n",
    "        if missing:\n",
    "            print(f\"  Warning: unfilled placeholders: {missing}\")\n",
    "\n",
    "        # Safe formatting that ignores unknown keys\n",
    "        for key, value in kwargs.items():\n",
    "            raw = raw.replace(\"{\" + key + \"}\", value)\n",
    "        return raw\n",
    "\n",
    "\n",
    "# ---------- Pre-populate the library ----------\n",
    "\n",
    "library = PromptLibrary()\n",
    "\n",
    "library.add_template(\"email_writer\", CRAFTPrompt(\n",
    "    context=\"We are a {company_type} company. The recipient is {recipient}.\",\n",
    "    role=\"a professional communications specialist\",\n",
    "    action=\"Draft a {email_type} email about {topic} that includes a clear \"\n",
    "           \"call-to-action.\",\n",
    "    format_spec=\"Subject line + 3 concise paragraphs. Keep under 200 words.\",\n",
    "    tone=\"{tone}\"\n",
    "))\n",
    "\n",
    "library.add_template(\"code_reviewer\", CRAFTPrompt(\n",
    "    context=\"The code is written in {language} for a {project_type} project. \"\n",
    "           \"The team follows {standard} coding standards.\",\n",
    "    role=\"a senior software engineer and code reviewer\",\n",
    "    action=\"Review the following code for bugs, performance issues, and \"\n",
    "           \"readability. Identify at least 3 specific improvements.\",\n",
    "    format_spec=\"Use a numbered list. For each issue: state the problem, \"\n",
    "                \"show the offending line, and suggest a fix with a code snippet.\",\n",
    "    tone=\"Constructive and educational\"\n",
    "))\n",
    "\n",
    "library.add_template(\"meeting_summarizer\", CRAFTPrompt(\n",
    "    context=\"The meeting was a {meeting_type} attended by {attendees}. \"\n",
    "           \"Duration: {duration}.\",\n",
    "    role=\"an executive assistant skilled at distilling meeting notes\",\n",
    "    action=\"Summarize the meeting into key decisions, action items with \"\n",
    "           \"owners, and open questions. Flag any items that are blocked.\",\n",
    "    format_spec=\"Use headings: Decisions, Action Items (table with Owner and \"\n",
    "                \"Due Date columns), Open Questions. Keep under 250 words.\",\n",
    "    tone=\"Neutral and precise\"\n",
    "))\n",
    "\n",
    "library.add_template(\"data_analyst\", CRAFTPrompt(\n",
    "    context=\"The dataset contains {dataset_description}. The stakeholder \"\n",
    "           \"is {audience}.\",\n",
    "    role=\"a senior data analyst at a {industry} company\",\n",
    "    action=\"Analyze the data to identify the top {num_insights} insights, \"\n",
    "           \"highlight any anomalies, and recommend next steps.\",\n",
    "    format_spec=\"Executive summary (3 sentences), then bullet points for each \"\n",
    "                \"insight, then a table of anomalies with severity ratings.\",\n",
    "    tone=\"Data-driven and actionable\"\n",
    "))\n",
    "\n",
    "# ---------- Show the library ----------\n",
    "print(\"\\n\")\n",
    "library.list_templates()\n",
    "\n",
    "# ---------- Demo: fill a template ----------\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"  DEMO: Filling the 'email_writer' template\")\n",
    "print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "filled = library.fill_template(\n",
    "    \"email_writer\",\n",
    "    company_type=\"B2B SaaS\",\n",
    "    recipient=\"the VP of Engineering at a Fortune 500 client\",\n",
    "    email_type=\"follow-up\",\n",
    "    topic=\"the security audit results from last week\",\n",
    "    tone=\"Confident, professional, and reassuring\"\n",
    ")\n",
    "print(filled)\n",
    "print(\"\\n--- Score ---\")\n",
    "score_prompt(filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Build Your Template Library\n",
    "\n",
    "Add **two new templates** to the library for tasks you perform regularly. Use `{placeholders}` for values that change between uses, then demonstrate each template by filling it in.\n",
    "\n",
    "**Ideas:** social media post, project status update, customer FAQ answer, training outline, bug report, interview question set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Add 2 new templates to the library for tasks you do regularly\n",
    "# Then use fill_template() to generate a complete prompt from each one\n",
    "\n",
    "library.add_template(\n",
    "    \"your_template_1\",\n",
    "    CRAFTPrompt(\n",
    "        context=\"\",      # Include {placeholders} for variable parts\n",
    "        role=\"\",\n",
    "        action=\"\",\n",
    "        format_spec=\"\",\n",
    "        tone=\"\"\n",
    "    )\n",
    ")\n",
    "\n",
    "library.add_template(\n",
    "    \"your_template_2\",\n",
    "    CRAFTPrompt(\n",
    "        context=\"\",\n",
    "        role=\"\",\n",
    "        action=\"\",\n",
    "        format_spec=\"\",\n",
    "        tone=\"\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Fill and display template 1\n",
    "print(\"=== Template 1 ===\")\n",
    "result1 = library.fill_template(\"your_template_1\")  # add your kwargs\n",
    "print(result1)\n",
    "print()\n",
    "\n",
    "# Fill and display template 2\n",
    "print(\"=== Template 2 ===\")\n",
    "result2 = library.fill_template(\"your_template_2\")  # add your kwargs\n",
    "print(result2)\n",
    "print()\n",
    "\n",
    "# Show the updated library\n",
    "print(\"\\n=== Full Library ===\")\n",
    "library.list_templates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Visualization - Prompt Quality Comparison\n",
    "\n",
    "A radar chart (spider chart) makes it easy to see which quality dimensions are strong or weak across different prompt styles. Below we compare three prompts representing increasing levels of structure:\n",
    "\n",
    "1. **Vague** - A bare-minimum, one-line request\n",
    "2. **Partially Structured** - Some detail but missing key CRAFT components\n",
    "3. **Full CRAFT** - All five components filled in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Three comparison prompts ----------\n",
    "\n",
    "vague_prompt = \"Make a marketing plan\"\n",
    "\n",
    "partial_prompt = (\n",
    "    \"Write a marketing plan for our new mobile app targeting millennials. \"\n",
    "    \"Include social media strategy and budget estimates.\"\n",
    ")\n",
    "\n",
    "craft_prompt = CRAFTPrompt(\n",
    "    context=\"Our fintech startup is launching a budgeting app aimed at \"\n",
    "            \"millennials (ages 25-40) in the US market. We have a quarterly \"\n",
    "            \"marketing budget of $50,000 and currently 2,000 beta users.\",\n",
    "    role=\"a digital marketing strategist with 10 years of experience in \"\n",
    "         \"fintech product launches\",\n",
    "    action=\"Create a 90-day go-to-market plan that identifies the top 3 \"\n",
    "           \"customer acquisition channels, proposes a content calendar, and \"\n",
    "           \"estimates cost-per-acquisition for each channel.\",\n",
    "    format_spec=\"Use the following structure: Executive Summary (5 sentences), \"\n",
    "                \"Channel Strategy (table with columns: Channel, Audience Fit, \"\n",
    "                \"Monthly Budget, Est. CPA), Content Calendar (bullet points \"\n",
    "                \"by week), and KPIs (numbered list of 5 metrics to track).\",\n",
    "    tone=\"Strategic, data-informed, and action-oriented\"\n",
    ").build()\n",
    "\n",
    "# ---------- Score each ----------\n",
    "print(\"Scoring: Vague prompt\")\n",
    "s_vague = score_prompt(vague_prompt)\n",
    "print(\"Scoring: Partial prompt\")\n",
    "s_partial = score_prompt(partial_prompt)\n",
    "print(\"Scoring: Full CRAFT prompt\")\n",
    "s_craft = score_prompt(craft_prompt)\n",
    "\n",
    "# ---------- Radar chart ----------\n",
    "dimensions = list(s_vague.keys())\n",
    "n_dims = len(dimensions)\n",
    "\n",
    "angles = np.linspace(0, 2 * np.pi, n_dims, endpoint=False).tolist()\n",
    "angles += angles[:1]  # close the polygon\n",
    "\n",
    "def values_for(scores: Dict[str, int]) -> List[int]:\n",
    "    vals = [scores[d] for d in dimensions]\n",
    "    return vals + vals[:1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 7), subplot_kw=dict(polar=True))\n",
    "\n",
    "ax.plot(angles, values_for(s_vague), 'o-', linewidth=2,\n",
    "        label=f'Vague ({sum(s_vague.values())}/25)', color='#e74c3c')\n",
    "ax.fill(angles, values_for(s_vague), alpha=0.10, color='#e74c3c')\n",
    "\n",
    "ax.plot(angles, values_for(s_partial), 's-', linewidth=2,\n",
    "        label=f'Partial ({sum(s_partial.values())}/25)', color='#f39c12')\n",
    "ax.fill(angles, values_for(s_partial), alpha=0.10, color='#f39c12')\n",
    "\n",
    "ax.plot(angles, values_for(s_craft), 'D-', linewidth=2,\n",
    "        label=f'Full CRAFT ({sum(s_craft.values())}/25)', color='#27ae60')\n",
    "ax.fill(angles, values_for(s_craft), alpha=0.15, color='#27ae60')\n",
    "\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels([d.capitalize() for d in dimensions], fontsize=12)\n",
    "ax.set_yticks([1, 2, 3, 4, 5])\n",
    "ax.set_yticklabels(['1', '2', '3', '4', '5'], fontsize=9, color='grey')\n",
    "ax.set_ylim(0, 5)\n",
    "ax.set_title('Prompt Quality Comparison', fontsize=15, fontweight='bold', pad=20)\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge: The Prompt Makeover\n",
    "\n",
    "Below are three intentionally terrible prompts. Your mission:\n",
    "\n",
    "1. Score each one as-is\n",
    "2. Transform each into a full CRAFT prompt\n",
    "3. Score the transformed versions\n",
    "4. Visualize all six scores (3 before + 3 after) in a grouped bar chart\n",
    "\n",
    "**Target:** Every transformed prompt should score at least 20/25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE - Challenge Exercise\n",
    "# Take these 3 terrible prompts and transform them using CRAFT\n",
    "# Score each before and after, and visualize the improvement\n",
    "\n",
    "terrible_prompts = [\n",
    "    \"Make a presentation about sales\",\n",
    "    \"Fix my code\",\n",
    "    \"Write something for social media\"\n",
    "]\n",
    "\n",
    "# Step 1: Score the terrible prompts\n",
    "before_scores = []\n",
    "for prompt in terrible_prompts:\n",
    "    print(f'Scoring: \"{prompt}\"')\n",
    "    before_scores.append(score_prompt(prompt))\n",
    "\n",
    "# Step 2: Create CRAFT versions\n",
    "# craft_version_1 = CRAFTPrompt(context=\"...\", role=\"...\", action=\"...\",\n",
    "#                                format_spec=\"...\", tone=\"...\")\n",
    "# craft_version_2 = CRAFTPrompt(...)\n",
    "# craft_version_3 = CRAFTPrompt(...)\n",
    "\n",
    "# Step 3: Score the CRAFT versions\n",
    "# after_scores = []\n",
    "# for craft_ver in [craft_version_1, craft_version_2, craft_version_3]:\n",
    "#     after_scores.append(score_prompt(craft_ver.build()))\n",
    "\n",
    "# Step 4: Visualize with a grouped bar chart\n",
    "# Hint: use plt.bar() with offset x positions for before/after groups\n",
    "# Labels for each prompt pair on the x-axis\n",
    "# Y-axis = total score out of 25"
   ]
  }
 ]
}