# Enterprise AI Adoption: Assessments

Comprehensive assessment materials including pre-course and post-course evaluations, daily self-assessments, and certification quiz.

---

## Table of Contents

1. [Pre-Course Assessment](#pre-course-assessment)
2. [Post-Course Assessment](#post-course-assessment)
3. [Daily Self-Assessment Checklists](#daily-self-assessment-checklists)
4. [Certification Quiz](#certification-quiz)
5. [Answer Keys](#answer-keys)

---

# Pre-Course Assessment

## Purpose
This assessment measures participants' baseline knowledge and attitudes before the course. Results help facilitators customize content and provide benchmarks for measuring learning.

## Instructions
Complete this assessment individually before Day 1. There are no "right" or "wrong" answers on attitude questions. Be honest—this helps us help you.

---

### Section A: Knowledge Assessment (15 questions)

**1. What does AI stand for?**
- a) Automated Intelligence
- b) Artificial Intelligence
- c) Advanced Integration
- d) Autonomous Implementation

**2. Which of the following is NOT a type of machine learning?**
- a) Supervised learning
- b) Unsupervised learning
- c) Reinforcement learning
- d) Directed learning

**3. When implementing AI to improve a business process, you should:**
- a) First automate the existing process, then optimize
- b) First consider what outcome you want, then design the optimal process
- c) Copy what competitors are doing
- d) Wait for the technology to mature

**4. "Human-in-the-Loop" (HITL) means:**
- a) Humans design the AI but never interact with it after deployment
- b) Humans review and approve every AI decision before it takes effect
- c) Humans monitor AI decisions and intervene only when needed
- d) Humans set parameters but AI operates completely independently

**5. Which of the following is a valid concern about AI bias?**
- a) AI always makes biased decisions
- b) AI can learn biases from historical training data
- c) AI bias cannot be detected
- d) Bias is only a problem in facial recognition AI

**6. The term "hallucination" in AI refers to:**
- a) When AI systems have visual glitches
- b) When AI generates confident but incorrect or fabricated information
- c) When users imagine AI capabilities that don't exist
- d) When AI systems dream during idle periods

**7. What is a "prompt" in the context of generative AI?**
- a) A reminder to update the AI system
- b) The input or instruction given to an AI to generate a response
- c) A warning message about AI limitations
- d) The time it takes AI to respond

**8. Which type of AI task involves creating new content like text, images, or code?**
- a) Classification
- b) Prediction
- c) Generation
- d) Clustering

**9. What is the primary purpose of a governance framework for AI?**
- a) To slow down AI adoption
- b) To ensure accountability, manage risk, and guide responsible use
- c) To increase IT department headcount
- d) To meet regulatory requirements only

**10. When considering AI for a workflow, which factor is LEAST important?**
- a) Whether the task is repetitive and consistent
- b) Whether high-quality data is available
- c) Whether the vendor has the best marketing
- d) Whether errors can be detected and corrected

**11. What does "ROI" stand for in business context?**
- a) Risk of Implementation
- b) Return on Investment
- c) Rate of Innovation
- d) Requirement of IT

**12. In AI context, what is "training data"?**
- a) Instructions for how employees should use AI
- b) The data used to teach an AI model to recognize patterns
- c) Test results from AI certification programs
- d) Documentation for AI systems

**13. Which approach is recommended when starting with AI in an organization?**
- a) Deploy across the entire organization at once
- b) Start with the most complex process to maximize impact
- c) Start with a focused pilot and learn before scaling
- d) Wait until AI is perfect before any implementation

**14. What is "explainability" in AI?**
- a) The AI's ability to speak human languages
- b) The ability to understand and describe how an AI reached its decision
- c) How well the AI manual is written
- d) The AI's customer support quality

**15. Which of the following is NOT a typical risk category for AI implementations?**
- a) Data risk
- b) Model risk
- c) Weather risk
- d) Reputational risk

---

### Section B: Self-Assessment of Knowledge (Rate 1-5)

Rate your current knowledge level for each topic:
*1 = No knowledge, 2 = Basic awareness, 3 = Some knowledge, 4 = Good knowledge, 5 = Expert*

| Topic | Rating (1-5) |
|-------|--------------|
| How AI/machine learning works at a basic level | |
| How AI is currently used in business | |
| How to identify good AI use cases in workflows | |
| AI risks and how to mitigate them | |
| AI governance and oversight models | |
| How to build a business case for AI | |
| How to manage organizational change for AI adoption | |
| How to evaluate AI vendors and tools | |

---

### Section C: Attitude Assessment (Rate Agreement 1-5)

Rate your agreement with each statement:
*1 = Strongly Disagree, 2 = Disagree, 3 = Neutral, 4 = Agree, 5 = Strongly Agree*

| Statement | Rating (1-5) |
|-----------|--------------|
| AI will have a significant positive impact on my work | |
| I am concerned that AI might make my job obsolete | |
| My organization is prepared to adopt AI effectively | |
| I feel confident in my ability to work alongside AI | |
| AI decision-making should always be reviewed by humans | |
| I understand the ethical implications of AI use | |
| My leadership supports AI experimentation | |
| I know of specific processes in my work that could benefit from AI | |

---

### Section D: Open Response

**1. Describe a workflow or process in your current role that you think could benefit from AI. Why did you choose this process?**

_______________________________________________

_______________________________________________

_______________________________________________

**2. What is your biggest concern or question about AI adoption in your organization?**

_______________________________________________

_______________________________________________

_______________________________________________

**3. What do you hope to learn from this course?**

_______________________________________________

_______________________________________________

_______________________________________________

---

# Post-Course Assessment

## Purpose
This assessment measures learning gains and changes in attitudes after completing the course. Compare results with pre-course assessment to demonstrate impact.

## Instructions
Complete this assessment individually at the end of Day 5. Be reflective and honest.

---

### Section A: Knowledge Assessment (15 questions)

**1. The key difference between "automating" and "redesigning" a workflow is:**
- a) Automation is faster to implement
- b) Redesigning starts with the desired outcome, not the existing process
- c) Automation requires AI while redesigning doesn't
- d) They are the same thing

**2. Which of the following is NOT one of the five AI Role Types discussed in the course?**
- a) Analyzer
- b) Generator
- c) Optimizer
- d) Router

**3. Human-on-the-Loop (HOTL) oversight means:**
- a) Humans approve every AI decision
- b) Humans monitor AI operations and intervene when needed
- c) AI operates with no human involvement
- d) Humans design but never see AI outputs

**4. The AI Readiness Canvas assesses readiness across how many dimensions?**
- a) 3
- b) 4
- c) 5
- d) 7

**5. Which is NOT a dimension on the AI Readiness Canvas?**
- a) Data Access
- b) Risk Tolerance
- c) Budget Size
- d) Employee Readiness

**6. In the 30-60-90 day rollout framework, what happens in Days 1-30?**
- a) Full deployment across the organization
- b) Foundation building and pilot preparation
- c) Scaling to additional users
- d) Post-implementation review

**7. An "escalation trigger" in AI governance is:**
- a) When management escalates AI concerns
- b) A condition that causes AI to stop and request human intervention
- c) When AI performance improves rapidly
- d) The price increase for AI services

**8. The Governance Canvas includes which of the following sections?**
- a) Risk assessment
- b) Oversight model selection
- c) Incident response planning
- d) All of the above

**9. When mapping a workflow for AI integration, what color coding represents AI tasks?**
- a) Blue
- b) Green
- c) Yellow
- d) Red

**10. What is the recommended first step when designing an AI-enhanced workflow?**
- a) Select the AI tool
- b) Define the desired outcome
- c) Document the current process
- d) Get IT approval

**11. Which of the following is a valid escalation trigger for AI systems?**
- a) Confidence score below a threshold
- b) Request involves high-value transaction
- c) Customer expresses frustration
- d) All of the above

**12. An AI Playbook should NOT include:**
- a) Solution overview and user guide
- b) Governance and oversight details
- c) Competitor analysis and market positioning
- d) Incident response procedures

**13. In the 30-60-90 day framework, when should you transition from HITL to HOTL?**
- a) Day 1
- b) When pilot metrics prove system reliability (typically Day 61+)
- c) After executive approval only
- d) Never—always use HITL

**14. What is the recommended approach for AI failure post-mortems?**
- a) Assign blame and punish those responsible
- b) Treat failures as learning opportunities and improve systems
- c) Keep failures confidential to avoid reputation damage
- d) Outsource the investigation

**15. The phrase "Slow is smooth, smooth is fast" in AI adoption means:**
- a) AI works slowly but accurately
- b) Taking time to build proper foundations leads to faster overall success
- c) You should slow down AI processing for better results
- d) AI adoption timelines should be extended indefinitely

---

### Section B: Self-Assessment of Knowledge (Rate 1-5)

Rate your current knowledge level for each topic:
*1 = No knowledge, 2 = Basic awareness, 3 = Some knowledge, 4 = Good knowledge, 5 = Expert*

| Topic | Rating (1-5) |
|-------|--------------|
| How AI/machine learning works at a basic level | |
| How AI is currently used in business | |
| How to identify good AI use cases in workflows | |
| AI risks and how to mitigate them | |
| AI governance and oversight models | |
| How to build a business case for AI | |
| How to manage organizational change for AI adoption | |
| How to evaluate AI vendors and tools | |

---

### Section C: Attitude Assessment (Rate Agreement 1-5)

Rate your agreement with each statement:
*1 = Strongly Disagree, 2 = Disagree, 3 = Neutral, 4 = Agree, 5 = Strongly Agree*

| Statement | Rating (1-5) |
|-----------|--------------|
| AI will have a significant positive impact on my work | |
| I am concerned that AI might make my job obsolete | |
| My organization is prepared to adopt AI effectively | |
| I feel confident in my ability to work alongside AI | |
| AI decision-making should always be reviewed by humans | |
| I understand the ethical implications of AI use | |
| My leadership supports AI experimentation | |
| I know of specific processes in my work that could benefit from AI | |

---

### Section D: Application Assessment

**1. Describe the AI initiative you developed during this course. What outcome does it target?**

_______________________________________________

_______________________________________________

_______________________________________________

**2. What oversight model did you choose for your initiative, and why?**

_______________________________________________

_______________________________________________

_______________________________________________

**3. What is the first action you will take to advance this initiative after the course?**

_______________________________________________

_______________________________________________

_______________________________________________

**4. What is the biggest challenge you anticipate, and how will you address it?**

_______________________________________________

_______________________________________________

_______________________________________________

---

### Section E: Course Feedback

**1. What was the most valuable part of this course?**

_______________________________________________

**2. What would you change or improve about this course?**

_______________________________________________

**3. Would you recommend this course to colleagues? Why or why not?**

_______________________________________________

**4. Any additional comments?**

_______________________________________________

---

# Daily Self-Assessment Checklists

Use these checklists at the end of each day to assess your understanding and identify areas for review.

---

## Day 1: Foundations & Mindset Shift

### Key Concepts Checklist

Check each box when you feel confident you understand the concept:

- [ ] I can explain the difference between "automate" and "redesign" approaches
- [ ] I can identify when a workflow should be redesigned vs. automated
- [ ] I understand the five dimensions of the AI Readiness Canvas
- [ ] I can assess a workflow and identify AI opportunities
- [ ] I can describe what an AI-native design looks like
- [ ] I understand the importance of starting with outcomes, not processes

### Application Questions

**Can I explain the automation vs. redesign distinction to a colleague?**
- [ ] Yes, confidently
- [ ] Somewhat—need more practice
- [ ] Not yet—need to review

**Did I identify at least one workflow that could be redesigned with AI?**
- [ ] Yes, and I documented it
- [ ] Yes, but need to develop further
- [ ] Not yet

**Which AI Readiness Canvas dimension is weakest in my organization?**
_______________________________________________

### Topics to Review
*List any concepts you want to revisit:*

_______________________________________________

---

## Day 2: Mapping and Redesigning Workflows

### Key Concepts Checklist

- [ ] I can map a current-state workflow with pain points identified
- [ ] I understand the five AI Role Types (Analyzer, Generator, Recommender, Validator, Router)
- [ ] I can identify which AI Role Types apply to a given workflow
- [ ] I can design a future-state workflow with AI integration
- [ ] I understand the color coding convention (Blue=Human, Green=AI, Yellow=Decision)
- [ ] I can create an Outcome Brief that starts with desired result

### Application Questions

**Did I complete a Before/After workflow map?**
- [ ] Yes, complete with both states
- [ ] Partially—current state only
- [ ] Not yet

**Which AI Role Types appear in my redesigned workflow?**
- [ ] Analyzer
- [ ] Generator
- [ ] Recommender
- [ ] Validator
- [ ] Router

**What is the biggest improvement from current to future state?**
_______________________________________________

### Topics to Review

_______________________________________________

---

## Day 3: Governance, Safety, and Human-in-the-Loop

### Key Concepts Checklist

- [ ] I understand the three oversight models (HITL, HOTL, HOOTL)
- [ ] I can select an appropriate oversight model for a given scenario
- [ ] I understand the five risk dimensions (Data, Model, Operational, Security, Reputational)
- [ ] I can conduct a basic risk assessment for an AI initiative
- [ ] I can design escalation triggers for AI systems
- [ ] I understand what should be included in a Governance Canvas

### Application Questions

**Which oversight model did I select for my workflow?**
- [ ] HITL (Human-in-the-Loop)
- [ ] HOTL (Human-on-the-Loop)
- [ ] HOOTL (Human-out-of-the-Loop)

**Why did I select this model?**
_______________________________________________

**Did I complete the Governance Canvas for my initiative?**
- [ ] Yes, all sections
- [ ] Partially—some sections incomplete
- [ ] Not yet

**What are the top 2 risks for my AI initiative?**
1. _______________________________________________
2. _______________________________________________

### Topics to Review

_______________________________________________

---

## Day 4: Building the Internal AI Playbook

### Key Concepts Checklist

- [ ] I understand the structure of an AI Playbook
- [ ] I can identify stakeholders and map their influence/interest
- [ ] I can build a business case for an AI initiative
- [ ] I know how to present AI proposals to skeptical stakeholders
- [ ] I can anticipate and address common objections
- [ ] I understand the peer testing process and its value

### Application Questions

**Did I draft sections of my AI Playbook?**
- [ ] Yes, multiple sections complete
- [ ] Some progress made
- [ ] Not yet started

**What was the hardest question during peer testing?**
_______________________________________________

**How will I address that question in my final proposal?**
_______________________________________________

**Who are the key stakeholders I need to convince?**
1. _______________________________________________
2. _______________________________________________
3. _______________________________________________

### Topics to Review

_______________________________________________

---

## Day 5: Capstone & Rollout

### Key Concepts Checklist

- [ ] I can create a 30-60-90 day rollout plan
- [ ] I understand what happens in each phase (Foundation, Pilot, Scale)
- [ ] I know how to identify pilot users and success criteria
- [ ] I can present my AI initiative clearly and concisely
- [ ] I understand ongoing maintenance and governance requirements
- [ ] I have a concrete action plan for post-course implementation

### Application Questions

**Did I complete my capstone presentation?**
- [ ] Yes, presented to the group
- [ ] Prepared but didn't present
- [ ] Not completed

**What is my first action item for next week?**
_______________________________________________

**Who will I talk to about my AI initiative?**
_______________________________________________

**What is my 30-day milestone?**
_______________________________________________

### Overall Course Reflection

**My confidence in working with AI has:**
- [ ] Increased significantly
- [ ] Increased somewhat
- [ ] Stayed about the same
- [ ] Decreased (explain why below)

**The most important thing I learned was:**
_______________________________________________

**The one thing I wish we covered more was:**
_______________________________________________

---

# Certification Quiz

## Enterprise AI Adoption Certification Exam

**Instructions:**
- 40 questions total
- 75% (30 correct) required to pass
- Time limit: 60 minutes
- Open book/notes permitted

---

### Section 1: Foundations (Questions 1-10)

**1. The "automation trap" refers to:**
- a) When automation creates more work than it saves
- b) Using new technology to optimize old processes instead of redesigning
- c) When employees become too dependent on automation
- d) Automation that fails during critical moments

**2. When redesigning a workflow for AI, the first question to ask is:**
- a) What AI tools are available?
- b) What is the budget for this project?
- c) What outcome are we trying to achieve?
- d) Which steps can AI perform?

**3. The AI Readiness Canvas dimension "Risk Tolerance" measures:**
- a) How much financial risk the organization can afford
- b) The organization's willingness to experiment and treat failure as learning
- c) The technical security risks of AI systems
- d) Customer tolerance for AI errors

**4. Which statement about "Employee Readiness" is TRUE?**
- a) Only technical staff need to be ready for AI
- b) Employee readiness includes AI literacy, change appetite, and identified champions
- c) Employee readiness is the least important dimension
- d) Employees will naturally adapt once AI is deployed

**5. An organization with low "Data Access" scores should:**
- a) Abandon AI plans entirely
- b) Deploy AI anyway and fix data issues later
- c) Prioritize data digitization and integration before AI deployment
- d) Focus only on AI applications that don't need data

**6. The primary goal of the "Workflow Autopsy" exercise is to:**
- a) Determine which employees to replace
- b) Identify inefficiencies, pain points, and AI opportunities in existing workflows
- c) Document processes for compliance purposes
- d) Compare workflows to competitors

**7. "AI-native design" means:**
- a) Using AI developed by native speakers
- b) Designing processes from scratch with AI capabilities in mind
- c) Using only domestically developed AI
- d) Training AI on native data sources only

**8. The "Decision Speed" dimension on the AI Readiness Canvas addresses:**
- a) How fast AI can make decisions
- b) How quickly organizational decisions and approvals can be made
- c) The processing speed of AI hardware
- d) How fast employees can learn AI tools

**9. An organization scoring "5" on all AI Readiness dimensions should:**
- a) Wait for even more advanced AI technology
- b) Deploy AI across the entire organization immediately
- c) Still pilot carefully but can move faster with confidence
- d) Sell their readiness consulting services to others

**10. The greatest value of the AI Readiness assessment is:**
- a) Proving the organization is ready for AI
- b) Identifying specific areas to improve before or during AI deployment
- c) Satisfying audit requirements
- d) Comparing against industry benchmarks

---

### Section 2: Workflow Design (Questions 11-20)

**11. The five AI Role Types are:**
- a) Analyzer, Generator, Recommender, Validator, Router
- b) Input, Process, Output, Review, Archive
- c) Collect, Analyze, Decide, Act, Learn
- d) Observer, Participant, Controller, Reviewer, Approver

**12. An AI that reviews contracts and highlights non-standard clauses is acting as a(n):**
- a) Generator
- b) Analyzer
- c) Router
- d) Recommender

**13. An AI that drafts customer email responses for human review is acting as a(n):**
- a) Validator
- b) Router
- c) Generator
- d) Analyzer

**14. An AI that categorizes support tickets and sends them to the right team is acting as a(n):**
- a) Analyzer
- b) Recommender
- c) Validator
- d) Router

**15. In workflow mapping, the color GREEN represents:**
- a) Decision points
- b) Human tasks
- c) AI tasks
- d) Pain points

**16. An "Outcome Brief" should:**
- a) Describe the current process in detail
- b) List all AI technologies being considered
- c) State the desired result in terms of value delivered
- d) Document the project budget and timeline

**17. When a workflow has both AI tasks (green) and human tasks (blue), this represents:**
- a) A failed design
- b) Human-AI collaboration
- c) An incomplete automation
- d) A compliance violation

**18. The "Before/After" workflow mapping technique helps by:**
- a) Showing what will be eliminated
- b) Visualizing the transformation and identifying gaps
- c) Proving AI is better than humans
- d) Documenting liability transfer

**19. Which is NOT a recommended use for the "Recommender" AI role?**
- a) Suggesting next best action in sales
- b) Making final legal decisions without human input
- c) Recommending products based on customer preferences
- d) Suggesting treatment options for physician review

**20. The purpose of identifying decision points (yellow) in workflow mapping is to:**
- a) Show where to add more automation
- b) Identify where judgment is required and oversight may be needed
- c) Highlight where delays occur
- d) Mark where to reduce staff

---

### Section 3: Governance & Oversight (Questions 21-30)

**21. Human-in-the-Loop (HITL) oversight is characterized by:**
- a) Humans review samples of AI decisions periodically
- b) Humans review and approve every AI decision before it takes effect
- c) Humans set rules but never see individual decisions
- d) Humans only involved during initial training

**22. Human-on-the-Loop (HOTL) oversight is characterized by:**
- a) No human involvement after deployment
- b) Humans approve every decision
- c) Humans monitor AI operations and intervene when needed
- d) Humans replaced by AI entirely

**23. Human-out-of-the-Loop (HOOTL) should be used when:**
- a) Stakes are high and errors are costly
- b) Regulations require human accountability
- c) Clear boundaries exist, testing is extensive, and single-error downside is contained
- d) The organization wants to eliminate human jobs

**24. Which is a valid escalation trigger for an AI system?**
- a) Confidence score below 80%
- b) Transaction amount exceeds $10,000
- c) Customer expresses frustration
- d) All of the above

**25. The five risk dimensions in AI governance are:**
- a) Data, Model, Operational, Security, Reputational
- b) Technical, Financial, Legal, Compliance, Market
- c) Input, Processing, Output, Storage, Transfer
- d) Design, Development, Deployment, Operation, Retirement

**26. "Data Risk" in AI governance includes:**
- a) Risk of data being wrong, biased, or breached
- b) Risk of using too much data
- c) Risk of AI generating too much output data
- d) Risk of data being too expensive

**27. "Model Risk" in AI governance includes:**
- a) Risk of using an attractive employee as a model
- b) Risk that the business model is unsound
- c) Risk that AI makes incorrect predictions or behaves unexpectedly
- d) Risk of selecting the wrong vendor

**28. An AI governance framework should include all EXCEPT:**
- a) Risk assessment and mitigation strategies
- b) Escalation triggers and override authority
- c) Competitor intelligence and market analysis
- d) Monitoring metrics and incident response procedures

**29. The purpose of logging AI decisions and human overrides is to:**
- a) Prove AI is always right
- b) Create an audit trail and enable continuous improvement
- c) Monitor employee productivity
- d) Generate marketing materials

**30. When should governance frameworks be reviewed?**
- a) Only when something goes wrong
- b) Once, at initial deployment
- c) Regularly (monthly metrics, quarterly reviews, annual full assessment)
- d) Never, once established they shouldn't change

---

### Section 4: Implementation & Rollout (Questions 31-40)

**31. In the 30-60-90 day framework, Days 1-30 focus on:**
- a) Full organization deployment
- b) Foundation building and pilot preparation
- c) Scaling to additional users
- d) Post-mortem analysis

**32. During the pilot phase (Days 31-60), organizations should:**
- a) Deploy AI across all users immediately
- b) Work with a small group of champions and start with maximum oversight
- c) Skip human oversight to test AI independence
- d) Focus on marketing the new AI system

**33. How many pilot users are recommended for initial testing?**
- a) 1
- b) 3-5
- c) 50-100
- d) The entire department

**34. When is it appropriate to transition from HITL to HOTL?**
- a) Immediately after deployment
- b) When pilot metrics demonstrate system reliability
- c) When executives request it
- d) After 30 days regardless of performance

**35. An AI Playbook should include:**
- a) Solution overview and user guide
- b) Governance and oversight details
- c) Incident response procedures
- d) All of the above

**36. Stakeholder mapping involves:**
- a) Creating an organization chart
- b) Analyzing stakeholders' influence, interest, and support level
- c) Eliminating stakeholders who oppose AI
- d) Selecting vendors

**37. "Peer testing" of AI initiatives helps by:**
- a) Creating competition between teams
- b) Finding weaknesses in proposals before they reach decision-makers
- c) Proving that AI is ready for deployment
- d) Comparing AI performance between organizations

**38. The recommended response when AI makes an error is to:**
- a) Assign blame and punish those responsible
- b) Hide the error to protect reputation
- c) Treat it as a learning opportunity and improve systems
- d) Abandon AI entirely

**39. Ongoing AI maintenance should include:**
- a) Regular performance monitoring
- b) Model retraining when drift is detected
- c) Governance framework reviews
- d) All of the above

**40. The phrase "Slow is smooth, smooth is fast" in AI adoption means:**
- a) AI processing should be slowed down
- b) Taking time to build proper foundations leads to faster overall success
- c) Implementation should be delayed indefinitely
- d) AI should never be rushed regardless of business needs

---

# Answer Keys

## Pre-Course Assessment Answer Key (Section A)

| Question | Answer | Explanation |
|----------|--------|-------------|
| 1 | b | Artificial Intelligence |
| 2 | d | Directed learning is not a type of ML |
| 3 | b | Start with desired outcome |
| 4 | b | HITL = human reviews every decision |
| 5 | b | AI can learn biases from training data |
| 6 | b | Hallucination = confident but incorrect info |
| 7 | b | Prompt = input/instruction to AI |
| 8 | c | Generation = creating new content |
| 9 | b | Governance ensures accountability and manages risk |
| 10 | c | Marketing is least important |
| 11 | b | Return on Investment |
| 12 | b | Data used to teach AI patterns |
| 13 | c | Start with focused pilot |
| 14 | b | Understanding how AI reached decision |
| 15 | c | Weather is not an AI risk category |

---

## Post-Course Assessment Answer Key (Section A)

| Question | Answer | Explanation |
|----------|--------|-------------|
| 1 | b | Redesigning starts with outcome |
| 2 | c | Optimizer is not one of the five |
| 3 | b | HOTL = monitor and intervene |
| 4 | c | Five dimensions |
| 5 | c | Budget Size is not a dimension |
| 6 | b | Foundation building |
| 7 | b | Condition that triggers human intervention |
| 8 | d | All are included |
| 9 | b | Green = AI tasks |
| 10 | b | Start with outcome |
| 11 | d | All are valid triggers |
| 12 | c | Competitor analysis not included |
| 13 | b | When metrics prove reliability |
| 14 | b | Treat as learning opportunity |
| 15 | b | Proper foundations = faster success |

---

## Certification Quiz Answer Key

| Question | Answer | Question | Answer |
|----------|--------|----------|--------|
| 1 | b | 21 | b |
| 2 | c | 22 | c |
| 3 | b | 23 | c |
| 4 | b | 24 | d |
| 5 | c | 25 | a |
| 6 | b | 26 | a |
| 7 | b | 27 | c |
| 8 | b | 28 | c |
| 9 | c | 29 | b |
| 10 | b | 30 | c |
| 11 | a | 31 | b |
| 12 | b | 32 | b |
| 13 | c | 33 | b |
| 14 | d | 34 | b |
| 15 | c | 35 | d |
| 16 | c | 36 | b |
| 17 | b | 37 | b |
| 18 | b | 38 | c |
| 19 | b | 39 | d |
| 20 | b | 40 | b |

### Scoring Guide

| Score | Result |
|-------|--------|
| 36-40 (90-100%) | Excellent - Strong mastery of content |
| 30-35 (75-89%) | Pass - Meets certification requirements |
| 24-29 (60-74%) | Near Pass - Review weak areas and retake |
| Below 24 (< 60%) | Not Yet - Additional study required |

---

*Assessments Version 1.0 | Enterprise AI Adoption Course*
