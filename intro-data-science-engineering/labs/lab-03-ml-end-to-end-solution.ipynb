{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "s0a1b2c3",
   "metadata": {},
   "source": [
    "# Lab 3: End-to-End ML Project \u2014 Customer Churn Prediction - SOLUTIONS\n",
    "**Introduction to Data Science & Engineering - Day 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s1b2c3d4",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s2c3d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             confusion_matrix, classification_report, roc_auc_score, roc_curve)\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s3d4e5f6",
   "metadata": {},
   "source": [
    "## Part 1: Generate and Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s4e5f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "n_customers = 2000\n",
    "\n",
    "# Base features\n",
    "tenure = np.random.randint(1, 72, n_customers)\n",
    "monthly_charges = np.round(np.random.uniform(20, 120, n_customers), 2)\n",
    "total_charges = np.round(tenure * monthly_charges * np.random.uniform(0.8, 1.1, n_customers), 2)\n",
    "\n",
    "contract = np.random.choice(['Month-to-month', 'One year', 'Two year'], n_customers, p=[0.5, 0.3, 0.2])\n",
    "payment = np.random.choice(['Electronic check', 'Mailed check', 'Bank transfer', 'Credit card'], n_customers)\n",
    "internet = np.random.choice(['DSL', 'Fiber optic', 'No'], n_customers, p=[0.35, 0.45, 0.20])\n",
    "\n",
    "support_tickets = np.random.poisson(2, n_customers)\n",
    "num_products = np.random.randint(1, 6, n_customers)\n",
    "\n",
    "# Churn based on realistic factors\n",
    "churn_prob = np.zeros(n_customers)\n",
    "churn_prob += (contract == 'Month-to-month') * 0.25\n",
    "churn_prob += (tenure < 12) * 0.15\n",
    "churn_prob += (monthly_charges > 80) * 0.1\n",
    "churn_prob += (support_tickets > 3) * 0.15\n",
    "churn_prob += (internet == 'Fiber optic') * 0.05\n",
    "churn_prob -= (contract == 'Two year') * 0.2\n",
    "churn_prob -= (num_products > 3) * 0.1\n",
    "churn_prob = np.clip(churn_prob, 0.05, 0.85)\n",
    "\n",
    "churn = np.random.binomial(1, churn_prob)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'customer_id': range(1, n_customers + 1),\n",
    "    'tenure_months': tenure,\n",
    "    'monthly_charges': monthly_charges,\n",
    "    'total_charges': total_charges,\n",
    "    'contract_type': contract,\n",
    "    'payment_method': payment,\n",
    "    'internet_service': internet,\n",
    "    'support_tickets': support_tickets,\n",
    "    'num_products': num_products,\n",
    "    'age': np.random.randint(18, 75, n_customers),\n",
    "    'has_partner': np.random.choice([0, 1], n_customers, p=[0.45, 0.55]),\n",
    "    'has_dependents': np.random.choice([0, 1], n_customers, p=[0.6, 0.4]),\n",
    "    'churn': churn\n",
    "})\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nChurn distribution:\")\n",
    "print(df['churn'].value_counts(normalize=True).round(3))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s5f6a7b8",
   "metadata": {},
   "source": [
    "### Exercise 1.1: Explore the Data - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s6a7b8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset Info:\")\n",
    "print(f\"  Shape: {df.shape}\")\n",
    "print(f\"  Churn rate: {df['churn'].mean():.1%}\")\n",
    "print(f\"\\nNumeric summary:\")\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s7b8c9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize churn by key features\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# Churn by contract type\n",
    "ct = df.groupby('contract_type')['churn'].mean().sort_values(ascending=False)\n",
    "ct.plot(kind='bar', ax=axes[0,0], color='#3b82f6')\n",
    "axes[0,0].set_title('Churn Rate by Contract Type')\n",
    "axes[0,0].set_ylabel('Churn Rate')\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Tenure distribution by churn\n",
    "sns.histplot(data=df, x='tenure_months', hue='churn', multiple='stack', bins=30, ax=axes[0,1], palette=['#10b981', '#ef4444'])\n",
    "axes[0,1].set_title('Tenure Distribution by Churn')\n",
    "\n",
    "# Monthly charges by churn\n",
    "sns.boxplot(data=df, x='churn', y='monthly_charges', ax=axes[0,2], palette=['#10b981', '#ef4444'])\n",
    "axes[0,2].set_title('Monthly Charges by Churn')\n",
    "axes[0,2].set_xticklabels(['Stayed', 'Churned'])\n",
    "\n",
    "# Support tickets by churn\n",
    "sns.boxplot(data=df, x='churn', y='support_tickets', ax=axes[1,0], palette=['#10b981', '#ef4444'])\n",
    "axes[1,0].set_title('Support Tickets by Churn')\n",
    "axes[1,0].set_xticklabels(['Stayed', 'Churned'])\n",
    "\n",
    "# Churn by internet service\n",
    "it = df.groupby('internet_service')['churn'].mean().sort_values(ascending=False)\n",
    "it.plot(kind='bar', ax=axes[1,1], color='#8b5cf6')\n",
    "axes[1,1].set_title('Churn Rate by Internet Service')\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Products by churn\n",
    "pt = df.groupby('num_products')['churn'].mean()\n",
    "pt.plot(kind='bar', ax=axes[1,2], color='#f59e0b')\n",
    "axes[1,2].set_title('Churn Rate by Number of Products')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s8c9d0e1",
   "metadata": {},
   "source": [
    "### Exercise 2.1: Create New Features - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s9d0e1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = df.copy()\n",
    "\n",
    "# Tenure-based features\n",
    "df_ml['tenure_years'] = df_ml['tenure_months'] / 12\n",
    "df_ml['is_new_customer'] = (df_ml['tenure_months'] <= 6).astype(int)\n",
    "\n",
    "# Charges-based features\n",
    "df_ml['avg_monthly_charge'] = df_ml['total_charges'] / df_ml['tenure_months'].replace(0, 1)\n",
    "df_ml['charge_per_product'] = df_ml['monthly_charges'] / df_ml['num_products']\n",
    "\n",
    "# Support ratio\n",
    "df_ml['support_per_tenure'] = df_ml['support_tickets'] / df_ml['tenure_months'].replace(0, 1)\n",
    "\n",
    "# Engagement score (composite)\n",
    "df_ml['engagement_score'] = (\n",
    "    df_ml['num_products'] * 0.3 +\n",
    "    (df_ml['tenure_months'] / 72) * 0.3 +\n",
    "    df_ml['has_partner'] * 0.2 +\n",
    "    df_ml['has_dependents'] * 0.2\n",
    ")\n",
    "\n",
    "print(\"New features created:\")\n",
    "print(df_ml[['tenure_years', 'is_new_customer', 'avg_monthly_charge', \n",
    "             'charge_per_product', 'support_per_tenure', 'engagement_score']].describe().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s10e1f2a3",
   "metadata": {},
   "source": [
    "### Exercise 2.2: Encode Categorical Variables - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s11f2a3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode\n",
    "df_encoded = pd.get_dummies(df_ml, columns=['contract_type', 'payment_method', 'internet_service'], drop_first=True)\n",
    "\n",
    "# Drop customer_id (not a feature)\n",
    "df_encoded = df_encoded.drop('customer_id', axis=1)\n",
    "\n",
    "print(f\"Shape after encoding: {df_encoded.shape}\")\n",
    "print(f\"\\nFeatures:\")\n",
    "for col in df_encoded.columns:\n",
    "    print(f\"  {col}: {df_encoded[col].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s12a3b4c5",
   "metadata": {},
   "source": [
    "### Exercise 2.3: Prepare Train/Test Split - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s13b4c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_encoded.drop('churn', axis=1)\n",
    "y = df_encoded['churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale numeric features\n",
    "numeric_features = ['tenure_months', 'monthly_charges', 'total_charges', 'support_tickets',\n",
    "                   'num_products', 'age', 'tenure_years', 'avg_monthly_charge',\n",
    "                   'charge_per_product', 'support_per_tenure', 'engagement_score']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train[numeric_features] = scaler.fit_transform(X_train[numeric_features])\n",
    "X_test[numeric_features] = scaler.transform(X_test[numeric_features])\n",
    "\n",
    "print(f\"Training set: {X_train.shape} ({y_train.mean():.1%} churn)\")\n",
    "print(f\"Test set: {X_test.shape} ({y_test.mean():.1%} churn)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s14c5d6e7",
   "metadata": {},
   "source": [
    "### Exercise 3.1: Train Three Models - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s15d6e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Train\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Metrics\n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'y_pred': y_pred,\n",
    "        'y_prob': y_prob,\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "        'auc': roc_auc_score(y_test, y_prob)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Accuracy:  {results[name]['accuracy']:.4f}\")\n",
    "    print(f\"  Precision: {results[name]['precision']:.4f}\")\n",
    "    print(f\"  Recall:    {results[name]['recall']:.4f}\")\n",
    "    print(f\"  F1 Score:  {results[name]['f1']:.4f}\")\n",
    "    print(f\"  AUC:       {results[name]['auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s16e7f8a9",
   "metadata": {},
   "source": [
    "### Exercise 3.2: Cross-Validation - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s17f8a9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"5-Fold Cross-Validation Results (F1 Score):\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for name, model_info in results.items():\n",
    "    cv_scores = cross_val_score(model_info['model'], X_train, y_train, cv=cv, scoring='f1')\n",
    "    print(f\"  {name:25s}: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s18a9b0c1",
   "metadata": {},
   "source": [
    "### Exercise 3.3: Confusion Matrices - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s19b0c1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for ax, (name, res) in zip(axes, results.items()):\n",
    "    cm = confusion_matrix(y_test, res['y_pred'])\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "               xticklabels=['Stayed', 'Churned'],\n",
    "               yticklabels=['Stayed', 'Churned'])\n",
    "    ax.set_title(f'{name}\\n(F1: {res[\"f1\"]:.3f})')\n",
    "    ax.set_ylabel('Actual')\n",
    "    ax.set_xlabel('Predicted')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s20c1d2e3",
   "metadata": {},
   "source": [
    "### Exercise 3.4: ROC Curves - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s21d2e3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for name, res in results.items():\n",
    "    fpr, tpr, _ = roc_curve(y_test, res['y_prob'])\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=f\"{name} (AUC={res['auc']:.3f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random (AUC=0.500)')\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC Curves \\u2014 Model Comparison', fontsize=14)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s22e3f4a5",
   "metadata": {},
   "source": [
    "### Exercise 4.1: Analyze Feature Importance - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s23f4a5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = results['Random Forest']['model']\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=feature_importance.head(15), x='importance', y='feature', palette='viridis')\n",
    "plt.title('Top 15 Features \\u2014 Random Forest Importance', fontsize=14)\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 10 Features:\")\n",
    "for _, row in feature_importance.head(10).iterrows():\n",
    "    print(f\"  {row['feature']:30s}: {row['importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s24a5b6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model = results['Gradient Boosting']['model']\n",
    "\n",
    "gb_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': gb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Side-by-side comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "sns.barplot(data=feature_importance.head(10), x='importance', y='feature', ax=axes[0], palette='viridis')\n",
    "axes[0].set_title('Random Forest \\u2014 Top 10 Features')\n",
    "\n",
    "sns.barplot(data=gb_importance.head(10), x='importance', y='feature', ax=axes[1], palette='magma')\n",
    "axes[1].set_title('Gradient Boosting \\u2014 Top 10 Features')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s25b6c7d8",
   "metadata": {},
   "source": [
    "### Exercise 5.1: Save the Best Model - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s26c7d8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = max(results, key=lambda k: results[k]['f1'])\n",
    "best_model = results[best_model_name]['model']\n",
    "\n",
    "print(f\"Best model: {best_model_name} (F1: {results[best_model_name]['f1']:.4f})\")\n",
    "\n",
    "# Save model and scaler\n",
    "joblib.dump(best_model, 'churn_model.pkl')\n",
    "joblib.dump(scaler, 'churn_scaler.pkl')\n",
    "\n",
    "print(\"Model and scaler saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s27d8e9f0",
   "metadata": {},
   "source": [
    "### Exercise 5.2: Create Prediction Function - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s28e9f0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_churn(customer_data, model_path='churn_model.pkl', scaler_path='churn_scaler.pkl'):\n",
    "    \"\"\"Predict churn probability for a new customer.\"\"\"\n",
    "    model = joblib.load(model_path)\n",
    "    scaler = joblib.load(scaler_path)\n",
    "    \n",
    "    # Ensure correct feature order\n",
    "    df_input = pd.DataFrame([customer_data])\n",
    "    \n",
    "    # Engineer features\n",
    "    df_input['tenure_years'] = df_input['tenure_months'] / 12\n",
    "    df_input['is_new_customer'] = (df_input['tenure_months'] <= 6).astype(int)\n",
    "    df_input['avg_monthly_charge'] = df_input['total_charges'] / df_input['tenure_months'].replace(0, 1)\n",
    "    df_input['charge_per_product'] = df_input['monthly_charges'] / df_input['num_products']\n",
    "    df_input['support_per_tenure'] = df_input['support_tickets'] / df_input['tenure_months'].replace(0, 1)\n",
    "    df_input['engagement_score'] = (\n",
    "        df_input['num_products'] * 0.3 +\n",
    "        (df_input['tenure_months'] / 72) * 0.3 +\n",
    "        df_input['has_partner'] * 0.2 +\n",
    "        df_input['has_dependents'] * 0.2\n",
    "    )\n",
    "    \n",
    "    # Encode categoricals (match training)\n",
    "    df_encoded = pd.get_dummies(df_input, columns=['contract_type', 'payment_method', 'internet_service'], drop_first=True)\n",
    "    \n",
    "    # Align columns with training data\n",
    "    for col in X_train.columns:\n",
    "        if col not in df_encoded.columns:\n",
    "            df_encoded[col] = 0\n",
    "    df_encoded = df_encoded[X_train.columns]\n",
    "    \n",
    "    # Scale\n",
    "    numeric_features_list = ['tenure_months', 'monthly_charges', 'total_charges', 'support_tickets',\n",
    "                            'num_products', 'age', 'tenure_years', 'avg_monthly_charge',\n",
    "                            'charge_per_product', 'support_per_tenure', 'engagement_score']\n",
    "    df_encoded[numeric_features_list] = scaler.transform(df_encoded[numeric_features_list])\n",
    "    \n",
    "    # Predict\n",
    "    prob = model.predict_proba(df_encoded)[0][1]\n",
    "    prediction = \"CHURN RISK\" if prob > 0.5 else \"LIKELY TO STAY\"\n",
    "    \n",
    "    return {'prediction': prediction, 'churn_probability': round(prob, 4)}\n",
    "\n",
    "# Test prediction\n",
    "test_customer = {\n",
    "    'tenure_months': 3,\n",
    "    'monthly_charges': 95.00,\n",
    "    'total_charges': 285.00,\n",
    "    'contract_type': 'Month-to-month',\n",
    "    'payment_method': 'Electronic check',\n",
    "    'internet_service': 'Fiber optic',\n",
    "    'support_tickets': 5,\n",
    "    'num_products': 1,\n",
    "    'age': 32,\n",
    "    'has_partner': 0,\n",
    "    'has_dependents': 0\n",
    "}\n",
    "\n",
    "result = predict_churn(test_customer)\n",
    "print(f\"Prediction: {result['prediction']}\")\n",
    "print(f\"Churn Probability: {result['churn_probability']:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s29f0a1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a loyal customer\n",
    "loyal_customer = {\n",
    "    'tenure_months': 48,\n",
    "    'monthly_charges': 55.00,\n",
    "    'total_charges': 2640.00,\n",
    "    'contract_type': 'Two year',\n",
    "    'payment_method': 'Bank transfer',\n",
    "    'internet_service': 'DSL',\n",
    "    'support_tickets': 1,\n",
    "    'num_products': 4,\n",
    "    'age': 45,\n",
    "    'has_partner': 1,\n",
    "    'has_dependents': 1\n",
    "}\n",
    "\n",
    "result = predict_churn(loyal_customer)\n",
    "print(f\"Prediction: {result['prediction']}\")\n",
    "print(f\"Churn Probability: {result['churn_probability']:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s30a1b2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up saved files\n",
    "import os\n",
    "for f in ['churn_model.pkl', 'churn_scaler.pkl']:\n",
    "    if os.path.exists(f):\n",
    "        os.remove(f)\n",
    "print(\"Cleanup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s31b2c3d4",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, you learned how to:\n",
    "\n",
    "1. **Generate and explore** a realistic churn dataset\n",
    "2. **Engineer features** from raw data (tenure-based, charge-based, engagement)\n",
    "3. **Encode and scale** features for ML\n",
    "4. **Train and compare** three models (Logistic Regression, Random Forest, Gradient Boosting)\n",
    "5. **Evaluate models** with cross-validation, confusion matrices, and ROC curves\n",
    "6. **Analyze feature importance** to understand model decisions\n",
    "7. **Save and deploy** models with joblib and build prediction functions\n",
    "\n",
    "---\n",
    "\n",
    "*Introduction to Data Science & Engineering | AI Elevate*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 5,
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}